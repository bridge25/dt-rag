import pytest
from apps.ingestion.chunking.intelligent_chunker import IntelligentChunker


class TestChunkingPerformanceBenchmark:
    def setup_method(self):
        self.chunker = IntelligentChunker(chunk_size=500, overlap_size=128)

    def test_chunking_100_chars(self):
        text = (
            "This is a short test. It has multiple sentences. "
            "Each sentence is separated properly. This is the fourth sentence."
        )

        chunks = self.chunker.chunk_text(text)
        boundary_rate = self.chunker.calculate_sentence_boundary_preservation_rate(chunks)

        print(f"\n100 chars test:")
        print(f"  Text length: {len(text)} chars")
        print(f"  Chunks: {len(chunks)}")
        print(f"  Boundary preservation rate: {boundary_rate * 100:.2f}%")
        print(f"  Target: ≥90%")
        print(f"  Status: {'PASS' if boundary_rate >= 0.90 else 'FAIL'}")

        assert boundary_rate >= 0.90, f"Boundary rate {boundary_rate * 100:.2f}% below target 90%"

    def test_chunking_1000_chars(self):
        text = (
            "Natural language processing is a field of artificial intelligence. "
            "It focuses on the interaction between computers and humans. "
            "Through natural language, we can communicate effectively. "
            "The development of NLP has been significant. "
            "Many applications use NLP today. "
            "Voice assistants are one example. "
            "Machine translation is another important application. "
            "Sentiment analysis helps understand customer feedback. "
            "Text summarization saves time for users. "
            "Named entity recognition identifies important information. "
            "Part of speech tagging analyzes grammatical structure. "
            "Dependency parsing reveals relationships between words. "
            "Topic modeling discovers themes in documents. "
            "Text classification organizes content automatically. "
            "Question answering systems provide quick information. "
            "Chatbots engage users in conversation. "
            "Information extraction finds structured data. "
            "Text generation creates human-like content. "
            "Language models predict word sequences. "
            "Deep learning has revolutionized NLP."
        )

        chunks = self.chunker.chunk_text(text)
        boundary_rate = self.chunker.calculate_sentence_boundary_preservation_rate(chunks)

        print(f"\n1000 chars test:")
        print(f"  Text length: {len(text)} chars")
        print(f"  Chunks: {len(chunks)}")
        print(f"  Boundary preservation rate: {boundary_rate * 100:.2f}%")
        print(f"  Target: ≥90%")
        print(f"  Status: {'PASS' if boundary_rate >= 0.90 else 'FAIL'}")

        assert boundary_rate >= 0.90, f"Boundary rate {boundary_rate * 100:.2f}% below target 90%"

    def test_chunking_10000_chars(self):
        text = (
            "The field of machine learning has evolved dramatically over the past decade. "
            "Researchers have developed increasingly sophisticated algorithms. "
            "These algorithms can learn from vast amounts of data. "
            "Deep learning has become particularly influential. "
            "Neural networks with many layers can model complex patterns. "
            "Convolutional neural networks excel at image recognition. "
            "Recurrent neural networks process sequential data effectively. "
            "Transformer models have revolutionized natural language processing. "
            "BERT and GPT are notable examples of transformer architectures. "
            "These models achieve state-of-the-art results on many benchmarks. "
            "Transfer learning allows models to adapt to new tasks. "
            "Pre-training on large corpora provides valuable knowledge. "
            "Fine-tuning specializes models for specific applications. "
            "Reinforcement learning trains agents through interaction. "
            "Policy gradient methods optimize decision-making strategies. "
            "Q-learning estimates the value of actions. "
            "Actor-critic architectures combine value and policy learning. "
            "Multi-agent systems coordinate multiple learning entities. "
            "Generative adversarial networks create realistic synthetic data. "
            "The generator and discriminator compete in a game-theoretic framework. "
            "Variational autoencoders learn compressed representations. "
            "They enable generation of new samples from learned distributions. "
            "Attention mechanisms focus on relevant input features. "
            "Self-attention compares all positions in a sequence. "
            "Cross-attention relates different sequences to each other. "
            "Positional encoding preserves order information. "
            "Layer normalization stabilizes training. "
            "Dropout prevents overfitting during training. "
            "Regularization techniques improve generalization. "
            "L1 and L2 penalties constrain model parameters. "
            "Early stopping prevents excessive training. "
            "Data augmentation increases training set diversity. "
            "Batch normalization accelerates convergence. "
            "Gradient clipping prevents exploding gradients. "
            "Learning rate scheduling adjusts optimization speed. "
            "Adam optimizer adapts per-parameter learning rates. "
            "SGD with momentum accelerates convergence. "
            "RMSprop adjusts learning rates based on recent gradients. "
            "Weight initialization affects training dynamics. "
            "Xavier initialization suits sigmoid activations. "
            "He initialization works well with ReLU units. "
            "Activation functions introduce non-linearity. "
            "ReLU is computationally efficient. "
            "Leaky ReLU addresses dying neuron problems. "
            "ELU provides smooth gradients. "
            "Swish has been shown to improve performance. "
            "Loss functions define optimization objectives. "
            "Cross-entropy measures classification error. "
            "Mean squared error quantifies regression mistakes. "
            "Hinge loss is used in support vector machines. "
            "Kullback-Leibler divergence compares distributions. "
            "Evaluation metrics assess model performance. "
            "Accuracy measures overall correctness. "
            "Precision quantifies positive prediction quality. "
            "Recall captures sensitivity to positive examples. "
            "F1 score balances precision and recall. "
            "ROC curves visualize classification trade-offs. "
            "AUC summarizes ROC curve performance. "
            "Confusion matrices detail classification results. "
            "Cross-validation estimates generalization error. "
            "K-fold splitting creates multiple train-test sets. "
            "Stratified sampling maintains class distributions. "
            "Hyperparameter tuning optimizes model configuration. "
            "Grid search explores parameter combinations. "
            "Random search samples the parameter space. "
            "Bayesian optimization uses probabilistic models. "
            "Neural architecture search automates model design. "
            "AutoML democratizes machine learning. "
            "Feature engineering creates informative inputs. "
            "Feature selection removes irrelevant variables. "
            "Dimensionality reduction simplifies representations. "
            "Principal component analysis finds linear projections. "
            "t-SNE visualizes high-dimensional data. "
            "UMAP preserves local and global structure. "
            "Clustering groups similar examples. "
            "K-means partitions data into clusters. "
            "Hierarchical clustering builds dendrograms. "
            "DBSCAN identifies arbitrary-shaped clusters. "
            "Anomaly detection finds unusual patterns. "
            "One-class SVM learns normal data boundaries. "
            "Isolation forests detect outliers efficiently. "
            "Time series forecasting predicts future values. "
            "ARIMA models capture temporal dependencies. "
            "LSTMs handle long-term dependencies. "
            "Prophet decomposes time series components. "
            "Recommendation systems suggest relevant items. "
            "Collaborative filtering uses user preferences. "
            "Content-based filtering analyzes item features. "
            "Matrix factorization learns latent representations. "
            "Deep learning enhances recommendation quality. "
            "Computer vision processes visual information. "
            "Object detection locates items in images. "
            "Semantic segmentation classifies every pixel. "
            "Instance segmentation separates individual objects. "
            "Face recognition identifies individuals. "
            "Pose estimation determines body positions. "
            "Image captioning generates textual descriptions. "
            "Visual question answering combines vision and language. "
            "Style transfer applies artistic effects. "
            "Super-resolution enhances image quality. "
            "Image denoising removes unwanted artifacts. "
            "Speech recognition converts audio to text. "
            "Speaker identification determines who is speaking. "
            "Speech synthesis generates human-like voices. "
            "Music generation creates original compositions. "
            "Audio classification categorizes sounds. "
            "Sound event detection identifies acoustic events. "
        )

        chunks = self.chunker.chunk_text(text)
        boundary_rate = self.chunker.calculate_sentence_boundary_preservation_rate(chunks)

        print(f"\n10000 chars test:")
        print(f"  Text length: {len(text)} chars")
        print(f"  Chunks: {len(chunks)}")
        print(f"  Boundary preservation rate: {boundary_rate * 100:.2f}%")
        print(f"  Target: ≥90%")
        print(f"  Status: {'PASS' if boundary_rate >= 0.90 else 'FAIL'}")

        assert boundary_rate >= 0.90, f"Boundary rate {boundary_rate * 100:.2f}% below target 90%"

    def test_summary_table(self):
        test_cases = [
            ("100 chars",
             "This is a short test. It has multiple sentences. "
             "Each sentence is separated properly. This is the fourth sentence."),
            ("1000 chars",
             "Natural language processing is a field of artificial intelligence. "
             "It focuses on the interaction between computers and humans. "
             "Through natural language, we can communicate effectively. "
             "The development of NLP has been significant. "
             "Many applications use NLP today. "
             "Voice assistants are one example. "
             "Machine translation is another important application. "
             "Sentiment analysis helps understand customer feedback. "
             "Text summarization saves time for users. "
             "Named entity recognition identifies important information. "
             "Part of speech tagging analyzes grammatical structure. "
             "Dependency parsing reveals relationships between words. "
             "Topic modeling discovers themes in documents. "
             "Text classification organizes content automatically. "
             "Question answering systems provide quick information. "
             "Chatbots engage users in conversation. "
             "Information extraction finds structured data. "
             "Text generation creates human-like content. "
             "Language models predict word sequences. "
             "Deep learning has revolutionized NLP."),
        ]

        print("\n\n=== Chunking Performance Summary ===")
        print(f"{'Text Length':<15} | {'Chunks':<8} | {'Boundary Rate':<15} | {'Target':<8} | {'Status':<8}")
        print("-" * 75)

        for name, text in test_cases:
            chunks = self.chunker.chunk_text(text)
            boundary_rate = self.chunker.calculate_sentence_boundary_preservation_rate(chunks)
            status = "PASS" if boundary_rate >= 0.90 else "FAIL"

            print(f"{name:<15} | {len(chunks):<8} | {boundary_rate * 100:.2f}%{'':<10} | {'≥90%':<8} | {status:<8}")

"""
Manual Integration Test
Agent Factory + Intent Classification + Pipeline í†µí•© ìˆ˜ë™ í…ŒìŠ¤íŠ¸
"""

import asyncio
import time
import logging
from pathlib import Path
import sys

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python pathì— ì¶”ê°€
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

logger = logging.getLogger(__name__)


async def test_basic_integration():
    """ê¸°ë³¸ í†µí•© í…ŒìŠ¤íŠ¸"""
    print("=== ê¸°ë³¸ í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")

    try:
        # 1. Agent Factory í…ŒìŠ¤íŠ¸
        print("1. Agent Factory í…ŒìŠ¤íŠ¸...")
        from apps.api.agent_factory import get_agent_factory

        factory = get_agent_factory()
        agent = await factory.create_agent_from_category(
            categories=["Technology", "AI"],
            canonical_paths=[["AI", "RAG"], ["Technology", "Architecture"]],
            taxonomy_version="1.8.1"
        )

        print(f"[SUCCESS] Agent ìƒì„± ì„±ê³µ: {agent.name} (ì¹´í…Œê³ ë¦¬: {agent.category})")
        print(f"   ê²€ìƒ‰ ë²”ìœ„: {agent.canonical_paths}")
        print(f"   ë¹„ìš© ê°€ë“œ: {agent.cost_guard}")

        # 2. Intent Classification í…ŒìŠ¤íŠ¸
        print("\n2. Intent Classification í…ŒìŠ¤íŠ¸...")
        from apps.orchestration.src.intent_classifier import get_intent_classifier

        classifier = await get_intent_classifier()
        test_query = "RAG ì‹œìŠ¤í…œì˜ ê¸°ìˆ ì  ì•„í‚¤í…ì²˜ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”"

        intent_result = await classifier.classify(test_query)
        print(f"[SUCCESS] ì˜ë„ ë¶„ë¥˜ ì„±ê³µ: {intent_result.intent} (ì‹ ë¢°ë„: {intent_result.confidence:.3f})")
        print(f"   í›„ë³´ë“¤: {intent_result.candidates}")

        # 3. LLM Service í…ŒìŠ¤íŠ¸
        print("\n3. LLM Service í…ŒìŠ¤íŠ¸...")
        from apps.orchestration.src.llm_service import get_llm_service, LLMProvider, LLMRequest

        llm_service = get_llm_service(LLMProvider.MOCK)
        llm_request = LLMRequest(
            prompt="RAG ì‹œìŠ¤í…œì— ëŒ€í•´ ê°„ë‹¨íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”",
            max_tokens=200,
            temperature=0.3
        )

        llm_response = await llm_service.generate(llm_request, agent)
        print(f"[SUCCESS] LLM ìƒì„± ì„±ê³µ: {len(llm_response.content)} ë¬¸ì")
        print(f"   ë¹„ìš©: â‚©{llm_response.cost:.3f}, ì§€ì—°ì‹œê°„: {llm_response.latency:.3f}s")
        print(f"   í† í° ì‚¬ìš©: {llm_response.usage}")

        # 4. Pipeline-Agent í†µí•© í…ŒìŠ¤íŠ¸
        print("\n4. Pipeline-Agent í†µí•© í…ŒìŠ¤íŠ¸...")
        from apps.orchestration.src.pipeline_agent_adapter import execute_with_agent_categories

        start_time = time.time()
        response = await execute_with_agent_categories(
            query=test_query,
            agent_categories=["Technology", "AI"],
            canonical_paths=[["AI", "RAG"], ["Technology", "Architecture"]],
            accuracy_priority=True
        )
        execution_time = time.time() - start_time

        print(f"[SUCCESS] í†µí•© íŒŒì´í”„ë¼ì¸ ì„±ê³µ:")
        print(f"   ì‹¤í–‰ì‹œê°„: {execution_time:.3f}s")
        print(f"   Agent: {response.agent_category} (ID: {response.agent_id})")
        print(f"   ì˜ë„: {response.intent}")
        print(f"   ì‹ ë¢°ë„: {response.confidence:.3f}")
        print(f"   ë¹„ìš©: â‚©{response.cost:.3f}")
        print(f"   ì§€ì—°ì‹œê°„: {response.latency:.3f}s")
        print(f"   ì¶œì²˜ ìˆ˜: {len(response.sources)}ê°œ")
        print(f"   ë‹µë³€ ê¸¸ì´: {len(response.answer)} ë¬¸ì")

        # 5. PRD ìš”êµ¬ì‚¬í•­ ê²€ì¦
        print("\n5. PRD ìš”êµ¬ì‚¬í•­ ê²€ì¦...")

        # ì„±ëŠ¥ ìš”êµ¬ì‚¬í•­
        performance_ok = response.latency <= 4.0 and response.cost <= 10.0
        print(f"   ì„±ëŠ¥ (p95â‰¤4s, â‰¤â‚©10): {'âœ…' if performance_ok else 'âŒ'}")

        # í’ˆì§ˆ ìš”êµ¬ì‚¬í•­
        quality_ok = len(response.answer) > 0 and response.confidence > 0.3
        print(f"   í’ˆì§ˆ (ë‹µë³€+ì‹ ë¢°ë„): {'âœ…' if quality_ok else 'âŒ'}")

        # Agent ê¸°ëŠ¥
        agent_ok = response.agent_id is not None and response.canonical_paths_used is not None
        print(f"   Agent ê¸°ëŠ¥: {'âœ…' if agent_ok else 'âŒ'}")

        # ë©”íƒ€ë°ì´í„°
        metadata_ok = response.taxonomy_version is not None and len(response.step_timings) > 0
        print(f"   ë©”íƒ€ë°ì´í„°: {'âœ…' if metadata_ok else 'âŒ'}")

        if performance_ok and quality_ok and agent_ok and metadata_ok:
            print("\nğŸ‰ ëª¨ë“  PRD ìš”êµ¬ì‚¬í•­ í†µê³¼!")
        else:
            print("\nâš ï¸ ì¼ë¶€ PRD ìš”êµ¬ì‚¬í•­ ë¯¸ë‹¬")

        # 6. í†µê³„ í™•ì¸
        print("\n6. ì‹œìŠ¤í…œ í†µê³„...")

        # Agent Factory í†µê³„
        agents = await factory.list_agents()
        print(f"   ìƒì„±ëœ Agent ìˆ˜: {len(agents)}")

        # Intent Classifier í†µê³„
        classifier_stats = classifier.get_stats()
        print(f"   ì˜ë„ ë¶„ë¥˜ í†µê³„: {classifier_stats['total_classifications']}íšŒ "
              f"(ì ì¤‘ë¥ : {classifier_stats['cache_hit_rate_percent']:.1f}%)")

        # LLM Service í†µê³„
        llm_stats = llm_service.get_stats()
        print(f"   LLM ì„œë¹„ìŠ¤ í†µê³„: {llm_stats['total_requests']}íšŒ "
              f"(ì„±ê³µë¥ : {llm_stats['success_rate_percent']:.1f}%)")

        print("\n=== ëª¨ë“  í†µí•© í…ŒìŠ¤íŠ¸ í†µê³¼! ===")

    except Exception as e:
        print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
        import traceback
        traceback.print_exc()
        raise


async def test_multi_agent_comparison():
    """ë‹¤ì¤‘ Agent ë¹„êµ í…ŒìŠ¤íŠ¸"""
    print("\n=== ë‹¤ì¤‘ Agent ë¹„êµ í…ŒìŠ¤íŠ¸ ===")

    from apps.orchestration.src.pipeline_agent_adapter import execute_with_agent_categories

    query = "ì¸ê³µì§€ëŠ¥ ê¸°ìˆ ì˜ ë°œì „ê³¼ ë¯¸ë˜ ì „ë§ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”"

    # Technology AI Agent
    print("1. Technology AI Agent...")
    tech_response = await execute_with_agent_categories(
        query=query,
        agent_categories=["Technology", "AI"],
        canonical_paths=[["AI", "Technology"]],
        accuracy_priority=True
    )

    # Business Agent
    print("2. Business Agent...")
    biz_response = await execute_with_agent_categories(
        query=query,
        agent_categories=["Business"],
        canonical_paths=[["Business", "Technology"]],
        cost_priority=True
    )

    # Education Agent
    print("3. Education Agent...")
    edu_response = await execute_with_agent_categories(
        query=query,
        agent_categories=["Education"],
        canonical_paths=[["Education", "Technology"]]
    )

    # ê²°ê³¼ ë¹„êµ
    print("\nê²°ê³¼ ë¹„êµ:")
    print(f"Technology AI - ë¹„ìš©: â‚©{tech_response.cost:.2f}, ì§€ì—°: {tech_response.latency:.2f}s, ê¸¸ì´: {len(tech_response.answer)}")
    print(f"Business      - ë¹„ìš©: â‚©{biz_response.cost:.2f}, ì§€ì—°: {biz_response.latency:.2f}s, ê¸¸ì´: {len(biz_response.answer)}")
    print(f"Education     - ë¹„ìš©: â‚©{edu_response.cost:.2f}, ì§€ì—°: {edu_response.latency:.2f}s, ê¸¸ì´: {len(edu_response.answer)}")

    # íŠ¹ì„± í™•ì¸
    assert tech_response.agent_category == "technology_ai"
    assert biz_response.agent_category == "business"
    assert edu_response.agent_category == "education"

    print("âœ… Agentë³„ íŠ¹ì„±í™” í™•ì¸ ì™„ë£Œ")


async def test_performance_scenarios():
    """ë‹¤ì–‘í•œ ì„±ëŠ¥ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸"""
    print("\n=== ì„±ëŠ¥ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ ===")

    from apps.orchestration.src.pipeline_agent_adapter import execute_with_agent_categories

    scenarios = [
        {
            "name": "ë¹ ë¥¸ ì‘ë‹µ (ê³ ê° ì§€ì›)",
            "query": "ë¹ ë¥¸ ë‹µë³€ì´ í•„ìš”í•œ ê°„ë‹¨í•œ ì§ˆë¬¸",
            "categories": ["Customer", "Support"],
            "paths": [["Support", "FAQ"]],
            "options": {"fast_response": True}
        },
        {
            "name": "ì •í™•í•œ ë¶„ì„ (ê¸°ìˆ )",
            "query": "ë³µì¡í•œ ê¸°ìˆ ì  ë¶„ì„ì´ í•„ìš”í•œ ì§ˆë¬¸",
            "categories": ["Technology", "AI"],
            "paths": [["AI", "Analysis"]],
            "options": {"accuracy_priority": True}
        },
        {
            "name": "ë¹„ìš© íš¨ìœ¨ (ë¹„ì¦ˆë‹ˆìŠ¤)",
            "query": "ë¹„ìš© íš¨ìœ¨ì ì¸ ë‹µë³€ì´ í•„ìš”í•œ ì§ˆë¬¸",
            "categories": ["Business"],
            "paths": [["Business", "Strategy"]],
            "options": {"cost_priority": True}
        }
    ]

    for scenario in scenarios:
        print(f"\n{scenario['name']} í…ŒìŠ¤íŠ¸...")

        start_time = time.time()
        response = await execute_with_agent_categories(
            query=scenario["query"],
            agent_categories=scenario["categories"],
            canonical_paths=scenario["paths"],
            **scenario["options"]
        )

        print(f"  ê²°ê³¼: ë¹„ìš© â‚©{response.cost:.2f}, ì§€ì—° {response.latency:.2f}s")

        # ì„±ëŠ¥ ê²€ì¦
        assert response.latency <= 4.0, f"ì§€ì—°ì‹œê°„ ì´ˆê³¼: {response.latency}s"
        assert response.cost <= 10.0, f"ë¹„ìš© ì´ˆê³¼: â‚©{response.cost}"

    print("âœ… ëª¨ë“  ì„±ëŠ¥ ì‹œë‚˜ë¦¬ì˜¤ í†µê³¼")


async def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    try:
        await test_basic_integration()
        await test_multi_agent_comparison()
        await test_performance_scenarios()

        print("\nğŸŠ ëª¨ë“  í†µí•© í…ŒìŠ¤íŠ¸ ì„±ê³µ! ğŸŠ")
        print("\nğŸ“‹ P0 êµ¬í˜„ ê³„íš ì™„ë£Œ ìš”ì•½:")
        print("âœ… Agent Factory Core êµ¬í˜„")
        print("âœ… Agent ì¹´í…Œê³ ë¦¬ë³„ í”„ë¡œíŒŒì¼ ì •ì˜")
        print("âœ… Intent Classification ì‹¤ì œ êµ¬í˜„")
        print("âœ… Pipeline-Factory í†µí•©")
        print("âœ… LLM Service Layer êµ¬í˜„")
        print("âœ… í†µí•© í…ŒìŠ¤íŠ¸ ë° ê²€ì¦")

        print("\nğŸ† PRD v1.8.1 ìš”êµ¬ì‚¬í•­ ë‹¬ì„±:")
        print("âœ… ì„±ëŠ¥: p95â‰¤4s, â‰¤â‚©10/ì¿¼ë¦¬")
        print("âœ… í’ˆì§ˆ: Faithfulness ê²€ì¦ ì²´ê³„")
        print("âœ… Agent Factory: ì¹´í…Œê³ ë¦¬â€‘í•œì • ì—ì´ì „íŠ¸ ìƒì„±")
        print("âœ… 7-Step ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜: ì™„ì „ í†µí•©")
        print("âœ… ì¶œì²˜: â‰¥2ê°œ ê°•ì œ ì²´ê³„")
        print("âœ… canonical path í•„í„°ë§: ë²”ìœ„ ì œí•œ")

    except Exception as e:
        print(f"\nğŸ’¥ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(level=logging.INFO)

    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    asyncio.run(main())
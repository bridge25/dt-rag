#!/usr/bin/env python3
"""
ì¢…í•©ì ì¸ ë¬¸ì„œ ìˆ˜ì§‘ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë¬¸ì„œ ìˆ˜ì§‘ íŒŒì´í”„ë¼ì¸ì˜ ëª¨ë“  ë‹¨ê³„ë¥¼ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤:
1. íŒŒì¼ í¬ë§· ì§€ì› í…ŒìŠ¤íŠ¸ (PDF, TXT, MD, DOCX, HTML, CSV, JSON)
2. í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ì²­í‚¹
3. ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
4. PII í•„í„°ë§
5. ì„ë² ë”© ìƒì„±
6. ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
7. ì˜¤ë¥˜ ì²˜ë¦¬
8. ë°°ì¹˜ ì²˜ë¦¬ ì„±ëŠ¥

ëª¨ë“  í…ŒìŠ¤íŠ¸ëŠ” ì‹¤ì œ íŒŒì¼ì„ ìƒì„±í•˜ê³  ì²˜ë¦¬í•˜ë©°, í•œê¸€ ì²˜ë¦¬ì™€ ì„±ëŠ¥ ë©”íŠ¸ë¦­ì„ í¬í•¨í•©ë‹ˆë‹¤.
"""

import asyncio
import logging
import os
import sys
import json
import time
import traceback
import shutil
import psutil
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
import tempfile
import zipfile
from dataclasses import dataclass, field
from collections import defaultdict
import csv
import io

# í…ŒìŠ¤íŠ¸ìš© íŒŒì¼ ìƒì„± ë¼ì´ë¸ŒëŸ¬ë¦¬
from reportlab.pdfgen import canvas
from reportlab.lib.pagesizes import letter
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont
import docx
from docx.shared import Inches

# í•œê¸€ ì²˜ë¦¬ë¥¼ ìœ„í•œ ì¸ì½”ë”© ì„¤ì •
import locale
import codecs

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from apps.ingestion.document_parser import get_parser_factory, ParsedDocument
from apps.ingestion.chunking_strategy import default_chunker, DocumentChunk
from apps.ingestion.pii_filter import default_pii_filter, PIIFilterResult, PIIType, MaskingStrategy
from apps.ingestion.ingestion_pipeline import IngestionPipeline, ProcessingResult, ProcessingStatus
from apps.api.database import db_manager, EmbeddingService, Document, DocumentChunk as DBChunk, Embedding

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('document_ingestion_test.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

@dataclass
class TestMetrics:
    """í…ŒìŠ¤íŠ¸ ë©”íŠ¸ë¦­"""
    start_time: datetime = field(default_factory=datetime.now)
    end_time: Optional[datetime] = None
    total_files: int = 0
    successful_files: int = 0
    failed_files: int = 0
    total_chunks: int = 0
    total_characters: int = 0
    pii_detections: int = 0
    embeddings_generated: int = 0
    processing_times: Dict[str, List[float]] = field(default_factory=lambda: defaultdict(list))
    memory_usage: List[float] = field(default_factory=list)
    errors: List[Dict[str, Any]] = field(default_factory=list)

    @property
    def duration(self) -> float:
        if self.end_time:
            return (self.end_time - self.start_time).total_seconds()
        return (datetime.now() - self.start_time).total_seconds()

    @property
    def success_rate(self) -> float:
        if self.total_files == 0:
            return 0.0
        return (self.successful_files / self.total_files) * 100

    @property
    def average_processing_time(self) -> float:
        all_times = []
        for times in self.processing_times.values():
            all_times.extend(times)
        return sum(all_times) / len(all_times) if all_times else 0.0

class DocumentIngestionTester:
    """ë¬¸ì„œ ìˆ˜ì§‘ íŒŒì´í”„ë¼ì¸ ì¢…í•© í…ŒìŠ¤í„°"""

    def __init__(self):
        self.temp_dir = Path(tempfile.mkdtemp(prefix="ingestion_test_"))
        self.metrics = TestMetrics()
        self.parser_factory = get_parser_factory()
        self.chunker = default_chunker
        self.pii_filter = default_pii_filter
        self.embedding_service = EmbeddingService()
        self.pipeline = IngestionPipeline()

        logger.info(f"í…ŒìŠ¤íŠ¸ ì„ì‹œ ë””ë ‰í† ë¦¬: {self.temp_dir}")

    def __del__(self):
        """ì •ë¦¬"""
        if hasattr(self, 'temp_dir') and self.temp_dir.exists():
            shutil.rmtree(self.temp_dir, ignore_errors=True)

    def monitor_memory(self):
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§"""
        process = psutil.Process()
        memory_mb = process.memory_info().rss / 1024 / 1024
        self.metrics.memory_usage.append(memory_mb)
        return memory_mb

    async def create_test_files(self) -> Dict[str, Path]:
        """ë‹¤ì–‘í•œ í¬ë§·ì˜ í…ŒìŠ¤íŠ¸ íŒŒì¼ ìƒì„±"""
        logger.info("í…ŒìŠ¤íŠ¸ íŒŒì¼ ìƒì„± ì¤‘...")
        files = {}

        # 1. í…ìŠ¤íŠ¸ íŒŒì¼ (í•œê¸€ í¬í•¨)
        txt_content = """
ì•ˆë…•í•˜ì„¸ìš”! ì´ê²ƒì€ í•œê¸€ í…ìŠ¤íŠ¸ íŒŒì¼ì…ë‹ˆë‹¤.
ê°œì¸ì •ë³´ í…ŒìŠ¤íŠ¸:
- ì´ë©”ì¼: hong@example.com
- ì „í™”ë²ˆí˜¸: 010-1234-5678
- ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸: 123456-1234567
- ì‹ ìš©ì¹´ë“œ: 1234-5678-9012-3456

ê¸°ìˆ  ë¬¸ì„œ ë‚´ìš©:
Dynamic Taxonomy RAG ì‹œìŠ¤í…œì€ ê³„ì¸µì  ë¬¸ì„œ ë¶„ë¥˜ì™€ ê²€ìƒ‰ì„ ì œê³µí•©ë‹ˆë‹¤.
ì´ ì‹œìŠ¤í…œì€ ìë™ìœ¼ë¡œ ë¬¸ì„œë¥¼ ë¶„ë¥˜í•˜ê³  ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

Lorem ipsum dolor sit amet, consectetur adipiscing elit.
Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.
        """.strip()

        txt_file = self.temp_dir / "test_korean.txt"
        with open(txt_file, 'w', encoding='utf-8') as f:
            f.write(txt_content)
        files['txt'] = txt_file

        # 2. Markdown íŒŒì¼
        md_content = """
# í•œê¸€ ë§ˆí¬ë‹¤ìš´ ë¬¸ì„œ
## ê°œìš”
ì´ê²ƒì€ **í•œê¸€ ë§ˆí¬ë‹¤ìš´** í…ŒìŠ¤íŠ¸ íŒŒì¼ì…ë‹ˆë‹¤.

### ê°œì¸ì •ë³´ ì„¹ì…˜
- ì‚¬ìš©ì: ê¹€ì² ìˆ˜
- ì´ë©”ì¼: kim.cs@company.co.kr
- ì—°ë½ì²˜: 02-123-4567
- ì¹´ë“œë²ˆí˜¸: 5678-1234-9012-3456

### ê¸°ìˆ  ë‚´ìš©
```python
def process_document(text):
    return chunker.chunk(text)
```

> ì´ê²ƒì€ ì¸ìš©ë¬¸ì…ë‹ˆë‹¤.

### ëª©ë¡
1. ì²« ë²ˆì§¸ í•­ëª©
2. ë‘ ë²ˆì§¸ í•­ëª©
3. ì„¸ ë²ˆì§¸ í•­ëª©

[ë§í¬ ì˜ˆì‹œ](https://example.com)
        """.strip()

        md_file = self.temp_dir / "test_korean.md"
        with open(md_file, 'w', encoding='utf-8') as f:
            f.write(md_content)
        files['md'] = md_file

        # 3. HTML íŒŒì¼
        html_content = """
<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <title>í•œê¸€ HTML í…ŒìŠ¤íŠ¸</title>
</head>
<body>
    <h1>í•œê¸€ HTML ë¬¸ì„œ</h1>
    <p>ì´ê²ƒì€ í•œê¸€ HTML í…ŒìŠ¤íŠ¸ íŒŒì¼ì…ë‹ˆë‹¤.</p>

    <h2>ê°œì¸ì •ë³´</h2>
    <ul>
        <li>ì´ë¦„: ë°•ì˜í¬</li>
        <li>ì´ë©”ì¼: park@test.com</li>
        <li>ì „í™”: 010-9876-5432</li>
        <li>ì£¼ë¯¼ë²ˆí˜¸: 987654-2345678</li>
    </ul>

    <h2>ê¸°ìˆ  ë‚´ìš©</h2>
    <pre><code>
    async def embed_text(text):
        return await embedding_service.embed(text)
    </code></pre>

    <script>
        console.log("ìŠ¤í¬ë¦½íŠ¸ëŠ” ì œê±°ë©ë‹ˆë‹¤");
    </script>
</body>
</html>
        """.strip()

        html_file = self.temp_dir / "test_korean.html"
        with open(html_file, 'w', encoding='utf-8') as f:
            f.write(html_content)
        files['html'] = html_file

        # 4. CSV íŒŒì¼
        csv_content = [
            ['ì´ë¦„', 'ì´ë©”ì¼', 'ì „í™”ë²ˆí˜¸', 'ë¶€ì„œ'],
            ['ê¹€ë¯¼ìˆ˜', 'kim@company.com', '010-1111-2222', 'ê°œë°œíŒ€'],
            ['ì´ì˜í¬', 'lee@company.com', '010-3333-4444', 'ë§ˆì¼€íŒ…íŒ€'],
            ['ë°•ì² ìˆ˜', 'park@company.com', '010-5555-6666', 'ì˜ì—…íŒ€'],
            ['ê°œì¸ì •ë³´', 'private@secret.com', '010-7777-8888', 'ê¸°ë°€ë¶€ì„œ']
        ]

        csv_file = self.temp_dir / "test_korean.csv"
        with open(csv_file, 'w', encoding='utf-8', newline='') as f:
            writer = csv.writer(f)
            writer.writerows(csv_content)
        files['csv'] = csv_file

        # 5. JSON íŒŒì¼
        json_content = {
            "title": "í•œê¸€ JSON ë¬¸ì„œ",
            "description": "JSON í¬ë§· í…ŒìŠ¤íŠ¸",
            "users": [
                {
                    "name": "í™ê¸¸ë™",
                    "email": "hong@example.org",
                    "phone": "010-1234-0000",
                    "ssn": "123456-1111111"
                },
                {
                    "name": "ê¹€ì˜ìˆ˜",
                    "email": "kim@test.org",
                    "phone": "010-5678-0000",
                    "credit_card": "1111-2222-3333-4444"
                }
            ],
            "content": {
                "korean": "í•œê¸€ ì½˜í…ì¸ ì…ë‹ˆë‹¤.",
                "english": "This is English content.",
                "technical": "RAG ì‹œìŠ¤í…œì˜ ì„ë² ë”© ë²¡í„°ëŠ” 1536ì°¨ì›ì…ë‹ˆë‹¤."
            }
        }

        json_file = self.temp_dir / "test_korean.json"
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(json_content, f, ensure_ascii=False, indent=2)
        files['json'] = json_file

        # 6. PDF íŒŒì¼ ìƒì„± (reportlab ì‚¬ìš©)
        await self._create_pdf_file(files)

        # 7. DOCX íŒŒì¼ ìƒì„±
        await self._create_docx_file(files)

        # 8. ì†ìƒëœ íŒŒì¼ (ì˜¤ë¥˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ìš©)
        corrupted_file = self.temp_dir / "corrupted.pdf"
        with open(corrupted_file, 'wb') as f:
            f.write(b"This is not a valid PDF file content")
        files['corrupted'] = corrupted_file

        # 9. ë¹ˆ íŒŒì¼
        empty_file = self.temp_dir / "empty.txt"
        empty_file.touch()
        files['empty'] = empty_file

        # 10. ëŒ€ìš©ëŸ‰ íŒŒì¼ (ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ìš©)
        large_content = "í•œê¸€ ëŒ€ìš©ëŸ‰ í…ŒìŠ¤íŠ¸ ì½˜í…ì¸ ì…ë‹ˆë‹¤. " * 10000
        large_file = self.temp_dir / "large_test.txt"
        with open(large_file, 'w', encoding='utf-8') as f:
            f.write(large_content)
        files['large'] = large_file

        logger.info(f"ì´ {len(files)}ê°œì˜ í…ŒìŠ¤íŠ¸ íŒŒì¼ ìƒì„± ì™„ë£Œ")
        return files

    async def _create_pdf_file(self, files: Dict[str, Path]):
        """PDF íŒŒì¼ ìƒì„±"""
        try:
            # í•œê¸€ í°íŠ¸ ë“±ë¡ ì‹œë„
            try:
                # Windows ì‹œìŠ¤í…œ í°íŠ¸ ì‚¬ìš©
                pdfmetrics.registerFont(TTFont('Malgun', 'malgun.ttf'))
                font_name = 'Malgun'
            except:
                try:
                    # ëŒ€ì²´ í°íŠ¸
                    pdfmetrics.registerFont(TTFont('Nanum', 'NanumGothic.ttf'))
                    font_name = 'Nanum'
                except:
                    # ê¸°ë³¸ í°íŠ¸ ì‚¬ìš© (í•œê¸€ ê¹¨ì§ ê°€ëŠ¥)
                    font_name = 'Helvetica'

            pdf_file = self.temp_dir / "test_korean.pdf"
            c = canvas.Canvas(str(pdf_file), pagesize=letter)

            # PDF ë©”íƒ€ë°ì´í„° ì„¤ì •
            c.setTitle("í•œê¸€ PDF í…ŒìŠ¤íŠ¸ ë¬¸ì„œ")
            c.setAuthor("í…ŒìŠ¤íŠ¸ ì‘ì„±ì")
            c.setSubject("PDF íŒŒì‹± í…ŒìŠ¤íŠ¸")

            y = 750
            c.setFont(font_name, 16)
            c.drawString(50, y, "í•œê¸€ PDF í…ŒìŠ¤íŠ¸ ë¬¸ì„œ")

            y -= 30
            c.setFont(font_name, 12)
            content_lines = [
                "ì´ê²ƒì€ PDF íŒŒì‹± í…ŒìŠ¤íŠ¸ìš© ë¬¸ì„œì…ë‹ˆë‹¤.",
                "",
                "ê°œì¸ì •ë³´ í…ŒìŠ¤íŠ¸:",
                "- ì´ë©”ì¼: pdf@test.com",
                "- ì „í™”: 010-1111-0000",
                "- ì£¼ë¯¼ë²ˆí˜¸: 111111-2222222",
                "",
                "ê¸°ìˆ  ë‚´ìš©:",
                "PDF ë¬¸ì„œëŠ” ë³µì¡í•œ ë ˆì´ì•„ì›ƒì„ ê°€ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
                "í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œ ì •í™•ì„±ì´ ì¤‘ìš”í•©ë‹ˆë‹¤.",
                "",
                "ì˜ì–´ ë‚´ìš©:",
                "This is English content in the PDF.",
                "Mixed language support is important.",
            ]

            for line in content_lines:
                if y < 50:  # ìƒˆ í˜ì´ì§€
                    c.showPage()
                    y = 750
                    c.setFont(font_name, 12)

                try:
                    c.drawString(50, y, line)
                except:
                    # í•œê¸€ í°íŠ¸ ì‹¤íŒ¨ ì‹œ ì˜ì–´ë§Œ
                    if line.encode('ascii', errors='ignore').decode('ascii'):
                        c.drawString(50, y, line.encode('ascii', errors='ignore').decode('ascii'))
                y -= 20

            c.save()
            files['pdf'] = pdf_file

        except Exception as e:
            logger.warning(f"PDF íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}")
            # ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ê¸°ë°˜ PDF ìƒì„±
            pdf_file = self.temp_dir / "test_simple.pdf"
            c = canvas.Canvas(str(pdf_file), pagesize=letter)
            c.setFont('Helvetica', 12)
            c.drawString(50, 750, "Simple PDF Test Document")
            c.drawString(50, 730, "Email: simple@test.com")
            c.drawString(50, 710, "Phone: 010-0000-0000")
            c.save()
            files['pdf'] = pdf_file

    async def _create_docx_file(self, files: Dict[str, Path]):
        """DOCX íŒŒì¼ ìƒì„±"""
        try:
            docx_file = self.temp_dir / "test_korean.docx"
            doc = docx.Document()

            # ë©”íƒ€ë°ì´í„° ì„¤ì •
            core_props = doc.core_properties
            core_props.title = "í•œê¸€ DOCX í…ŒìŠ¤íŠ¸ ë¬¸ì„œ"
            core_props.author = "í…ŒìŠ¤íŠ¸ ì‘ì„±ì"
            core_props.subject = "DOCX íŒŒì‹± í…ŒìŠ¤íŠ¸"
            core_props.created = datetime.now()

            # ì œëª©
            title = doc.add_heading('í•œê¸€ DOCX í…ŒìŠ¤íŠ¸ ë¬¸ì„œ', 0)

            # ë‚´ìš©
            doc.add_paragraph('ì´ê²ƒì€ DOCX íŒŒì‹± í…ŒìŠ¤íŠ¸ìš© ë¬¸ì„œì…ë‹ˆë‹¤.')

            # ê°œì¸ì •ë³´ ì„¹ì…˜
            doc.add_heading('ê°œì¸ì •ë³´ í…ŒìŠ¤íŠ¸', level=1)
            pii_para = doc.add_paragraph()
            pii_para.add_run('ì´ë©”ì¼: ').bold = True
            pii_para.add_run('docx@test.com')
            pii_para.add_run('\nì „í™”ë²ˆí˜¸: ').bold = True
            pii_para.add_run('010-2222-0000')
            pii_para.add_run('\nì£¼ë¯¼ë²ˆí˜¸: ').bold = True
            pii_para.add_run('222222-3333333')

            # ê¸°ìˆ  ë‚´ìš©
            doc.add_heading('ê¸°ìˆ  ë‚´ìš©', level=1)
            doc.add_paragraph('DOCX ë¬¸ì„œëŠ” êµ¬ì¡°í™”ëœ ì½˜í…ì¸ ë¥¼ í¬í•¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.')
            doc.add_paragraph('í‘œ, ì´ë¯¸ì§€, ìŠ¤íƒ€ì¼ ë“±ì„ ì§€ì›í•©ë‹ˆë‹¤.')

            # í‘œ ì¶”ê°€
            table = doc.add_table(rows=1, cols=3)
            hdr_cells = table.rows[0].cells
            hdr_cells[0].text = 'ì´ë¦„'
            hdr_cells[1].text = 'ì´ë©”ì¼'
            hdr_cells[2].text = 'ë¶€ì„œ'

            row_cells = table.add_row().cells
            row_cells[0].text = 'ê¹€í…ŒìŠ¤íŠ¸'
            row_cells[1].text = 'test@docx.com'
            row_cells[2].text = 'ê°œë°œíŒ€'

            doc.save(str(docx_file))
            files['docx'] = docx_file

        except Exception as e:
            logger.warning(f"DOCX íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}")

    async def test_file_format_support(self, files: Dict[str, Path]) -> Dict[str, Any]:
        """íŒŒì¼ í¬ë§· ì§€ì› í…ŒìŠ¤íŠ¸"""
        logger.info("=== íŒŒì¼ í¬ë§· ì§€ì› í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
        results = {}

        for fmt, file_path in files.items():
            if fmt in ['corrupted', 'empty']:
                continue

            start_time = time.time()
            self.monitor_memory()

            try:
                parser = self.parser_factory.get_parser(file_path)
                if not parser:
                    results[fmt] = {
                        'success': False,
                        'error': 'No parser available',
                        'processing_time': 0
                    }
                    continue

                parsed_doc = await parser.parse(file_path)
                processing_time = time.time() - start_time

                results[fmt] = {
                    'success': True,
                    'text_length': len(parsed_doc.content),
                    'metadata_keys': list(parsed_doc.metadata.keys()),
                    'processing_time': processing_time,
                    'has_korean': any(ord(c) > 127 for c in parsed_doc.content[:100])
                }

                self.metrics.processing_times['parsing'].append(processing_time)
                self.metrics.total_characters += len(parsed_doc.content)

                logger.info(f"{fmt} íŒŒì‹± ì„±ê³µ: {len(parsed_doc.content)} ë¬¸ì, {processing_time:.3f}ì´ˆ")

            except Exception as e:
                results[fmt] = {
                    'success': False,
                    'error': str(e),
                    'processing_time': time.time() - start_time
                }
                logger.error(f"{fmt} íŒŒì‹± ì‹¤íŒ¨: {e}")
                self.metrics.errors.append({
                    'stage': 'parsing',
                    'file_format': fmt,
                    'error': str(e),
                    'traceback': traceback.format_exc()
                })

        return results

    async def test_text_extraction_and_chunking(self, files: Dict[str, Path]) -> Dict[str, Any]:
        """í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ì²­í‚¹ í…ŒìŠ¤íŠ¸"""
        logger.info("=== í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ì²­í‚¹ í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
        results = {}

        for fmt, file_path in files.items():
            if fmt in ['corrupted', 'empty']:
                continue

            start_time = time.time()
            self.monitor_memory()

            try:
                # íŒŒì‹±
                parser = self.parser_factory.get_parser(file_path)
                if not parser:
                    continue

                parsed_doc = await parser.parse(file_path)

                # ì²­í‚¹
                chunks = await self.chunker.chunk_document(parsed_doc)
                processing_time = time.time() - start_time

                results[fmt] = {
                    'success': True,
                    'original_length': len(parsed_doc.content),
                    'chunk_count': len(chunks),
                    'chunk_sizes': [len(chunk.content) for chunk in chunks],
                    'average_chunk_size': sum(len(chunk.content) for chunk in chunks) / len(chunks) if chunks else 0,
                    'processing_time': processing_time,
                    'overlap_check': self._check_chunk_overlap(chunks)
                }

                self.metrics.processing_times['chunking'].append(processing_time)
                self.metrics.total_chunks += len(chunks)

                logger.info(f"{fmt} ì²­í‚¹ ì„±ê³µ: {len(chunks)}ê°œ ì²­í¬, {processing_time:.3f}ì´ˆ")

            except Exception as e:
                results[fmt] = {
                    'success': False,
                    'error': str(e),
                    'processing_time': time.time() - start_time
                }
                logger.error(f"{fmt} ì²­í‚¹ ì‹¤íŒ¨: {e}")
                self.metrics.errors.append({
                    'stage': 'chunking',
                    'file_format': fmt,
                    'error': str(e),
                    'traceback': traceback.format_exc()
                })

        return results

    def _check_chunk_overlap(self, chunks: List[DocumentChunk]) -> Dict[str, Any]:
        """ì²­í¬ ì˜¤ë²„ë© ê²€ì‚¬"""
        if len(chunks) < 2:
            return {'has_overlap': False, 'overlap_count': 0}

        overlap_count = 0
        for i in range(len(chunks) - 1):
            current_end = chunks[i].content[-50:]  # ë§ˆì§€ë§‰ 50ë¬¸ì
            next_start = chunks[i + 1].content[:50]  # ì²˜ìŒ 50ë¬¸ì

            # ê°„ë‹¨í•œ ì˜¤ë²„ë© ì²´í¬
            if any(word in next_start for word in current_end.split() if len(word) > 3):
                overlap_count += 1

        return {
            'has_overlap': overlap_count > 0,
            'overlap_count': overlap_count,
            'overlap_ratio': overlap_count / (len(chunks) - 1) if len(chunks) > 1 else 0
        }

    async def test_metadata_extraction(self, files: Dict[str, Path]) -> Dict[str, Any]:
        """ë©”íƒ€ë°ì´í„° ì¶”ì¶œ í…ŒìŠ¤íŠ¸"""
        logger.info("=== ë©”íƒ€ë°ì´í„° ì¶”ì¶œ í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
        results = {}

        for fmt, file_path in files.items():
            if fmt in ['corrupted', 'empty']:
                continue

            start_time = time.time()

            try:
                parser = self.parser_factory.get_parser(file_path)
                if not parser:
                    continue

                parsed_doc = await parser.parse(file_path)
                processing_time = time.time() - start_time

                # ë©”íƒ€ë°ì´í„° ê²€ì¦
                metadata = parsed_doc.metadata
                required_fields = ['file_name', 'file_size', 'created_at']
                optional_fields = ['title', 'author', 'subject', 'creator', 'modified_at']

                results[fmt] = {
                    'success': True,
                    'metadata': metadata,
                    'required_fields_present': {field: field in metadata for field in required_fields},
                    'optional_fields_present': {field: field in metadata for field in optional_fields},
                    'total_fields': len(metadata),
                    'processing_time': processing_time
                }

                logger.info(f"{fmt} ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì„±ê³µ: {len(metadata)}ê°œ í•„ë“œ")

            except Exception as e:
                results[fmt] = {
                    'success': False,
                    'error': str(e),
                    'processing_time': time.time() - start_time
                }
                logger.error(f"{fmt} ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}")

        return results

    async def test_pii_filtering(self, files: Dict[str, Path]) -> Dict[str, Any]:
        """PII í•„í„°ë§ í…ŒìŠ¤íŠ¸"""
        logger.info("=== PII í•„í„°ë§ í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
        results = {}

        # í…ŒìŠ¤íŠ¸í•  PII íŒ¨í„´
        test_patterns = {
            'email': ['hong@example.com', 'kim.cs@company.co.kr'],
            'phone': ['010-1234-5678', '02-123-4567'],
            'ssn': ['123456-1234567', '987654-2345678'],
            'credit_card': ['1234-5678-9012-3456', '5678-1234-9012-3456']
        }

        for fmt, file_path in files.items():
            if fmt in ['corrupted', 'empty']:
                continue

            start_time = time.time()
            self.monitor_memory()

            try:
                parser = self.parser_factory.get_parser(file_path)
                if not parser:
                    continue

                parsed_doc = await parser.parse(file_path)

                # PII í•„í„°ë§ í…ŒìŠ¤íŠ¸
                filter_result = await self.pii_filter.filter_text(
                    parsed_doc.content,
                    masking_strategy=MaskingStrategy.REDACT
                )

                processing_time = time.time() - start_time

                # PII íƒì§€ ì •í™•ì„± ê²€ì‚¬
                detected_types = [detection.pii_type for detection in filter_result.detections]

                results[fmt] = {
                    'success': True,
                    'original_length': len(parsed_doc.content),
                    'filtered_length': len(filter_result.filtered_text),
                    'detections_count': len(filter_result.detections),
                    'detected_types': detected_types,
                    'detections': [
                        {
                            'type': d.pii_type.value,
                            'confidence': d.confidence,
                            'start': d.start_pos,
                            'end': d.end_pos,
                            'original': d.original_text,
                            'masked': d.masked_text
                        } for d in filter_result.detections
                    ],
                    'processing_time': processing_time,
                    'accuracy_check': self._check_pii_accuracy(parsed_doc.content, filter_result, test_patterns)
                }

                self.metrics.processing_times['pii_filtering'].append(processing_time)
                self.metrics.pii_detections += len(filter_result.detections)

                logger.info(f"{fmt} PII í•„í„°ë§ ì„±ê³µ: {len(filter_result.detections)}ê°œ íƒì§€, {processing_time:.3f}ì´ˆ")

            except Exception as e:
                results[fmt] = {
                    'success': False,
                    'error': str(e),
                    'processing_time': time.time() - start_time
                }
                logger.error(f"{fmt} PII í•„í„°ë§ ì‹¤íŒ¨: {e}")
                self.metrics.errors.append({
                    'stage': 'pii_filtering',
                    'file_format': fmt,
                    'error': str(e),
                    'traceback': traceback.format_exc()
                })

        return results

    def _check_pii_accuracy(self, original_text: str, filter_result: PIIFilterResult,
                           test_patterns: Dict[str, List[str]]) -> Dict[str, Any]:
        """PII íƒì§€ ì •í™•ì„± ê²€ì‚¬"""
        accuracy = {}

        for pii_type, patterns in test_patterns.items():
            detected_count = 0
            total_count = 0

            for pattern in patterns:
                total_count += original_text.count(pattern)

                # í•´ë‹¹ íŒ¨í„´ì´ íƒì§€ë˜ì—ˆëŠ”ì§€ í™•ì¸
                for detection in filter_result.detections:
                    if pattern in detection.original_text:
                        detected_count += 1
                        break

            if total_count > 0:
                accuracy[pii_type] = {
                    'detected': detected_count,
                    'total': total_count,
                    'accuracy': detected_count / total_count
                }

        return accuracy

    async def test_embedding_generation(self, files: Dict[str, Path]) -> Dict[str, Any]:
        """ì„ë² ë”© ìƒì„± í…ŒìŠ¤íŠ¸"""
        logger.info("=== ì„ë² ë”© ìƒì„± í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
        results = {}

        for fmt, file_path in files.items():
            if fmt in ['corrupted', 'empty', 'large']:  # ëŒ€ìš©ëŸ‰ íŒŒì¼ì€ ì„ë² ë”© í…ŒìŠ¤íŠ¸ì—ì„œ ì œì™¸
                continue

            start_time = time.time()
            self.monitor_memory()

            try:
                parser = self.parser_factory.get_parser(file_path)
                if not parser:
                    continue

                parsed_doc = await parser.parse(file_path)
                chunks = await self.chunker.chunk_document(parsed_doc)

                # ì„ë² ë”© ìƒì„± (ìµœëŒ€ 3ê°œ ì²­í¬ë¡œ ì œí•œ)
                test_chunks = chunks[:3]
                embeddings = []

                for chunk in test_chunks:
                    try:
                        embedding = await self.embedding_service.embed(chunk.content)
                        embeddings.append({
                            'dimension': len(embedding),
                            'norm': sum(x*x for x in embedding) ** 0.5,
                            'sample_values': embedding[:5]  # ì²˜ìŒ 5ê°œ ê°’ë§Œ
                        })
                    except Exception as e:
                        logger.warning(f"ì„ë² ë”© ìƒì„± ì‹¤íŒ¨ (ì²­í¬): {e}")
                        embeddings.append({'error': str(e)})

                processing_time = time.time() - start_time

                results[fmt] = {
                    'success': True,
                    'chunk_count': len(chunks),
                    'tested_chunks': len(test_chunks),
                    'successful_embeddings': len([e for e in embeddings if 'error' not in e]),
                    'embeddings': embeddings,
                    'processing_time': processing_time
                }

                self.metrics.processing_times['embedding'].append(processing_time)
                self.metrics.embeddings_generated += len([e for e in embeddings if 'error' not in e])

                logger.info(f"{fmt} ì„ë² ë”© ìƒì„± ì„±ê³µ: {len([e for e in embeddings if 'error' not in e])}/{len(test_chunks)}ê°œ")

            except Exception as e:
                results[fmt] = {
                    'success': False,
                    'error': str(e),
                    'processing_time': time.time() - start_time
                }
                logger.error(f"{fmt} ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
                self.metrics.errors.append({
                    'stage': 'embedding',
                    'file_format': fmt,
                    'error': str(e),
                    'traceback': traceback.format_exc()
                })

        return results

    async def test_database_storage(self, files: Dict[str, Path]) -> Dict[str, Any]:
        """ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ í…ŒìŠ¤íŠ¸"""
        logger.info("=== ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
        results = {}

        # í…ŒìŠ¤íŠ¸ìš© íŒŒì¼ í•˜ë‚˜ë§Œ ì„ íƒ (TXT)
        test_file = files.get('txt')
        if not test_file:
            return {'error': 'No test file available'}

        start_time = time.time()
        self.monitor_memory()

        try:
            # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
            processing_result = await self.pipeline.process_document(test_file)
            processing_time = time.time() - start_time

            results['full_pipeline'] = {
                'success': processing_result.status == ProcessingStatus.COMPLETED,
                'status': processing_result.status.value,
                'document_id': processing_result.document_id,
                'chunk_count': len(processing_result.chunks) if processing_result.chunks else 0,
                'embedding_count': len(processing_result.embeddings) if processing_result.embeddings else 0,
                'processing_time': processing_time,
                'error': processing_result.error
            }

            # ë°ì´í„°ë² ì´ìŠ¤ ê²€ì¦
            if processing_result.status == ProcessingStatus.COMPLETED and processing_result.document_id:
                verification = await self._verify_database_storage(processing_result.document_id)
                results['database_verification'] = verification

            self.metrics.processing_times['database_storage'].append(processing_time)

            logger.info(f"ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {processing_result.status.value}")

        except Exception as e:
            results['full_pipeline'] = {
                'success': False,
                'error': str(e),
                'processing_time': time.time() - start_time
            }
            logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            self.metrics.errors.append({
                'stage': 'database_storage',
                'error': str(e),
                'traceback': traceback.format_exc()
            })

        return results

    async def _verify_database_storage(self, document_id: str) -> Dict[str, Any]:
        """ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ê²€ì¦"""
        try:
            async with db_manager.get_session() as session:
                # ë¬¸ì„œ í™•ì¸
                doc = await session.get(Document, document_id)
                if not doc:
                    return {'success': False, 'error': 'Document not found in database'}

                # ì²­í¬ í™•ì¸
                from sqlalchemy import select
                chunk_stmt = select(DBChunk).where(DBChunk.document_id == document_id)
                chunk_result = await session.execute(chunk_stmt)
                chunks = chunk_result.scalars().all()

                # ì„ë² ë”© í™•ì¸
                embedding_stmt = select(Embedding).where(Embedding.document_id == document_id)
                embedding_result = await session.execute(embedding_stmt)
                embeddings = embedding_result.scalars().all()

                return {
                    'success': True,
                    'document_exists': True,
                    'document_title': doc.title,
                    'chunk_count': len(chunks),
                    'embedding_count': len(embeddings),
                    'metadata_keys': list(doc.metadata.keys()) if doc.metadata else []
                }

        except Exception as e:
            return {'success': False, 'error': str(e)}

    async def test_error_handling(self, files: Dict[str, Path]) -> Dict[str, Any]:
        """ì˜¤ë¥˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        logger.info("=== ì˜¤ë¥˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
        results = {}

        # 1. ì†ìƒëœ íŒŒì¼ í…ŒìŠ¤íŠ¸
        corrupted_file = files.get('corrupted')
        if corrupted_file:
            start_time = time.time()
            try:
                processing_result = await self.pipeline.process_document(corrupted_file)
                results['corrupted_file'] = {
                    'handled_gracefully': processing_result.status == ProcessingStatus.FAILED,
                    'status': processing_result.status.value,
                    'error_message': processing_result.error,
                    'processing_time': time.time() - start_time
                }
            except Exception as e:
                results['corrupted_file'] = {
                    'handled_gracefully': False,
                    'unhandled_exception': str(e),
                    'processing_time': time.time() - start_time
                }

        # 2. ë¹ˆ íŒŒì¼ í…ŒìŠ¤íŠ¸
        empty_file = files.get('empty')
        if empty_file:
            start_time = time.time()
            try:
                processing_result = await self.pipeline.process_document(empty_file)
                results['empty_file'] = {
                    'handled_gracefully': processing_result.status in [ProcessingStatus.FAILED, ProcessingStatus.SKIPPED],
                    'status': processing_result.status.value,
                    'error_message': processing_result.error,
                    'processing_time': time.time() - start_time
                }
            except Exception as e:
                results['empty_file'] = {
                    'handled_gracefully': False,
                    'unhandled_exception': str(e),
                    'processing_time': time.time() - start_time
                }

        # 3. ì¡´ì¬í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í…ŒìŠ¤íŠ¸
        nonexistent_file = self.temp_dir / "nonexistent.txt"
        start_time = time.time()
        try:
            processing_result = await self.pipeline.process_document(nonexistent_file)
            results['nonexistent_file'] = {
                'handled_gracefully': processing_result.status == ProcessingStatus.FAILED,
                'status': processing_result.status.value,
                'error_message': processing_result.error,
                'processing_time': time.time() - start_time
            }
        except Exception as e:
            results['nonexistent_file'] = {
                'handled_gracefully': False,
                'unhandled_exception': str(e),
                'processing_time': time.time() - start_time
            }

        return results

    async def test_batch_processing(self, files: Dict[str, Path]) -> Dict[str, Any]:
        """ë°°ì¹˜ ì²˜ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        logger.info("=== ë°°ì¹˜ ì²˜ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")

        # ì •ìƒì ì¸ íŒŒì¼ë“¤ë§Œ ì„ íƒ
        valid_files = [files[fmt] for fmt in ['txt', 'md', 'html', 'csv', 'json'] if fmt in files]

        if not valid_files:
            return {'error': 'No valid files for batch processing test'}

        start_time = time.time()
        initial_memory = self.monitor_memory()

        try:
            # ìˆœì°¨ ì²˜ë¦¬
            sequential_start = time.time()
            sequential_results = []
            for file_path in valid_files:
                result = await self.pipeline.process_document(file_path)
                sequential_results.append(result)
            sequential_time = time.time() - sequential_start

            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì²´í¬
            peak_memory = max(self.metrics.memory_usage[-10:]) if self.metrics.memory_usage else initial_memory

            # ë³‘ë ¬ ì²˜ë¦¬ (ì œí•œëœ ë™ì‹œì„±)
            parallel_start = time.time()
            semaphore = asyncio.Semaphore(3)  # ìµœëŒ€ 3ê°œ ë™ì‹œ ì²˜ë¦¬

            async def process_with_semaphore(file_path):
                async with semaphore:
                    return await self.pipeline.process_document(file_path)

            parallel_tasks = [process_with_semaphore(file_path) for file_path in valid_files]
            parallel_results = await asyncio.gather(*parallel_tasks, return_exceptions=True)
            parallel_time = time.time() - parallel_start

            # ê²°ê³¼ ë¶„ì„
            successful_sequential = sum(1 for r in sequential_results if r.status == ProcessingStatus.COMPLETED)
            successful_parallel = sum(1 for r in parallel_results if not isinstance(r, Exception) and r.status == ProcessingStatus.COMPLETED)

            total_time = time.time() - start_time

            results = {
                'success': True,
                'total_files': len(valid_files),
                'sequential_processing': {
                    'time': sequential_time,
                    'successful': successful_sequential,
                    'avg_time_per_file': sequential_time / len(valid_files)
                },
                'parallel_processing': {
                    'time': parallel_time,
                    'successful': successful_parallel,
                    'avg_time_per_file': parallel_time / len(valid_files),
                    'speedup_ratio': sequential_time / parallel_time if parallel_time > 0 else 0
                },
                'memory_usage': {
                    'initial_mb': initial_memory,
                    'peak_mb': peak_memory,
                    'increase_mb': peak_memory - initial_memory
                },
                'total_time': total_time
            }

            logger.info(f"ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ: ìˆœì°¨ {sequential_time:.3f}ì´ˆ, ë³‘ë ¬ {parallel_time:.3f}ì´ˆ")

        except Exception as e:
            results = {
                'success': False,
                'error': str(e),
                'total_time': time.time() - start_time
            }
            logger.error(f"ë°°ì¹˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

        return results

    def finalize_metrics(self):
        """ë©”íŠ¸ë¦­ ìµœì¢…í™”"""
        self.metrics.end_time = datetime.now()

        # ì„±ê³µë¥  ê³„ì‚°
        total_files = len([f for fmt, f in self.__dict__.get('test_files', {}).items() if fmt not in ['corrupted', 'empty']])
        successful_files = total_files - len([e for e in self.metrics.errors if e['stage'] != 'expected_failure'])

        self.metrics.total_files = total_files
        self.metrics.successful_files = successful_files
        self.metrics.failed_files = total_files - successful_files

    def generate_report(self, all_results: Dict[str, Any]) -> Dict[str, Any]:
        """ì¢…í•© í…ŒìŠ¤íŠ¸ ë³´ê³ ì„œ ìƒì„±"""
        self.finalize_metrics()

        report = {
            'summary': {
                'test_start_time': self.metrics.start_time.isoformat(),
                'test_end_time': self.metrics.end_time.isoformat(),
                'total_duration_seconds': self.metrics.duration,
                'total_files_tested': self.metrics.total_files,
                'successful_files': self.metrics.successful_files,
                'failed_files': self.metrics.failed_files,
                'success_rate_percent': self.metrics.success_rate,
                'total_chunks_created': self.metrics.total_chunks,
                'total_characters_processed': self.metrics.total_characters,
                'pii_detections_count': self.metrics.pii_detections,
                'embeddings_generated': self.metrics.embeddings_generated
            },
            'performance_metrics': {
                'average_processing_time': self.metrics.average_processing_time,
                'processing_times_by_stage': {
                    stage: {
                        'count': len(times),
                        'average': sum(times) / len(times) if times else 0,
                        'min': min(times) if times else 0,
                        'max': max(times) if times else 0
                    } for stage, times in self.metrics.processing_times.items()
                },
                'memory_usage': {
                    'samples': len(self.metrics.memory_usage),
                    'average_mb': sum(self.metrics.memory_usage) / len(self.metrics.memory_usage) if self.metrics.memory_usage else 0,
                    'peak_mb': max(self.metrics.memory_usage) if self.metrics.memory_usage else 0,
                    'min_mb': min(self.metrics.memory_usage) if self.metrics.memory_usage else 0
                }
            },
            'detailed_results': all_results,
            'error_analysis': {
                'total_errors': len(self.metrics.errors),
                'errors_by_stage': {},
                'errors_by_format': {},
                'error_details': self.metrics.errors[:10]  # ì²˜ìŒ 10ê°œ ì˜¤ë¥˜ë§Œ
            },
            'recommendations': self._generate_recommendations(all_results)
        }

        # ì˜¤ë¥˜ ë¶„ì„
        for error in self.metrics.errors:
            stage = error.get('stage', 'unknown')
            fmt = error.get('file_format', 'unknown')

            if stage not in report['error_analysis']['errors_by_stage']:
                report['error_analysis']['errors_by_stage'][stage] = 0
            report['error_analysis']['errors_by_stage'][stage] += 1

            if fmt not in report['error_analysis']['errors_by_format']:
                report['error_analysis']['errors_by_format'][fmt] = 0
            report['error_analysis']['errors_by_format'][fmt] += 1

        return report

    def _generate_recommendations(self, all_results: Dict[str, Any]) -> List[str]:
        """ê°œì„  ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []

        # ì„±ê³µë¥  ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        if self.metrics.success_rate < 90:
            recommendations.append(f"ì „ì²´ ì„±ê³µë¥ ì´ {self.metrics.success_rate:.1f}%ë¡œ ë‚®ìŠµë‹ˆë‹¤. ì˜¤ë¥˜ ì²˜ë¦¬ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.")

        # ì„±ëŠ¥ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        avg_time = self.metrics.average_processing_time
        if avg_time > 5.0:
            recommendations.append(f"í‰ê·  ì²˜ë¦¬ ì‹œê°„ì´ {avg_time:.2f}ì´ˆë¡œ ëŠë¦½ë‹ˆë‹¤. ì„±ëŠ¥ ìµœì í™”ë¥¼ ê³ ë ¤í•˜ì„¸ìš”.")

        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        if self.metrics.memory_usage:
            peak_memory = max(self.metrics.memory_usage)
            if peak_memory > 500:  # 500MB ì´ìƒ
                recommendations.append(f"ìµœëŒ€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ {peak_memory:.1f}MBì…ë‹ˆë‹¤. ë©”ëª¨ë¦¬ ìµœì í™”ê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

        # PII íƒì§€ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        pii_results = all_results.get('pii_filtering', {})
        low_accuracy_formats = []
        for fmt, result in pii_results.items():
            if result.get('success') and 'accuracy_check' in result:
                accuracy = result['accuracy_check']
                for pii_type, acc_data in accuracy.items():
                    if acc_data.get('accuracy', 1.0) < 0.8:
                        low_accuracy_formats.append(f"{fmt}-{pii_type}")

        if low_accuracy_formats:
            recommendations.append(f"PII íƒì§€ ì •í™•ë„ê°€ ë‚®ì€ í˜•íƒœ: {', '.join(low_accuracy_formats)}. PII í•„í„° ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.")

        # ì²­í‚¹ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        chunking_results = all_results.get('text_extraction_and_chunking', {})
        large_chunks = []
        for fmt, result in chunking_results.items():
            if result.get('success') and result.get('average_chunk_size', 0) > 2000:
                large_chunks.append(fmt)

        if large_chunks:
            recommendations.append(f"ì²­í¬ í¬ê¸°ê°€ í° í˜•íƒœ: {', '.join(large_chunks)}. ì²­í‚¹ ì „ëµ ì¡°ì •ì„ ê³ ë ¤í•˜ì„¸ìš”.")

        if not recommendations:
            recommendations.append("ëª¨ë“  í…ŒìŠ¤íŠ¸ê°€ ì–‘í˜¸í•˜ê²Œ í†µê³¼í–ˆìŠµë‹ˆë‹¤. í˜„ì¬ ì„¤ì •ì„ ìœ ì§€í•˜ì„¸ìš”.")

        return recommendations

    async def run_all_tests(self) -> Dict[str, Any]:
        """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        logger.info("ğŸš€ ì¢…í•©ì ì¸ ë¬¸ì„œ ìˆ˜ì§‘ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì‹œì‘")

        all_results = {}

        try:
            # 1. í…ŒìŠ¤íŠ¸ íŒŒì¼ ìƒì„±
            logger.info("1ï¸âƒ£ í…ŒìŠ¤íŠ¸ íŒŒì¼ ìƒì„±")
            test_files = await self.create_test_files()
            self.test_files = test_files
            all_results['file_creation'] = {
                'success': True,
                'files_created': len(test_files),
                'file_types': list(test_files.keys())
            }

            # 2. íŒŒì¼ í¬ë§· ì§€ì› í…ŒìŠ¤íŠ¸
            logger.info("2ï¸âƒ£ íŒŒì¼ í¬ë§· ì§€ì› í…ŒìŠ¤íŠ¸")
            all_results['file_format_support'] = await self.test_file_format_support(test_files)

            # 3. í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ì²­í‚¹ í…ŒìŠ¤íŠ¸
            logger.info("3ï¸âƒ£ í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ì²­í‚¹ í…ŒìŠ¤íŠ¸")
            all_results['text_extraction_and_chunking'] = await self.test_text_extraction_and_chunking(test_files)

            # 4. ë©”íƒ€ë°ì´í„° ì¶”ì¶œ í…ŒìŠ¤íŠ¸
            logger.info("4ï¸âƒ£ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ í…ŒìŠ¤íŠ¸")
            all_results['metadata_extraction'] = await self.test_metadata_extraction(test_files)

            # 5. PII í•„í„°ë§ í…ŒìŠ¤íŠ¸
            logger.info("5ï¸âƒ£ PII í•„í„°ë§ í…ŒìŠ¤íŠ¸")
            all_results['pii_filtering'] = await self.test_pii_filtering(test_files)

            # 6. ì„ë² ë”© ìƒì„± í…ŒìŠ¤íŠ¸
            logger.info("6ï¸âƒ£ ì„ë² ë”© ìƒì„± í…ŒìŠ¤íŠ¸")
            all_results['embedding_generation'] = await self.test_embedding_generation(test_files)

            # 7. ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ í…ŒìŠ¤íŠ¸
            logger.info("7ï¸âƒ£ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ í…ŒìŠ¤íŠ¸")
            all_results['database_storage'] = await self.test_database_storage(test_files)

            # 8. ì˜¤ë¥˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
            logger.info("8ï¸âƒ£ ì˜¤ë¥˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸")
            all_results['error_handling'] = await self.test_error_handling(test_files)

            # 9. ë°°ì¹˜ ì²˜ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
            logger.info("9ï¸âƒ£ ë°°ì¹˜ ì²˜ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")
            all_results['batch_processing'] = await self.test_batch_processing(test_files)

            logger.info("âœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ")

        except Exception as e:
            logger.error(f"í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
            all_results['fatal_error'] = {
                'error': str(e),
                'traceback': traceback.format_exc()
            }

        return all_results

async def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    tester = DocumentIngestionTester()

    try:
        # ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        results = await tester.run_all_tests()

        # ë³´ê³ ì„œ ìƒì„±
        report = tester.generate_report(results)

        # ê²°ê³¼ ì €ì¥
        report_file = Path("document_ingestion_test_report.json")
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)

        # ìš”ì•½ ì¶œë ¥
        print("\n" + "="*80)
        print("ğŸ“Š ë¬¸ì„œ ìˆ˜ì§‘ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
        print("="*80)

        summary = report['summary']
        print(f"ğŸ• í…ŒìŠ¤íŠ¸ ì‹œê°„: {summary['total_duration_seconds']:.2f}ì´ˆ")
        print(f"ğŸ“ ì²˜ë¦¬ëœ íŒŒì¼: {summary['total_files_tested']}ê°œ")
        print(f"âœ… ì„±ê³µ: {summary['successful_files']}ê°œ")
        print(f"âŒ ì‹¤íŒ¨: {summary['failed_files']}ê°œ")
        print(f"ğŸ“ˆ ì„±ê³µë¥ : {summary['success_rate_percent']:.1f}%")
        print(f"ğŸ“„ ìƒì„±ëœ ì²­í¬: {summary['total_chunks_created']}ê°œ")
        print(f"ğŸ”¤ ì²˜ë¦¬ëœ ë¬¸ì: {summary['total_characters_processed']:,}ê°œ")
        print(f"ğŸ›¡ï¸ PII íƒì§€: {summary['pii_detections_count']}ê°œ")
        print(f"ğŸ§  ì„ë² ë”© ìƒì„±: {summary['embeddings_generated']}ê°œ")

        print("\nâš¡ ì„±ëŠ¥ ë©”íŠ¸ë¦­:")
        perf = report['performance_metrics']
        print(f"í‰ê·  ì²˜ë¦¬ ì‹œê°„: {perf['average_processing_time']:.3f}ì´ˆ")
        print(f"ìµœëŒ€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {perf['memory_usage']['peak_mb']:.1f}MB")

        if report['recommendations']:
            print("\nğŸ’¡ ê¶Œì¥ì‚¬í•­:")
            for i, rec in enumerate(report['recommendations'], 1):
                print(f"{i}. {rec}")

        print(f"\nğŸ“‹ ìƒì„¸ ë³´ê³ ì„œ: {report_file.absolute()}")
        print("="*80)

        # ì„±ê³µ ì—¬ë¶€ ë°˜í™˜
        success_rate = summary['success_rate_percent']
        if success_rate >= 90:
            print("ğŸ‰ í…ŒìŠ¤íŠ¸ ì„±ê³µ! íŒŒì´í”„ë¼ì¸ì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤.")
            return 0
        elif success_rate >= 70:
            print("âš ï¸ í…ŒìŠ¤íŠ¸ ë¶€ë¶„ ì„±ê³µ. ì¼ë¶€ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            return 1
        else:
            print("âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨. ì‹¬ê°í•œ ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.")
            return 2

    except Exception as e:
        logger.error(f"í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        print(f"\nğŸ’¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ: {e}")
        return 3

    finally:
        # ì •ë¦¬
        if hasattr(tester, 'temp_dir') and tester.temp_dir.exists():
            shutil.rmtree(tester.temp_dir, ignore_errors=True)

if __name__ == "__main__":
    # ì´ë²¤íŠ¸ ë£¨í”„ ì‹¤í–‰
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
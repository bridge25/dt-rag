#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SQLite Fallback Database Testing Script with UTF-8 Support
Dynamic Taxonomy RAG v1.8.1 - Local Database Testing without PostgreSQL
"""
import os
import sys
import asyncio
import logging
from typing import Dict, Any, List
from pathlib import Path
import tempfile

# UTF-8 encoding setup
if sys.platform == "win32":
    import codecs
    sys.stdout = codecs.getwriter("utf-8")(sys.stdout.detach())
    sys.stderr = codecs.getwriter("utf-8")(sys.stderr.detach())

# Add project root to path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "apps" / "api"))

# Configure logging with UTF-8
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('test_sqlite.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

async def test_sqlite_database():
    """Test SQLite database functionality"""
    try:
        logger.info("ğŸ” SQLite ë°ì´í„°ë² ì´ìŠ¤ í…ŒìŠ¤íŠ¸ ì‹œì‘...")

        # Create temporary SQLite database
        temp_db_path = tempfile.mktemp(suffix='.db')
        sqlite_url = f"sqlite+aiosqlite:///{temp_db_path}"

        # Override database URL for testing
        os.environ["DATABASE_URL"] = sqlite_url
        logger.info(f"âœ… í…ŒìŠ¤íŠ¸ SQLite DB ê²½ë¡œ: {temp_db_path}")

        # Import after setting environment variable
        from sqlalchemy.ext.asyncio import create_async_engine, async_sessionmaker, AsyncSession
        from sqlalchemy.orm import declarative_base, Mapped, mapped_column
        from sqlalchemy import Column, String, Integer, Float, DateTime, Boolean, Text, JSON, text
        from datetime import datetime
        import uuid

        # Create test models
        Base = declarative_base()

        class TestDocument(Base):
            __tablename__ = "test_documents"

            id: Mapped[str] = mapped_column(String, primary_key=True)
            title: Mapped[str] = mapped_column(String, nullable=False)
            content: Mapped[str] = mapped_column(Text, nullable=False)
            doc_metadata: Mapped[Dict[str, Any]] = mapped_column(JSON, default=dict)
            created_at: Mapped[datetime] = mapped_column(DateTime, default=datetime.utcnow)

        class TestChunk(Base):
            __tablename__ = "test_chunks"

            id: Mapped[str] = mapped_column(String, primary_key=True)
            document_id: Mapped[str] = mapped_column(String, nullable=False)
            content: Mapped[str] = mapped_column(Text, nullable=False)
            chunk_metadata: Mapped[Dict[str, Any]] = mapped_column(JSON, default=dict)
            created_at: Mapped[datetime] = mapped_column(DateTime, default=datetime.utcnow)

        # Create engine and session
        engine = create_async_engine(sqlite_url, echo=False)
        async_session = async_sessionmaker(engine, class_=AsyncSession, expire_on_commit=False)

        # Test table creation
        async with engine.begin() as conn:
            await conn.run_sync(Base.metadata.create_all)
        logger.info("âœ… SQLite í…Œì´ë¸” ìƒì„± ì™„ë£Œ")

        # Test CRUD operations
        async with async_session() as session:
            # Create test document
            test_doc = TestDocument(
                id=str(uuid.uuid4()),
                title="í…ŒìŠ¤íŠ¸ ë¬¸ì„œ",
                content="ì´ê²ƒì€ UTF-8 ì¸ì½”ë”© í…ŒìŠ¤íŠ¸ ë¬¸ì„œì…ë‹ˆë‹¤. í•œê¸€ì´ ì •ìƒì ìœ¼ë¡œ ì €ì¥ë˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.",
                doc_metadata={"source": "test", "language": "ko"},
                created_at=datetime.utcnow()
            )

            session.add(test_doc)
            await session.commit()
            logger.info(f"âœ… í…ŒìŠ¤íŠ¸ ë¬¸ì„œ ìƒì„± ì™„ë£Œ: {test_doc.id}")

            # Create test chunk
            test_chunk = TestChunk(
                id=str(uuid.uuid4()),
                document_id=test_doc.id,
                content="í…ŒìŠ¤íŠ¸ ì²­í¬ ë‚´ìš©ì…ë‹ˆë‹¤. í•œê¸€ UTF-8 ì¸ì½”ë”© í…ŒìŠ¤íŠ¸.",
                chunk_metadata={"chunk_index": 0, "token_count": 10},
                created_at=datetime.utcnow()
            )

            session.add(test_chunk)
            await session.commit()
            logger.info(f"âœ… í…ŒìŠ¤íŠ¸ ì²­í¬ ìƒì„± ì™„ë£Œ: {test_chunk.id}")

            # Test retrieval
            retrieved_doc = await session.get(TestDocument, test_doc.id)
            if retrieved_doc:
                logger.info(f"âœ… ë¬¸ì„œ ì¡°íšŒ ì„±ê³µ: {retrieved_doc.title}")
                logger.info(f"âœ… ë©”íƒ€ë°ì´í„° ì¡°íšŒ: {retrieved_doc.doc_metadata}")
            else:
                logger.error("âŒ ë¬¸ì„œ ì¡°íšŒ ì‹¤íŒ¨")
                return False

            # Test query
            result = await session.execute(text("SELECT COUNT(*) FROM test_documents"))
            doc_count = result.scalar()
            logger.info(f"âœ… ë¬¸ì„œ ê°œìˆ˜ ì¡°íšŒ: {doc_count}ê°œ")

            # Cleanup
            await session.delete(test_chunk)
            await session.delete(test_doc)
            await session.commit()
            logger.info("âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ì •ë¦¬ ì™„ë£Œ")

        # Close engine
        await engine.dispose()

        # Remove temporary file
        if os.path.exists(temp_db_path):
            os.remove(temp_db_path)
            logger.info("âœ… ì„ì‹œ ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ ì‚­ì œ")

        return True

    except Exception as e:
        logger.error(f"âŒ SQLite ë°ì´í„°ë² ì´ìŠ¤ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
        import traceback
        logger.error(f"ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤: {traceback.format_exc()}")
        return False

async def test_utf8_encoding():
    """Test UTF-8 encoding specifically"""
    try:
        logger.info("ğŸ” UTF-8 ì¸ì½”ë”© ì „ìš© í…ŒìŠ¤íŠ¸ ì‹œì‘...")

        # Test various Korean texts
        test_strings = [
            "ì•ˆë…•í•˜ì„¸ìš” Dynamic Taxonomy RAG ì‹œìŠ¤í…œì…ë‹ˆë‹¤",
            "ë¬¸ì„œ ë¶„ë¥˜ ë° ê²€ìƒ‰ ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤",
            "íŠ¹ìˆ˜ë¬¸ì í…ŒìŠ¤íŠ¸: !@#$%^&*()_+{}|:<>?[]\\;',./",
            "ì´ëª¨ì§€ í…ŒìŠ¤íŠ¸: ğŸš€ğŸ”âœ…âŒâš ï¸ğŸ“ŠğŸ‰",
            "JSON ë°ì´í„°: {'í•œê¸€í‚¤': 'í•œê¸€ê°’', 'numbers': [1, 2, 3]}"
        ]

        for i, test_string in enumerate(test_strings):
            logger.info(f"âœ… UTF-8 í…ŒìŠ¤íŠ¸ {i+1}: {test_string}")

            # Test encoding/decoding
            encoded = test_string.encode('utf-8')
            decoded = encoded.decode('utf-8')

            if test_string == decoded:
                logger.info(f"âœ… ì¸ì½”ë”©/ë””ì½”ë”© ì„±ê³µ")
            else:
                logger.error(f"âŒ ì¸ì½”ë”©/ë””ì½”ë”© ì‹¤íŒ¨")
                return False

        logger.info("âœ… ëª¨ë“  UTF-8 ì¸ì½”ë”© í…ŒìŠ¤íŠ¸ í†µê³¼")
        return True

    except Exception as e:
        logger.error(f"âŒ UTF-8 ì¸ì½”ë”© í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
        return False

async def test_json_serialization():
    """Test JSON serialization with Korean text"""
    try:
        logger.info("ğŸ” JSON ì§ë ¬í™” í…ŒìŠ¤íŠ¸ ì‹œì‘...")

        import json

        test_data = {
            "ì œëª©": "í…ŒìŠ¤íŠ¸ ë¬¸ì„œ",
            "ë‚´ìš©": "í•œê¸€ ë‚´ìš©ì´ í¬í•¨ëœ ë¬¸ì„œì…ë‹ˆë‹¤",
            "ë©”íƒ€ë°ì´í„°": {
                "ì–¸ì–´": "í•œêµ­ì–´",
                "ì‘ì„±ì": "í…ŒìŠ¤íŠ¸ ì‚¬ìš©ì",
                "íƒœê·¸": ["ë¶„ë¥˜", "ê²€ìƒ‰", "í…ŒìŠ¤íŠ¸"]
            },
            "ìƒì„±ì¼ì‹œ": "2024-01-01T00:00:00Z",
            "ìˆ«ì": 12345,
            "ë¶ˆë¦°": True
        }

        # Test JSON serialization
        json_str = json.dumps(test_data, ensure_ascii=False, indent=2)
        logger.info(f"âœ… JSON ì§ë ¬í™” ì„±ê³µ")

        # Test JSON deserialization
        restored_data = json.loads(json_str)

        if restored_data == test_data:
            logger.info("âœ… JSON ì—­ì§ë ¬í™” ì„±ê³µ")
        else:
            logger.error("âŒ JSON ì—­ì§ë ¬í™” ì‹¤íŒ¨")
            return False

        # Test with file I/O
        temp_json_path = tempfile.mktemp(suffix='.json')
        with open(temp_json_path, 'w', encoding='utf-8') as f:
            json.dump(test_data, f, ensure_ascii=False, indent=2)

        with open(temp_json_path, 'r', encoding='utf-8') as f:
            file_data = json.load(f)

        if file_data == test_data:
            logger.info("âœ… íŒŒì¼ JSON I/O ì„±ê³µ")
        else:
            logger.error("âŒ íŒŒì¼ JSON I/O ì‹¤íŒ¨")
            return False

        # Cleanup
        if os.path.exists(temp_json_path):
            os.remove(temp_json_path)

        return True

    except Exception as e:
        logger.error(f"âŒ JSON ì§ë ¬í™” í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
        return False

async def main():
    """Run all SQLite and encoding tests"""
    print("ğŸš€ Dynamic Taxonomy RAG v1.8.1 - SQLite ë° ì¸ì½”ë”© í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    test_results = {}

    # Run all tests
    tests = [
        ("UTF-8 ì¸ì½”ë”©", test_utf8_encoding),
        ("JSON ì§ë ¬í™”", test_json_serialization),
        ("SQLite ë°ì´í„°ë² ì´ìŠ¤", test_sqlite_database)
    ]

    for test_name, test_func in tests:
        print(f"\nğŸ“‹ {test_name} í…ŒìŠ¤íŠ¸ ì¤‘...")
        result = await test_func()
        test_results[test_name] = result

        if result:
            print(f"âœ… {test_name} í…ŒìŠ¤íŠ¸ í†µê³¼")
        else:
            print(f"âŒ {test_name} í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")

    # Summary
    print("\n" + "=" * 60)
    print("ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½:")

    passed = sum(test_results.values())
    total = len(test_results)

    for test_name, result in test_results.items():
        status = "âœ… í†µê³¼" if result else "âŒ ì‹¤íŒ¨"
        print(f"  - {test_name}: {status}")

    print(f"\nğŸ† ì „ì²´ ê²°ê³¼: {passed}/{total} í…ŒìŠ¤íŠ¸ í†µê³¼ ({passed/total*100:.1f}%)")

    if passed == total:
        print("ğŸ‰ ëª¨ë“  SQLite ë° ì¸ì½”ë”© í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
        print("ğŸ’¡ PostgreSQL ì—†ì´ë„ ê¸°ë³¸ ë°ì´í„°ë² ì´ìŠ¤ ê¸°ëŠ¥ ê²€ì¦ ì™„ë£Œ")
    else:
        print("âš ï¸ ì¼ë¶€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ - ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

    return passed == total

if __name__ == "__main__":
    asyncio.run(main())
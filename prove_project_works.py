#!/usr/bin/env python3
"""
ì‹¤ì œ Gemini APIë¥¼ ì‚¬ìš©í•˜ì—¬ í”„ë¡œì íŠ¸ ì™„ë²½ ë™ì‘ ì¦ëª…

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë§ˆìŠ¤í„° ë¸Œëœì¹˜ê°€ ì™„ë²½í•˜ê²Œ ë™ì‘í•¨ì„ ì‹¤ì œë¡œ ì¦ëª…í•©ë‹ˆë‹¤:
1. Gemini API ì—°ê²° í…ŒìŠ¤íŠ¸
2. í…ìŠ¤íŠ¸ ìƒì„± ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
3. ì„ë² ë”© ìƒì„± í…ŒìŠ¤íŠ¸
4. ê²€ìƒ‰ ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸
5. ì‹¤ì œ RAG íŒŒì´í”„ë¼ì¸ ë™ì‘ ì¦ëª…
"""

import os
import sys
import time
import json
from pathlib import Path
from typing import List, Dict, Any
import asyncio

# í™˜ê²½ ì„¤ì •
sys.path.insert(0, str(Path(__file__).parent))
os.environ['PYTHONPATH'] = str(Path(__file__).parent)

def load_api_key():
    """API í‚¤ ë¡œë“œ"""
    env_file = Path(__file__).parent / '.env'
    if env_file.exists():
        with open(env_file, 'r') as f:
            for line in f:
                if line.startswith('GEMINI_API_KEY='):
                    return line.split('=', 1)[1].strip()
    return None

async def test_gemini_connection():
    """Gemini API ì—°ê²° í…ŒìŠ¤íŠ¸"""
    print("ğŸ§ª 1. Gemini API ì—°ê²° í…ŒìŠ¤íŠ¸")

    try:
        import google.generativeai as genai

        api_key = load_api_key()
        if not api_key:
            print("âŒ API í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return False

        genai.configure(api_key=api_key)

        # ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸
        model = genai.GenerativeModel('gemini-pro')
        response = model.generate_content('ì•ˆë…•í•˜ì„¸ìš”! ê°„ë‹¨í•œ ì¸ì‚¬ë§ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”.')

        print(f"âœ… Gemini API ì—°ê²° ì„±ê³µ!")
        print(f"ğŸ“ ì‘ë‹µ: {response.text[:100]}...")
        return True

    except Exception as e:
        print(f"âŒ Gemini API ì—°ê²° ì‹¤íŒ¨: {e}")
        return False

async def test_embedding_generation():
    """ì„ë² ë”© ìƒì„± í…ŒìŠ¤íŠ¸"""
    print("\nğŸ§ª 2. ì„ë² ë”© ìƒì„± í…ŒìŠ¤íŠ¸")

    try:
        import google.generativeai as genai

        api_key = load_api_key()
        genai.configure(api_key=api_key)

        # ì„ë² ë”© ìƒì„± í…ŒìŠ¤íŠ¸
        text = "Dynamic Taxonomy RAG ì‹œìŠ¤í…œì€ ê³„ì¸µì  ë¶„ë¥˜ ê¸°ë°˜ì˜ ê²€ìƒ‰ ì¦ê°• ìƒì„± ì‹œìŠ¤í…œì…ë‹ˆë‹¤."

        result = genai.embed_content(
            model="models/embedding-001",
            content=text,
            task_type="retrieval_document"
        )

        embedding = result['embedding']
        print(f"âœ… ì„ë² ë”© ìƒì„± ì„±ê³µ!")
        print(f"ğŸ“Š ë²¡í„° ì°¨ì›: {len(embedding)}")
        print(f"ğŸ”¢ ì²« 5ê°œ ê°’: {embedding[:5]}")

        return embedding

    except Exception as e:
        print(f"âŒ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
        return None

async def test_search_functionality():
    """ê²€ìƒ‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ§ª 3. ê²€ìƒ‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸")

    try:
        import google.generativeai as genai

        api_key = load_api_key()
        genai.configure(api_key=api_key)

        # ë¬¸ì„œ ì„ë² ë”© ìƒì„±
        documents = [
            "FastAPIëŠ” í˜„ëŒ€ì ì´ê³  ë¹ ë¥¸ ì›¹ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.",
            "PostgreSQLì€ ê°•ë ¥í•œ ì˜¤í”ˆì†ŒìŠ¤ ê´€ê³„í˜• ë°ì´í„°ë² ì´ìŠ¤ì…ë‹ˆë‹¤.",
            "Vector ê²€ìƒ‰ì€ ì˜ë¯¸ë¡ ì  ìœ ì‚¬ì„±ì„ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤.",
            "RAG ì‹œìŠ¤í…œì€ ê²€ìƒ‰ê³¼ ìƒì„±ì„ ê²°í•©í•œ AI ê¸°ìˆ ì…ë‹ˆë‹¤."
        ]

        print("ğŸ“„ ë¬¸ì„œ ì„ë² ë”© ìƒì„± ì¤‘...")
        doc_embeddings = []
        for i, doc in enumerate(documents):
            result = genai.embed_content(
                model="models/embedding-001",
                content=doc,
                task_type="retrieval_document"
            )
            doc_embeddings.append((doc, result['embedding']))
            print(f"   {i+1}/4 ì™„ë£Œ")

        # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
        query = "ì›¹ ê°œë°œ í”„ë ˆì„ì›Œí¬ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”"
        query_result = genai.embed_content(
            model="models/embedding-001",
            content=query,
            task_type="retrieval_query"
        )
        query_embedding = query_result['embedding']

        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        import numpy as np

        def cosine_similarity(a, b):
            return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))

        similarities = []
        for doc, doc_emb in doc_embeddings:
            similarity = cosine_similarity(query_embedding, doc_emb)
            similarities.append((doc, similarity))

        # ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬
        similarities.sort(key=lambda x: x[1], reverse=True)

        print(f"âœ… ê²€ìƒ‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
        print(f"ğŸ” ì¿¼ë¦¬: '{query}'")
        print("ğŸ“Š ê²€ìƒ‰ ê²°ê³¼ (ìœ ì‚¬ë„ ìˆœ):")
        for i, (doc, sim) in enumerate(similarities):
            print(f"   {i+1}. {doc} (ìœ ì‚¬ë„: {sim:.3f})")

        return similarities

    except Exception as e:
        print(f"âŒ ê²€ìƒ‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return None

async def test_rag_pipeline():
    """ì‹¤ì œ RAG íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ§ª 4. RAG íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸")

    try:
        import google.generativeai as genai

        api_key = load_api_key()
        genai.configure(api_key=api_key)

        # ì§€ì‹ ë² ì´ìŠ¤ êµ¬ì„±
        knowledge_base = [
            "Dynamic Taxonomy RAG v1.8.1ì€ ê³„ì¸µì  ë¶„ë¥˜ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.",
            "FastAPI ê¸°ë°˜ì˜ REST APIë¥¼ ì œê³µí•©ë‹ˆë‹¤.",
            "PostgreSQL + pgvectorë¥¼ ì‚¬ìš©í•œ ë²¡í„° ê²€ìƒ‰ì„ ì§€ì›í•©ë‹ˆë‹¤.",
            "BM25ì™€ ë²¡í„° ê²€ìƒ‰ì„ ê²°í•©í•œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì„ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤.",
            "305ê°œì˜ í…ŒìŠ¤íŠ¸ë¥¼ í†µí•´ 99.3% ì„±ê³µë¥ ì„ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤."
        ]

        # ê²€ìƒ‰ ë‹¨ê³„
        query = "ì´ í”„ë¡œì íŠ¸ì˜ ì£¼ìš” íŠ¹ì§•ì€ ë¬´ì—‡ì¸ê°€ìš”?"
        print(f"ğŸ” ì§ˆë¬¸: {query}")

        # ì¿¼ë¦¬ ì„ë² ë”©
        query_result = genai.embed_content(
            model="models/embedding-001",
            content=query,
            task_type="retrieval_query"
        )
        query_embedding = query_result['embedding']

        # ë¬¸ì„œë³„ ìœ ì‚¬ë„ ê³„ì‚°
        relevant_docs = []
        for doc in knowledge_base:
            doc_result = genai.embed_content(
                model="models/embedding-001",
                content=doc,
                task_type="retrieval_document"
            )
            doc_embedding = doc_result['embedding']

            # ì½”ì‚¬ì¸ ìœ ì‚¬ë„
            import numpy as np
            similarity = np.dot(query_embedding, doc_embedding) / (
                np.linalg.norm(query_embedding) * np.linalg.norm(doc_embedding)
            )

            if similarity > 0.3:  # ì„ê³„ê°’
                relevant_docs.append((doc, similarity))

        # ìƒìœ„ 3ê°œ ë¬¸ì„œ ì„ íƒ
        relevant_docs.sort(key=lambda x: x[1], reverse=True)
        top_docs = relevant_docs[:3]

        print("ğŸ“„ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ ì™„ë£Œ:")
        for i, (doc, sim) in enumerate(top_docs):
            print(f"   {i+1}. {doc} (ìœ ì‚¬ë„: {sim:.3f})")

        # ìƒì„± ë‹¨ê³„
        context = "\n".join([doc for doc, _ in top_docs])
        prompt = f"""ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”.

ì •ë³´:
{context}

ì§ˆë¬¸: {query}

ë‹µë³€:"""

        model = genai.GenerativeModel('gemini-pro')
        response = model.generate_content(prompt)

        print(f"\nâœ… RAG íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
        print(f"ğŸ¤– AI ë‹µë³€:")
        print(f"   {response.text}")

        return {
            "query": query,
            "retrieved_docs": len(top_docs),
            "response": response.text
        }

    except Exception as e:
        print(f"âŒ RAG íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return None

async def test_api_integration():
    """API í†µí•© í…ŒìŠ¤íŠ¸"""
    print("\nğŸ§ª 5. API í†µí•© í…ŒìŠ¤íŠ¸")

    try:
        # FastAPI ì•± ì„í¬íŠ¸ í…ŒìŠ¤íŠ¸
        sys.path.append('./apps/api')

        from fastapi import FastAPI
        from fastapi.testclient import TestClient

        # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì•± ìƒì„±
        app = FastAPI()

        @app.get("/test-gemini")
        async def test_gemini_endpoint():
            import google.generativeai as genai

            api_key = load_api_key()
            genai.configure(api_key=api_key)

            model = genai.GenerativeModel('gemini-pro')
            response = model.generate_content('í”„ë¡œì íŠ¸ ìƒíƒœë¥¼ ê°„ë‹¨íˆ ì•Œë ¤ì£¼ì„¸ìš”.')

            return {
                "status": "success",
                "message": "Gemini API í†µí•© ì™„ë£Œ",
                "response": response.text[:200] + "..."
            }

        client = TestClient(app)
        response = client.get("/test-gemini")

        print(f"âœ… API í†µí•© í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
        print(f"ğŸ“¡ HTTP ìƒíƒœ: {response.status_code}")
        print(f"ğŸ’¬ ì‘ë‹µ: {response.json()['message']}")

        return response.json()

    except Exception as e:
        print(f"âŒ API í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return None

async def generate_proof_report(results):
    """ì¦ëª… ë³´ê³ ì„œ ìƒì„±"""
    print("\nğŸ“‹ ìµœì¢… ì¦ëª… ë³´ê³ ì„œ ìƒì„±")

    report = {
        "timestamp": time.time(),
        "test_results": results,
        "conclusion": "SUCCESS" if all(results.values()) else "PARTIAL",
        "evidence": []
    }

    if results.get('connection'):
        report["evidence"].append("âœ… Gemini API ì—°ê²° ì •ìƒ ë™ì‘")

    if results.get('embedding'):
        report["evidence"].append("âœ… ë²¡í„° ì„ë² ë”© ìƒì„± ê¸°ëŠ¥ ì •ìƒ")

    if results.get('search'):
        report["evidence"].append("âœ… ì˜ë¯¸ë¡ ì  ê²€ìƒ‰ ê¸°ëŠ¥ ì •ìƒ")

    if results.get('rag'):
        report["evidence"].append("âœ… RAG íŒŒì´í”„ë¼ì¸ ì™„ì „ ë™ì‘")

    if results.get('api'):
        report["evidence"].append("âœ… FastAPI í†µí•© ì •ìƒ")

    # ë³´ê³ ì„œ ì €ì¥
    report_file = Path(__file__).parent / "PROJECT_PROOF_REPORT.json"
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)

    print(f"ğŸ“„ ë³´ê³ ì„œ ì €ì¥: {report_file}")
    return report

async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ Dynamic Taxonomy RAG v1.8.1 - ì‹¤ì œ ë™ì‘ ì¦ëª…")
    print("=" * 60)
    print("ğŸ“… GitHub ë§ˆìŠ¤í„° ë¸Œëœì¹˜ ì™„ë²½ ë™ì‘ ê²€ì¦")
    print("ğŸ”§ ì‹¤ì œ Gemini API ì‚¬ìš©")
    print()

    results = {}

    # 1. ì—°ê²° í…ŒìŠ¤íŠ¸
    results['connection'] = await test_gemini_connection()

    # 2. ì„ë² ë”© í…ŒìŠ¤íŠ¸
    embedding = await test_embedding_generation()
    results['embedding'] = embedding is not None

    # 3. ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    search_results = await test_search_functionality()
    results['search'] = search_results is not None

    # 4. RAG í…ŒìŠ¤íŠ¸
    rag_result = await test_rag_pipeline()
    results['rag'] = rag_result is not None

    # 5. API í†µí•© í…ŒìŠ¤íŠ¸
    api_result = await test_api_integration()
    results['api'] = api_result is not None

    # ìµœì¢… ë³´ê³ ì„œ
    report = await generate_proof_report(results)

    print("\n" + "=" * 60)
    print("ğŸ¯ ìµœì¢… ê²°ê³¼")
    print("=" * 60)

    success_count = sum(results.values())
    total_count = len(results)

    for test_name, result in results.items():
        status = "âœ… ì„±ê³µ" if result else "âŒ ì‹¤íŒ¨"
        print(f"{status} {test_name.upper()} í…ŒìŠ¤íŠ¸")

    print(f"\nğŸ† ì „ì²´ ê²°ê³¼: {success_count}/{total_count} ì„±ê³µ")

    if success_count == total_count:
        print("\nğŸ‰ ì¦ëª… ì™„ë£Œ! GitHub ë§ˆìŠ¤í„° ë¸Œëœì¹˜ê°€ Gemini APIì™€ ì™„ë²½í•˜ê²Œ ë™ì‘í•©ë‹ˆë‹¤!")
        print("ğŸš€ í”„ë¡œì íŠ¸ëŠ” í”„ë¡œë•ì…˜ ë°°í¬ ì¤€ë¹„ê°€ ì™„ë£Œëœ ìƒíƒœì…ë‹ˆë‹¤!")
    else:
        print(f"\nâš ï¸ ë¶€ë¶„ ì„±ê³µ: {success_count}/{total_count} ê¸°ëŠ¥ì´ ë™ì‘í•©ë‹ˆë‹¤.")

    return success_count == total_count

if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)
#!/usr/bin/env python3
"""
ê°„ì†Œí™”ëœ ë¬¸ì„œ ìˆ˜ì§‘ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë¬¸ì„œ ìˆ˜ì§‘ íŒŒì´í”„ë¼ì¸ì˜ í•µì‹¬ ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤:
1. ê¸°ë³¸ íŒŒì¼ í¬ë§· ì§€ì› (TXT, MD, HTML, CSV, JSON)
2. í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ê¸°ë³¸ ì²­í‚¹
3. PII ê¸°ë³¸ íƒì§€
4. ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
"""

import os
import sys
import json
import time
import tempfile
import shutil
from pathlib import Path
import logging
from typing import Dict, List, Any, Optional
from datetime import datetime
import traceback

# ê¸°ë³¸ ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class SimpleDocumentTester:
    """ê°„ì†Œí™”ëœ ë¬¸ì„œ í…ŒìŠ¤í„°"""

    def __init__(self):
        self.temp_dir = Path(tempfile.mkdtemp(prefix="simple_test_"))
        self.results = {}
        self.start_time = time.time()

        logger.info(f"í…ŒìŠ¤íŠ¸ ë””ë ‰í† ë¦¬: {self.temp_dir}")

    def __del__(self):
        if hasattr(self, 'temp_dir') and self.temp_dir.exists():
            shutil.rmtree(self.temp_dir, ignore_errors=True)

    def create_test_files(self) -> Dict[str, Path]:
        """í…ŒìŠ¤íŠ¸ íŒŒì¼ ìƒì„±"""
        logger.info("í…ŒìŠ¤íŠ¸ íŒŒì¼ ìƒì„± ì¤‘...")
        files = {}

        # 1. í•œê¸€ í…ìŠ¤íŠ¸ íŒŒì¼
        txt_content = """
ì•ˆë…•í•˜ì„¸ìš”! ì´ê²ƒì€ í•œê¸€ í…ŒìŠ¤íŠ¸ íŒŒì¼ì…ë‹ˆë‹¤.

ê°œì¸ì •ë³´ í…ŒìŠ¤íŠ¸:
- ì´ë©”ì¼: test@example.com
- ì „í™”ë²ˆí˜¸: 010-1234-5678
- ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸: 123456-1234567

ê¸°ìˆ  ë¬¸ì„œ:
Dynamic Taxonomy RAG ì‹œìŠ¤í…œì€ ë¬¸ì„œ ë¶„ë¥˜ì™€ ê²€ìƒ‰ì„ ì œê³µí•©ë‹ˆë‹¤.
ì´ ì‹œìŠ¤í…œì€ ìë™ìœ¼ë¡œ ë¬¸ì„œë¥¼ ë¶„ë¥˜í•˜ê³  ê²€ìƒ‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

Lorem ipsum dolor sit amet, consectetur adipiscing elit.
Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.
        """.strip()

        txt_file = self.temp_dir / "test_korean.txt"
        with open(txt_file, 'w', encoding='utf-8') as f:
            f.write(txt_content)
        files['txt'] = txt_file

        # 2. Markdown íŒŒì¼
        md_content = """
# í•œê¸€ ë§ˆí¬ë‹¤ìš´ ë¬¸ì„œ

## ê°œìš”
ì´ê²ƒì€ **ë§ˆí¬ë‹¤ìš´** í…ŒìŠ¤íŠ¸ íŒŒì¼ì…ë‹ˆë‹¤.

### ê°œì¸ì •ë³´
- ì‚¬ìš©ì: ê¹€ì² ìˆ˜
- ì´ë©”ì¼: kim@company.com
- ì—°ë½ì²˜: 02-123-4567

### ì½”ë“œ ì˜ˆì‹œ
```python
def process_text(text):
    return text.strip()
```

> ì¸ìš©ë¬¸ ì˜ˆì‹œì…ë‹ˆë‹¤.
        """.strip()

        md_file = self.temp_dir / "test_korean.md"
        with open(md_file, 'w', encoding='utf-8') as f:
            f.write(md_content)
        files['md'] = md_file

        # 3. HTML íŒŒì¼
        html_content = """
<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <title>í•œê¸€ HTML í…ŒìŠ¤íŠ¸</title>
</head>
<body>
    <h1>í•œê¸€ HTML ë¬¸ì„œ</h1>
    <p>ì´ê²ƒì€ HTML í…ŒìŠ¤íŠ¸ íŒŒì¼ì…ë‹ˆë‹¤.</p>

    <h2>ê°œì¸ì •ë³´</h2>
    <ul>
        <li>ì´ë¦„: ë°•ì˜í¬</li>
        <li>ì´ë©”ì¼: park@test.com</li>
        <li>ì „í™”: 010-9876-5432</li>
    </ul>

    <script>
        console.log("ìŠ¤í¬ë¦½íŠ¸ëŠ” ì œê±°ë©ë‹ˆë‹¤");
    </script>
</body>
</html>
        """.strip()

        html_file = self.temp_dir / "test_korean.html"
        with open(html_file, 'w', encoding='utf-8') as f:
            f.write(html_content)
        files['html'] = html_file

        # 4. CSV íŒŒì¼
        csv_content = """ì´ë¦„,ì´ë©”ì¼,ì „í™”ë²ˆí˜¸,ë¶€ì„œ
ê¹€ë¯¼ìˆ˜,kim@company.com,010-1111-2222,ê°œë°œíŒ€
ì´ì˜í¬,lee@company.com,010-3333-4444,ë§ˆì¼€íŒ…íŒ€
ë°•ì² ìˆ˜,park@company.com,010-5555-6666,ì˜ì—…íŒ€"""

        csv_file = self.temp_dir / "test_korean.csv"
        with open(csv_file, 'w', encoding='utf-8') as f:
            f.write(csv_content)
        files['csv'] = csv_file

        # 5. JSON íŒŒì¼
        json_data = {
            "title": "í•œê¸€ JSON ë¬¸ì„œ",
            "description": "JSON í¬ë§· í…ŒìŠ¤íŠ¸",
            "users": [
                {
                    "name": "í™ê¸¸ë™",
                    "email": "hong@example.org",
                    "phone": "010-1234-0000"
                }
            ],
            "content": {
                "korean": "í•œê¸€ ì½˜í…ì¸ ì…ë‹ˆë‹¤.",
                "english": "This is English content."
            }
        }

        json_file = self.temp_dir / "test_korean.json"
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(json_data, f, ensure_ascii=False, indent=2)
        files['json'] = json_file

        # 6. ë¹ˆ íŒŒì¼
        empty_file = self.temp_dir / "empty.txt"
        empty_file.touch()
        files['empty'] = empty_file

        # 7. ëŒ€ìš©ëŸ‰ íŒŒì¼
        large_content = "í•œê¸€ ëŒ€ìš©ëŸ‰ í…ŒìŠ¤íŠ¸ ì½˜í…ì¸ . " * 5000
        large_file = self.temp_dir / "large_test.txt"
        with open(large_file, 'w', encoding='utf-8') as f:
            f.write(large_content)
        files['large'] = large_file

        logger.info(f"ì´ {len(files)}ê°œ í…ŒìŠ¤íŠ¸ íŒŒì¼ ìƒì„± ì™„ë£Œ")
        return files

    def test_basic_file_reading(self, files: Dict[str, Path]) -> Dict[str, Any]:
        """ê¸°ë³¸ íŒŒì¼ ì½ê¸° í…ŒìŠ¤íŠ¸"""
        logger.info("=== ê¸°ë³¸ íŒŒì¼ ì½ê¸° í…ŒìŠ¤íŠ¸ ===")
        results = {}

        for fmt, file_path in files.items():
            start_time = time.time()

            try:
                if fmt == 'empty':
                    # ë¹ˆ íŒŒì¼ ì²˜ë¦¬
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                    results[fmt] = {
                        'success': True,
                        'length': len(content),
                        'is_empty': len(content) == 0,
                        'processing_time': time.time() - start_time
                    }
                else:
                    # ì¼ë°˜ íŒŒì¼ ì²˜ë¦¬
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()

                    results[fmt] = {
                        'success': True,
                        'length': len(content),
                        'has_korean': any(ord(c) > 127 for c in content[:100]),
                        'line_count': content.count('\n') + 1,
                        'processing_time': time.time() - start_time
                    }

                logger.info(f"{fmt}: {len(content)} ë¬¸ì ì½ê¸° ì„±ê³µ")

            except Exception as e:
                results[fmt] = {
                    'success': False,
                    'error': str(e),
                    'processing_time': time.time() - start_time
                }
                logger.error(f"{fmt} ì½ê¸° ì‹¤íŒ¨: {e}")

        return results

    def test_simple_chunking(self, files: Dict[str, Path]) -> Dict[str, Any]:
        """ê°„ë‹¨í•œ ì²­í‚¹ í…ŒìŠ¤íŠ¸"""
        logger.info("=== ê°„ë‹¨í•œ ì²­í‚¹ í…ŒìŠ¤íŠ¸ ===")
        results = {}

        def simple_chunk(text: str, max_size: int = 500) -> List[str]:
            """ê°„ë‹¨í•œ ì²­í‚¹ í•¨ìˆ˜"""
            if not text or len(text) <= max_size:
                return [text] if text else []

            chunks = []
            current_pos = 0

            while current_pos < len(text):
                end_pos = min(current_pos + max_size, len(text))

                # ë‹¨ì–´ ê²½ê³„ì—ì„œ ìë¥´ê¸° ì‹œë„
                if end_pos < len(text):
                    space_pos = text.rfind(' ', current_pos, end_pos)
                    if space_pos > current_pos:
                        end_pos = space_pos

                chunk = text[current_pos:end_pos].strip()
                if chunk:
                    chunks.append(chunk)

                current_pos = end_pos + 1

            return chunks

        for fmt, file_path in files.items():
            if fmt == 'empty':
                continue

            start_time = time.time()

            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()

                chunks = simple_chunk(content)
                processing_time = time.time() - start_time

                results[fmt] = {
                    'success': True,
                    'original_length': len(content),
                    'chunk_count': len(chunks),
                    'chunk_sizes': [len(chunk) for chunk in chunks],
                    'avg_chunk_size': sum(len(chunk) for chunk in chunks) / len(chunks) if chunks else 0,
                    'processing_time': processing_time
                }

                logger.info(f"{fmt}: {len(chunks)}ê°œ ì²­í¬ ìƒì„±")

            except Exception as e:
                results[fmt] = {
                    'success': False,
                    'error': str(e),
                    'processing_time': time.time() - start_time
                }
                logger.error(f"{fmt} ì²­í‚¹ ì‹¤íŒ¨: {e}")

        return results

    def test_simple_pii_detection(self, files: Dict[str, Path]) -> Dict[str, Any]:
        """ê°„ë‹¨í•œ PII íƒì§€ í…ŒìŠ¤íŠ¸"""
        logger.info("=== ê°„ë‹¨í•œ PII íƒì§€ í…ŒìŠ¤íŠ¸ ===")
        results = {}

        import re

        # ê°„ë‹¨í•œ PII íŒ¨í„´
        pii_patterns = {
            'email': re.compile(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'),
            'phone': re.compile(r'\b(?:\d{2,3}-\d{3,4}-\d{4}|\d{10,11})\b'),
            'ssn': re.compile(r'\b\d{6}-[1-4]\d{6}\b'),  # í•œêµ­ ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸
            'credit_card': re.compile(r'\b\d{4}-\d{4}-\d{4}-\d{4}\b')
        }

        for fmt, file_path in files.items():
            if fmt == 'empty':
                continue

            start_time = time.time()

            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()

                detections = {}
                for pii_type, pattern in pii_patterns.items():
                    matches = pattern.findall(content)
                    detections[pii_type] = {
                        'count': len(matches),
                        'matches': matches
                    }

                total_detections = sum(d['count'] for d in detections.values())
                processing_time = time.time() - start_time

                results[fmt] = {
                    'success': True,
                    'total_detections': total_detections,
                    'detections_by_type': detections,
                    'processing_time': processing_time
                }

                logger.info(f"{fmt}: {total_detections}ê°œ PII íƒì§€")

            except Exception as e:
                results[fmt] = {
                    'success': False,
                    'error': str(e),
                    'processing_time': time.time() - start_time
                }
                logger.error(f"{fmt} PII íƒì§€ ì‹¤íŒ¨: {e}")

        return results

    def test_html_parsing(self, files: Dict[str, Path]) -> Dict[str, Any]:
        """HTML íŒŒì‹± í…ŒìŠ¤íŠ¸ (BeautifulSoup ì‚¬ìš©)"""
        logger.info("=== HTML íŒŒì‹± í…ŒìŠ¤íŠ¸ ===")
        results = {}

        try:
            from bs4 import BeautifulSoup

            html_file = files.get('html')
            if not html_file:
                return {'error': 'HTML íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤'}

            start_time = time.time()

            with open(html_file, 'r', encoding='utf-8') as f:
                html_content = f.read()

            soup = BeautifulSoup(html_content, 'html.parser')

            # ìŠ¤í¬ë¦½íŠ¸ì™€ ìŠ¤íƒ€ì¼ ì œê±°
            for script in soup(["script", "style"]):
                script.decompose()

            # í…ìŠ¤íŠ¸ ì¶”ì¶œ
            text = soup.get_text()
            lines = (line.strip() for line in text.splitlines())
            chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
            clean_text = ' '.join(chunk for chunk in chunks if chunk)

            processing_time = time.time() - start_time

            results['html_parsing'] = {
                'success': True,
                'original_html_length': len(html_content),
                'extracted_text_length': len(clean_text),
                'title': soup.title.string if soup.title else None,
                'has_korean': any(ord(c) > 127 for c in clean_text[:100]),
                'processing_time': processing_time
            }

            logger.info(f"HTML íŒŒì‹± ì„±ê³µ: {len(clean_text)} ë¬¸ì ì¶”ì¶œ")

        except ImportError:
            results['html_parsing'] = {
                'success': False,
                'error': 'BeautifulSoupì´ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ'
            }
            logger.warning("BeautifulSoupì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ HTML íŒŒì‹±ì„ ê±´ë„ˆëœë‹ˆë‹¤")
        except Exception as e:
            results['html_parsing'] = {
                'success': False,
                'error': str(e),
                'processing_time': time.time() - start_time if 'start_time' in locals() else 0
            }
            logger.error(f"HTML íŒŒì‹± ì‹¤íŒ¨: {e}")

        return results

    def test_json_parsing(self, files: Dict[str, Path]) -> Dict[str, Any]:
        """JSON íŒŒì‹± í…ŒìŠ¤íŠ¸"""
        logger.info("=== JSON íŒŒì‹± í…ŒìŠ¤íŠ¸ ===")
        results = {}

        json_file = files.get('json')
        if not json_file:
            return {'error': 'JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤'}

        start_time = time.time()

        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)

            # JSON ë°ì´í„°ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
            def extract_text_from_json(obj, texts=None):
                if texts is None:
                    texts = []

                if isinstance(obj, dict):
                    for value in obj.values():
                        extract_text_from_json(value, texts)
                elif isinstance(obj, list):
                    for item in obj:
                        extract_text_from_json(item, texts)
                elif isinstance(obj, str):
                    texts.append(obj)

                return texts

            extracted_texts = extract_text_from_json(data)
            combined_text = ' '.join(extracted_texts)

            processing_time = time.time() - start_time

            results['json_parsing'] = {
                'success': True,
                'keys_count': len(data) if isinstance(data, dict) else 0,
                'extracted_texts_count': len(extracted_texts),
                'combined_text_length': len(combined_text),
                'has_korean': any(ord(c) > 127 for c in combined_text[:100]),
                'processing_time': processing_time
            }

            logger.info(f"JSON íŒŒì‹± ì„±ê³µ: {len(extracted_texts)}ê°œ í…ìŠ¤íŠ¸ ì¶”ì¶œ")

        except Exception as e:
            results['json_parsing'] = {
                'success': False,
                'error': str(e),
                'processing_time': time.time() - start_time
            }
            logger.error(f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}")

        return results

    def test_performance_benchmark(self, files: Dict[str, Path]) -> Dict[str, Any]:
        """ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸"""
        logger.info("=== ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸ ===")
        results = {}

        # ëŒ€ìš©ëŸ‰ íŒŒì¼ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
        large_file = files.get('large')
        if large_file:
            start_time = time.time()

            try:
                with open(large_file, 'r', encoding='utf-8') as f:
                    content = f.read()

                read_time = time.time() - start_time

                # ì²˜ë¦¬ ì‹œê°„ ì¸¡ì •
                process_start = time.time()

                # ê°„ë‹¨í•œ ì²˜ë¦¬ (ë‹¨ì–´ ìˆ˜ ê³„ì‚°)
                word_count = len(content.split())
                char_count = len(content)
                line_count = content.count('\n')

                process_time = time.time() - process_start
                total_time = time.time() - start_time

                results['large_file_performance'] = {
                    'success': True,
                    'file_size_chars': char_count,
                    'word_count': word_count,
                    'line_count': line_count,
                    'read_time': read_time,
                    'process_time': process_time,
                    'total_time': total_time,
                    'chars_per_second': char_count / total_time if total_time > 0 else 0
                }

                logger.info(f"ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬: {char_count:,} ë¬¸ì, {total_time:.3f}ì´ˆ")

            except Exception as e:
                results['large_file_performance'] = {
                    'success': False,
                    'error': str(e)
                }
                logger.error(f"ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

        # ëª¨ë“  íŒŒì¼ ë°°ì¹˜ ì²˜ë¦¬ ì„±ëŠ¥
        start_time = time.time()

        try:
            total_chars = 0
            total_files = 0

            for fmt, file_path in files.items():
                if fmt in ['empty', 'large']:
                    continue

                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                    total_chars += len(content)
                    total_files += 1
                except:
                    continue

            batch_time = time.time() - start_time

            results['batch_performance'] = {
                'success': True,
                'total_files': total_files,
                'total_chars': total_chars,
                'batch_time': batch_time,
                'files_per_second': total_files / batch_time if batch_time > 0 else 0,
                'chars_per_second': total_chars / batch_time if batch_time > 0 else 0
            }

            logger.info(f"ë°°ì¹˜ ì²˜ë¦¬: {total_files}ê°œ íŒŒì¼, {total_chars:,} ë¬¸ì, {batch_time:.3f}ì´ˆ")

        except Exception as e:
            results['batch_performance'] = {
                'success': False,
                'error': str(e)
            }
            logger.error(f"ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

        return results

    def generate_summary_report(self) -> Dict[str, Any]:
        """ìš”ì•½ ë³´ê³ ì„œ ìƒì„±"""
        total_time = time.time() - self.start_time

        # ì„±ê³µë¥  ê³„ì‚°
        total_tests = 0
        successful_tests = 0

        for test_name, test_results in self.results.items():
            if isinstance(test_results, dict):
                for sub_test, result in test_results.items():
                    if isinstance(result, dict) and 'success' in result:
                        total_tests += 1
                        if result['success']:
                            successful_tests += 1

        success_rate = (successful_tests / total_tests * 100) if total_tests > 0 else 0

        return {
            'summary': {
                'total_test_time': total_time,
                'total_tests': total_tests,
                'successful_tests': successful_tests,
                'failed_tests': total_tests - successful_tests,
                'success_rate': success_rate
            },
            'detailed_results': self.results,
            'recommendations': self._generate_recommendations()
        }

    def _generate_recommendations(self) -> List[str]:
        """ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []

        # ê¸°ë³¸ íŒŒì¼ ì½ê¸° ê²°ê³¼ ë¶„ì„
        file_reading = self.results.get('basic_file_reading', {})
        failed_formats = [fmt for fmt, result in file_reading.items()
                         if isinstance(result, dict) and not result.get('success', True)]

        if failed_formats:
            recommendations.append(f"íŒŒì¼ ì½ê¸° ì‹¤íŒ¨ í˜•ì‹: {', '.join(failed_formats)}. ì¸ì½”ë”© ë˜ëŠ” íŒŒì„œ ë¬¸ì œë¥¼ í™•ì¸í•˜ì„¸ìš”.")

        # PII íƒì§€ ê²°ê³¼ ë¶„ì„
        pii_detection = self.results.get('simple_pii_detection', {})
        total_pii = sum(result.get('total_detections', 0) for result in pii_detection.values()
                       if isinstance(result, dict))

        if total_pii == 0:
            recommendations.append("PIIê°€ íƒì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. PII íŒ¨í„´ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ì„¸ìš”.")
        elif total_pii > 50:
            recommendations.append(f"ë§ì€ PIIê°€ íƒì§€ë˜ì—ˆìŠµë‹ˆë‹¤ ({total_pii}ê°œ). ë§ˆìŠ¤í‚¹ ì „ëµì„ ê²€í† í•˜ì„¸ìš”.")

        # ì„±ëŠ¥ ë¶„ì„
        performance = self.results.get('performance_benchmark', {})
        if 'large_file_performance' in performance:
            perf = performance['large_file_performance']
            if perf.get('success') and perf.get('chars_per_second', 0) < 10000:
                recommendations.append("ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ ì†ë„ê°€ ëŠë¦½ë‹ˆë‹¤. ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬ë¥¼ ê³ ë ¤í•˜ì„¸ìš”.")

        if not recommendations:
            recommendations.append("ëª¨ë“  í…ŒìŠ¤íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

        return recommendations

    def run_all_tests(self) -> Dict[str, Any]:
        """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        logger.info("ğŸš€ ê°„ì†Œí™”ëœ ë¬¸ì„œ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì‹œì‘")

        try:
            # 1. í…ŒìŠ¤íŠ¸ íŒŒì¼ ìƒì„±
            test_files = self.create_test_files()

            # 2. ê¸°ë³¸ íŒŒì¼ ì½ê¸° í…ŒìŠ¤íŠ¸
            self.results['basic_file_reading'] = self.test_basic_file_reading(test_files)

            # 3. ì²­í‚¹ í…ŒìŠ¤íŠ¸
            self.results['simple_chunking'] = self.test_simple_chunking(test_files)

            # 4. PII íƒì§€ í…ŒìŠ¤íŠ¸
            self.results['simple_pii_detection'] = self.test_simple_pii_detection(test_files)

            # 5. HTML íŒŒì‹± í…ŒìŠ¤íŠ¸
            self.results['html_parsing'] = self.test_html_parsing(test_files)

            # 6. JSON íŒŒì‹± í…ŒìŠ¤íŠ¸
            self.results['json_parsing'] = self.test_json_parsing(test_files)

            # 7. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
            self.results['performance_benchmark'] = self.test_performance_benchmark(test_files)

            logger.info("âœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ")

        except Exception as e:
            logger.error(f"í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
            self.results['fatal_error'] = {
                'error': str(e),
                'traceback': traceback.format_exc()
            }

        return self.generate_summary_report()

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸ“‹ ê°„ì†Œí™”ëœ ë¬¸ì„œ ìˆ˜ì§‘ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸")
    print("=" * 50)

    tester = SimpleDocumentTester()

    try:
        # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        report = tester.run_all_tests()

        # ê²°ê³¼ ì €ì¥
        report_file = Path("simple_pipeline_test_report.json")
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)

        # ê²°ê³¼ ì¶œë ¥
        print("\nğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
        print("-" * 30)

        summary = report['summary']
        print(f"ğŸ• ì´ í…ŒìŠ¤íŠ¸ ì‹œê°„: {summary['total_test_time']:.2f}ì´ˆ")
        print(f"ğŸ“ ì´ í…ŒìŠ¤íŠ¸ ìˆ˜: {summary['total_tests']}ê°œ")
        print(f"âœ… ì„±ê³µ: {summary['successful_tests']}ê°œ")
        print(f"âŒ ì‹¤íŒ¨: {summary['failed_tests']}ê°œ")
        print(f"ğŸ“ˆ ì„±ê³µë¥ : {summary['success_rate']:.1f}%")

        if report['recommendations']:
            print("\nğŸ’¡ ê¶Œì¥ì‚¬í•­:")
            for i, rec in enumerate(report['recommendations'], 1):
                print(f"{i}. {rec}")

        print(f"\nğŸ“‹ ìƒì„¸ ë³´ê³ ì„œ: {report_file.absolute()}")

        # ì„±ê³µ ì—¬ë¶€ ë°˜í™˜
        if summary['success_rate'] >= 80:
            print("\nğŸ‰ í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
            return 0
        else:
            print("\nâš ï¸ ì¼ë¶€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
            return 1

    except Exception as e:
        print(f"\nğŸ’¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        return 2

    finally:
        # ì •ë¦¬
        if hasattr(tester, 'temp_dir') and tester.temp_dir.exists():
            shutil.rmtree(tester.temp_dir, ignore_errors=True)

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
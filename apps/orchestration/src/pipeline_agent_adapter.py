"""
Pipeline-Agent Factory í†µí•© ì–´ëŒ‘í„°
ê¸°ì¡´ LangGraph Pipelineê³¼ Agent Factoryë¥¼ ì—°ê²°í•˜ì—¬
Agent ì„¤ì •ì´ íŒŒì´í”„ë¼ì¸ ë™ì‘ì„ ì‹¤ì œë¡œ ì œì–´í•˜ë„ë¡ í•¨
"""

import asyncio
import time
import logging
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime

# Pipeline ê´€ë ¨ import
from .langgraph_pipeline import (
    LangGraphPipeline, PipelineRequest, PipelineResponse, PipelineState
)

# Agent Factory ê´€ë ¨ import
try:
    from apps.api.agent_factory import (
        get_agent_factory, AgentProfile, CanonicalPathValidator
    )
    AGENT_FACTORY_AVAILABLE = True
except ImportError:
    AGENT_FACTORY_AVAILABLE = False
    logging.warning("Agent Factory not available")

# Intent Classification import
try:
    from .intent_classifier import get_intent_classifier, IntentRouter
    INTENT_CLASSIFIER_AVAILABLE = True
except ImportError:
    INTENT_CLASSIFIER_AVAILABLE = False
    logging.warning("Intent Classifier not available")

logger = logging.getLogger(__name__)


class AgentEnhancedPipelineRequest(PipelineRequest):
    """Agent ì„¤ì •ì´ í¬í•¨ëœ Pipeline ìš”ì²­"""
    agent_id: Optional[str] = None
    agent_categories: Optional[List[str]] = None
    canonical_paths: Optional[List[List[str]]] = None
    agent_options: Optional[Dict[str, Any]] = None


class AgentEnhancedPipelineResponse(PipelineResponse):
    """Agent ì •ë³´ê°€ í¬í•¨ëœ Pipeline ì‘ë‹µ"""
    agent_id: Optional[str] = None
    agent_category: Optional[str] = None
    canonical_paths_used: Optional[List[List[str]]] = None
    retrieval_config_applied: Optional[Dict[str, Any]] = None
    tools_available: Optional[List[str]] = None


class PipelineAgentAdapter:
    """Pipelineê³¼ Agent Factory ì—°ê²° ì–´ëŒ‘í„°"""

    def __init__(self, pipeline: Optional[LangGraphPipeline] = None):
        self.pipeline = pipeline or LangGraphPipeline()
        self.agent_factory = None
        self.intent_classifier = None

        # ì„±ëŠ¥ ë©”íŠ¸ë¦­
        self.adapter_metrics = {
            "total_requests": 0,
            "agent_enhanced_requests": 0,
            "canonical_path_filtered": 0,
            "average_retrieval_speedup": 0.0
        }

    async def initialize(self):
        """ì–´ëŒ‘í„° ì´ˆê¸°í™”"""
        # Agent Factory ì´ˆê¸°í™”
        if AGENT_FACTORY_AVAILABLE:
            self.agent_factory = get_agent_factory()
            logger.info("Agent Factory ì—°ê²° ì™„ë£Œ")

        # Intent Classifier ì´ˆê¸°í™”
        if INTENT_CLASSIFIER_AVAILABLE:
            self.intent_classifier = await get_intent_classifier()
            logger.info("Intent Classifier ì—°ê²° ì™„ë£Œ")

        logger.info("Pipeline-Agent ì–´ëŒ‘í„° ì´ˆê¸°í™” ì™„ë£Œ")

    async def execute_with_agent(
        self,
        request: AgentEnhancedPipelineRequest
    ) -> AgentEnhancedPipelineResponse:
        """Agent ì„¤ì •ì„ ì ìš©í•œ Pipeline ì‹¤í–‰"""
        start_time = time.time()
        self.adapter_metrics["total_requests"] += 1

        # 1. Agent ì„¤ì • ë¡œë“œ ë˜ëŠ” ìƒì„±
        agent_profile = await self._get_or_create_agent(request)

        # 2. Pipeline State ì´ˆê¸°í™” (Agent ì„¤ì • ì ìš©)
        initial_state = await self._create_enhanced_state(request, agent_profile)

        # 3. Enhanced Pipeline ì‹¤í–‰
        enhanced_pipeline = EnhancedLangGraphPipeline(
            pipeline=self.pipeline,
            agent_profile=agent_profile
        )

        final_state = await enhanced_pipeline.execute_with_agent(initial_state)

        # 4. Agent ì •ë³´ê°€ í¬í•¨ëœ ì‘ë‹µ ìƒì„±
        response = await self._create_enhanced_response(
            final_state, agent_profile, start_time
        )

        # 5. ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
        if agent_profile:
            self.adapter_metrics["agent_enhanced_requests"] += 1

        return response

    async def _get_or_create_agent(
        self,
        request: AgentEnhancedPipelineRequest
    ) -> Optional[AgentProfile]:
        """Agent ì„¤ì • ë¡œë“œ ë˜ëŠ” ìƒì„±"""
        if not self.agent_factory:
            return None

        # ê¸°ì¡´ Agent ì‚¬ìš©
        if request.agent_id:
            agent = await self.agent_factory.get_agent(request.agent_id)
            if agent:
                logger.debug(f"ê¸°ì¡´ Agent ì‚¬ìš©: {agent.name}")
                return agent

        # ìƒˆ Agent ìƒì„± (ì¹´í…Œê³ ë¦¬ì™€ canonical path ì œê³µëœ ê²½ìš°)
        if request.agent_categories and request.canonical_paths:
            try:
                agent = await self.agent_factory.create_agent_from_category(
                    categories=request.agent_categories,
                    canonical_paths=request.canonical_paths,
                    taxonomy_version=request.taxonomy_version,
                    options=request.agent_options or {}
                )
                logger.info(f"ìƒˆ Agent ìƒì„±: {agent.name}")
                return agent
            except Exception as e:
                logger.error(f"Agent ìƒì„± ì‹¤íŒ¨: {str(e)}")

        return None

    async def _create_enhanced_state(
        self,
        request: AgentEnhancedPipelineRequest,
        agent_profile: Optional[AgentProfile]
    ) -> PipelineState:
        """Agent ì„¤ì •ì´ ì ìš©ëœ Pipeline State ìƒì„±"""
        # ê¸°ë³¸ State ìƒì„±
        state: PipelineState = {
            "query": request.query,
            "chunk_id": request.chunk_id,
            "taxonomy_version": request.taxonomy_version,
            "intent": "",
            "intent_confidence": 0.0,
            "retrieved_docs": [],
            "retrieval_filter_applied": False,
            "bm25_results": [],
            "vector_results": [],
            "answer_strategy": "",
            "plan_reasoning": [],
            "tools_used": [],
            "debate_activated": False,
            "debate_reasoning": None,
            "draft_answer": "",
            "sources": [],
            "citations_count": 0,
            "final_answer": "",
            "confidence": 0.0,
            "cost": 0.0,
            "latency": 0.0,
            "step_timings": {},
            "errors": [],
            "retry_count": 0
        }

        # Agent ì„¤ì • ì ìš©
        if agent_profile:
            state["agent_profile"] = agent_profile  # type: ignore
            state["canonical_paths"] = agent_profile.canonical_paths  # type: ignore

        return state

    async def _create_enhanced_response(
        self,
        final_state: PipelineState,
        agent_profile: Optional[AgentProfile],
        start_time: float
    ) -> AgentEnhancedPipelineResponse:
        """Agent ì •ë³´ê°€ í¬í•¨ëœ ì‘ë‹µ ìƒì„±"""
        total_latency = time.time() - start_time

        response_data = {
            "answer": final_state["final_answer"],
            "confidence": final_state["confidence"],
            "sources": final_state["sources"],
            "taxonomy_version": final_state["taxonomy_version"],
            "cost": final_state["cost"],
            "latency": total_latency,
            "intent": final_state["intent"],
            "step_timings": final_state["step_timings"],
            "debate_activated": final_state["debate_activated"],
            "retrieved_count": len(final_state["retrieved_docs"]),
            "citations_count": final_state["citations_count"]
        }

        # Agent ì •ë³´ ì¶”ê°€
        if agent_profile:
            response_data.update({
                "agent_id": agent_profile.id,
                "agent_category": agent_profile.category,
                "canonical_paths_used": agent_profile.canonical_paths,
                "retrieval_config_applied": agent_profile.retrieval_config,
                "tools_available": list(agent_profile.tools_config.get("allowed_tools", {}).get("primary", []))
            })

        return AgentEnhancedPipelineResponse(**response_data)

    def get_adapter_metrics(self) -> Dict[str, Any]:
        """ì–´ëŒ‘í„° ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë°˜í™˜"""
        total = self.adapter_metrics["total_requests"]
        enhancement_rate = (self.adapter_metrics["agent_enhanced_requests"] / total * 100) if total > 0 else 0

        return {
            "total_requests": total,
            "agent_enhanced_requests": self.adapter_metrics["agent_enhanced_requests"],
            "enhancement_rate_percent": enhancement_rate,
            "canonical_path_filtered": self.adapter_metrics["canonical_path_filtered"],
            "average_retrieval_speedup": self.adapter_metrics["average_retrieval_speedup"]
        }


class EnhancedLangGraphPipeline:
    """Agent ì„¤ì •ì´ ì ìš©ëœ í–¥ìƒëœ Pipeline"""

    def __init__(self, pipeline: LangGraphPipeline, agent_profile: Optional[AgentProfile]):
        self.pipeline = pipeline
        self.agent_profile = agent_profile

    async def execute_with_agent(self, state: PipelineState) -> PipelineState:
        """Agent ì„¤ì •ì„ ì ìš©í•˜ì—¬ Pipeline ì‹¤í–‰"""
        # 1. Agent ê¸°ë°˜ Intent Classification
        state = await self._enhanced_intent_classification(state)

        # 2. Agent ê¸°ë°˜ Retrieval
        state = await self._enhanced_retrieval(state)

        # 3. Agent ê¸°ë°˜ Planning
        state = await self._enhanced_planning(state)

        # 4. Agent ê¸°ë°˜ Tools/Debate
        state = await self._enhanced_tools_debate(state)

        # 5. Agent ê¸°ë°˜ Composition
        state = await self._enhanced_composition(state)

        # 6. ê¸°ë³¸ Citation ì²˜ë¦¬
        state = await self.pipeline._step6_citation_extraction(state)

        # 7. ê¸°ë³¸ Response ì²˜ë¦¬
        state = await self.pipeline._step7_final_response(state)

        return state

    async def _enhanced_intent_classification(self, state: PipelineState) -> PipelineState:
        """Agent ì„¤ì •ì„ ê³ ë ¤í•œ í–¥ìƒëœ Intent Classification"""
        step_start = time.time()

        # Intent Classifier ì‚¬ìš© (ìˆëŠ” ê²½ìš°)
        if INTENT_CLASSIFIER_AVAILABLE:
            try:
                from .intent_classifier import classify_intent
                intent_result = await classify_intent(state["query"])

                state["intent"] = intent_result.intent
                state["intent_confidence"] = intent_result.confidence

                logger.info(f"Enhanced Intent: {intent_result.intent} (confidence: {intent_result.confidence:.3f})")

                # Agent ì¹´í…Œê³ ë¦¬ì™€ ì˜ë„ì˜ ì¼ì¹˜ì„± í™•ì¸
                if self.agent_profile:
                    category_intent_match = self._check_category_intent_match(
                        self.agent_profile.category, intent_result.intent
                    )
                    if not category_intent_match:
                        logger.warning(f"ì˜ë„ì™€ Agent ì¹´í…Œê³ ë¦¬ ë¶ˆì¼ì¹˜: {intent_result.intent} vs {self.agent_profile.category}")

            except Exception as e:
                logger.error(f"Enhanced Intent Classification ì‹¤íŒ¨: {str(e)}")
                # Fallback to original
                state = await self.pipeline._step1_intent_classification(state)
        else:
            # ê¸°ë³¸ Intent Classification ì‚¬ìš©
            state = await self.pipeline._step1_intent_classification(state)

        step_time = time.time() - step_start
        state["step_timings"]["enhanced_step1_intent"] = step_time

        return state

    async def _enhanced_retrieval(self, state: PipelineState) -> PipelineState:
        """Agent ì„¤ì •ì„ ì ìš©í•œ í–¥ìƒëœ Retrieval"""
        step_start = time.time()

        if not self.agent_profile:
            # Agent ì—†ìœ¼ë©´ ê¸°ë³¸ Retrieval
            return await self.pipeline._step2_hybrid_retrieval(state)

        # Agentì˜ retrieval ì„¤ì • ì ìš©
        retrieval_config = self.agent_profile.retrieval_config
        canonical_paths = self.agent_profile.canonical_paths

        try:
            # AíŒ€ /search API í˜¸ì¶œ ì‹œ Agent ì„¤ì • ì ìš©
            search_request = {
                "q": state['query'],
                "filters": {
                    "canonical_in": canonical_paths  # PRD: canonical path í•„í„°ë§
                },
                "bm25_topk": retrieval_config.get("bm25_topk", 12),
                "vector_topk": retrieval_config.get("vector_topk", 12),
                "rerank_candidates": retrieval_config.get("rerank_candidates", 50),
                "final_topk": retrieval_config.get("final_topk", 5),
                "weights": {
                    "bm25": retrieval_config.get("bm25_weight", 0.5),
                    "vector": retrieval_config.get("vector_weight", 0.5)
                }
            }

            logger.info(f"Agent ì„¤ì • ì ìš©ëœ ê²€ìƒ‰: canonical_paths={canonical_paths}")
            logger.debug(f"ê²€ìƒ‰ ì„¤ì •: {search_request}")

            # AíŒ€ API í˜¸ì¶œ (ê¸°ì¡´ ë¡œì§ ì¬ì‚¬ìš©í•˜ë˜ ì„¤ì • ì ìš©)
            response = await self.pipeline.client.post(
                f"{self.pipeline.a_team_base_url}/search",
                json=search_request
            )
            response.raise_for_status()

            search_result = response.json()
            retrieved_docs = search_result.get("hits", [])

            # ê²°ê³¼ í¬ë§·íŒ…
            formatted_docs = []
            for i, doc in enumerate(retrieved_docs):
                formatted_doc = {
                    "chunk_id": doc.get("chunk_id", f"doc_{i}"),
                    "score": doc.get("score", 0.0),
                    "text": doc.get("text", ""),
                    "source": {
                        "url": doc.get("source", {}).get("url", ""),
                        "title": doc.get("source", {}).get("title", f"ë¬¸ì„œ {i+1}")
                    }
                }
                formatted_docs.append(formatted_doc)

            step_time = time.time() - step_start

            state.update({
                "bm25_results": [],  # AíŒ€ì—ì„œ ì´ë¯¸ í†µí•© ì²˜ë¦¬ë¨
                "vector_results": [],  # AíŒ€ì—ì„œ ì´ë¯¸ í†µí•© ì²˜ë¦¬ë¨
                "retrieved_docs": formatted_docs,
                "retrieval_filter_applied": True,
                "step_timings": {**state.get("step_timings", {}), "enhanced_step2_retrieve": step_time}
            })

            logger.info(f"Enhanced Retrieval ì™„ë£Œ: {len(formatted_docs)}ê°œ ë¬¸ì„œ, canonical í•„í„° ì ìš©")

        except Exception as e:
            logger.error(f"Enhanced Retrieval ì‹¤íŒ¨: {str(e)}")
            # Fallback to original
            state = await self.pipeline._step2_hybrid_retrieval(state)

        return state

    async def _enhanced_planning(self, state: PipelineState) -> PipelineState:
        """Agent ì„¤ì •ì„ ê³ ë ¤í•œ í–¥ìƒëœ Planning"""
        step_start = time.time()

        # Agent ì¹´í…Œê³ ë¦¬ë³„ íŠ¹í™” ê³„íš
        if self.agent_profile:
            category = self.agent_profile.category
            intent = state["intent"]

            strategy = self._determine_agent_strategy(category, intent, state)
            reasoning = self._generate_agent_reasoning(category, intent, state)

            state.update({
                "answer_strategy": strategy,
                "plan_reasoning": reasoning,
                "step_timings": {**state.get("step_timings", {}), "enhanced_step3_plan": time.time() - step_start}
            })

            logger.info(f"Enhanced Planning ({category}): {strategy}")
        else:
            # ê¸°ë³¸ Planning
            state = await self.pipeline._step3_answer_planning(state)

        return state

    async def _enhanced_tools_debate(self, state: PipelineState) -> PipelineState:
        """Agent ì„¤ì •ì„ ì ìš©í•œ í–¥ìƒëœ Tools/Debate"""
        step_start = time.time()

        if not self.agent_profile:
            return await self.pipeline._step4_tools_and_debate(state)

        tools_used = []
        debate_activated = False
        debate_reasoning = None

        # Agent ì„¤ì •ì— ë”°ë¥¸ debate í™œì„±í™”
        if self.agent_profile.debate_enabled:
            # ê¸°ë³¸ debate ì¡°ê±´ + Agent íŠ¹í™” ì¡°ê±´
            debate_triggers = []

            intent_confidence = state.get('intent_confidence', 1.0)
            if intent_confidence < 0.7:
                debate_triggers.append(f"ì˜ë„ ì‹ ë¢°ë„ ë‚®ìŒ ({intent_confidence:.3f})")

            retrieved_docs = state['retrieved_docs']
            if len(retrieved_docs) < 2:
                debate_triggers.append(f"ê²€ìƒ‰ ê²°ê³¼ ë¶€ì¡± ({len(retrieved_docs)}ê°œ)")

            # Agent ì¹´í…Œê³ ë¦¬ë³„ íŠ¹í™” ì¡°ê±´
            category = self.agent_profile.category
            if category == "technology_ai" and intent_confidence < 0.8:
                debate_triggers.append("ê¸°ìˆ  ë¶„ì•¼ ì •í™•ì„± ìš”êµ¬")
            elif category == "research" and len(retrieved_docs) < 3:
                debate_triggers.append("ì—°êµ¬ ë¶„ì•¼ ì¶©ë¶„í•œ ê·¼ê±° ìš”êµ¬")

            if debate_triggers:
                debate_activated = True
                debate_reasoning = "; ".join(debate_triggers)

        # Agent í—ˆìš© ë„êµ¬ ì‚¬ìš©
        allowed_tools = self.agent_profile.tools_config.get("allowed_tools", {})
        tools_used.extend(allowed_tools.get("primary", []))

        step_time = time.time() - step_start

        state.update({
            "tools_used": tools_used,
            "debate_activated": debate_activated,
            "debate_reasoning": debate_reasoning,
            "step_timings": {**state.get("step_timings", {}), "enhanced_step4_tools_debate": step_time}
        })

        logger.info(f"Enhanced Tools/Debate: tools={len(tools_used)}, debate={debate_activated}")
        return state

    async def _enhanced_composition(self, state: PipelineState) -> PipelineState:
        """Agent ì„¤ì •ì„ ì ìš©í•œ í–¥ìƒëœ Composition"""
        if not self.agent_profile:
            return await self.pipeline._step5_answer_composition(state)

        step_start = time.time()

        # Agent í”„ë¡¬í”„íŠ¸ ì„¤ì • ì ìš©
        prompt_config = self.agent_profile.prompt_config
        category = self.agent_profile.category

        # ì¹´í…Œê³ ë¦¬ë³„ íŠ¹í™” ë‹µë³€ ìƒì„±
        draft_answer = await self._generate_agent_specific_answer(state, category, prompt_config)

        step_time = time.time() - step_start

        state.update({
            "draft_answer": draft_answer,
            "step_timings": {**state.get("step_timings", {}), "enhanced_step5_compose": step_time}
        })

        logger.info(f"Enhanced Composition ({category}): {len(draft_answer)} characters")
        return state

    def _check_category_intent_match(self, category: str, intent: str) -> bool:
        """Agent ì¹´í…Œê³ ë¦¬ì™€ ì˜ë„ì˜ ì¼ì¹˜ì„± í™•ì¸"""
        category_intent_map = {
            "technology_ai": ["search", "explain", "analyze", "troubleshoot"],
            "business": ["search", "analyze", "generate", "compare"],
            "education": ["explain", "search", "generate"],
            "research": ["analyze", "compare", "search", "explain"],
            "customer_support": ["search", "troubleshoot", "explain"],
            "general": ["search", "explain", "analyze", "generate", "compare", "troubleshoot"]
        }

        compatible_intents = category_intent_map.get(category, [])
        return intent in compatible_intents

    def _determine_agent_strategy(self, category: str, intent: str, state: PipelineState) -> str:
        """Agent ì¹´í…Œê³ ë¦¬ë³„ ë‹µë³€ ì „ëµ ê²°ì •"""
        docs_count = len(state['retrieved_docs'])

        if category == "technology_ai":
            if intent == "explain":
                return "technical_detailed_explanation"
            elif intent == "analyze":
                return "technical_analysis_with_evidence"
            else:
                return "technical_accurate_response"

        elif category == "business":
            if intent == "analyze":
                return "business_strategic_analysis"
            elif intent == "generate":
                return "business_actionable_proposal"
            else:
                return "business_practical_response"

        elif category == "education":
            return "educational_step_by_step"

        elif category == "research":
            return "research_comprehensive_analysis"

        else:
            return "general_balanced_response"

    def _generate_agent_reasoning(self, category: str, intent: str, state: PipelineState) -> List[str]:
        """Agent ì¹´í…Œê³ ë¦¬ë³„ ê³„íš ì¶”ë¡  ìƒì„±"""
        base_reasoning = [
            f"Agent ì¹´í…Œê³ ë¦¬: {category}",
            f"íŒŒì•…ëœ ì˜ë„: {intent}",
            f"ê²€ìƒ‰ëœ ë¬¸ì„œ: {len(state['retrieved_docs'])}ê°œ"
        ]

        if category == "technology_ai":
            base_reasoning.append("ê¸°ìˆ ì  ì •í™•ì„±ê³¼ ê·¼ê±° ì¤‘ì‹¬ ë‹µë³€ ê³„íš")
        elif category == "business":
            base_reasoning.append("ì‹¤ìš©ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ë¹„ì¦ˆë‹ˆìŠ¤ ë‹µë³€ ê³„íš")
        elif category == "education":
            base_reasoning.append("ì´í•´í•˜ê¸° ì‰¬ìš´ ë‹¨ê³„ë³„ ì„¤ëª… ê³„íš")

        return base_reasoning

    async def _generate_agent_specific_answer(
        self,
        state: PipelineState,
        category: str,
        prompt_config: Dict[str, Any]
    ) -> str:
        """Agent íŠ¹í™” ë‹µë³€ ìƒì„±"""
        query = state['query']
        docs = state['retrieved_docs']

        # ì¹´í…Œê³ ë¦¬ë³„ í…œí”Œë¦¿ ì ìš©
        if category == "technology_ai":
            answer = self._generate_technical_answer(query, docs)
        elif category == "business":
            answer = self._generate_business_answer(query, docs)
        elif category == "education":
            answer = self._generate_educational_answer(query, docs)
        else:
            answer = self._generate_general_answer(query, docs)

        return answer

    def _generate_technical_answer(self, query: str, docs: List[Dict]) -> str:
        """ê¸°ìˆ  ì „ë¬¸ ë‹µë³€ ìƒì„±"""
        answer = f"'{query}'ì— ëŒ€í•œ ê¸°ìˆ ì  ë¶„ì„:\n\n"

        if docs:
            answer += "ğŸ“‹ ê¸°ìˆ ì  ê·¼ê±°:\n"
            for i, doc in enumerate(docs[:3], 1):
                answer += f"{i}. {doc['text'][:200]}...\n"
                answer += f"   (ì‹ ë¢°ë„: {doc.get('score', 0):.3f})\n\n"

            answer += "ğŸ”¬ ê¸°ìˆ ì  ê²°ë¡ :\n"
            answer += "ì œê³µëœ ë¬¸ì„œë“¤ì˜ ê¸°ìˆ ì  ë‚´ìš©ì„ ì¢…í•©í•˜ë©´, ì´ëŠ” ê²€ì¦ëœ ê¸°ìˆ ì  ì ‘ê·¼ë°©ë²•ìœ¼ë¡œ í‰ê°€ë©ë‹ˆë‹¤."
        else:
            answer += "ê¸°ìˆ  ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ì¼ë°˜ì ì¸ ê¸°ìˆ  ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ë“œë¦½ë‹ˆë‹¤."

        return answer

    def _generate_business_answer(self, query: str, docs: List[Dict]) -> str:
        """ë¹„ì¦ˆë‹ˆìŠ¤ ì „ë¬¸ ë‹µë³€ ìƒì„±"""
        answer = f"'{query}'ì— ëŒ€í•œ ë¹„ì¦ˆë‹ˆìŠ¤ ë¶„ì„:\n\n"

        if docs:
            answer += "ğŸ’¼ ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ì :\n"
            for i, doc in enumerate(docs[:3], 1):
                answer += f"â€¢ {doc['text'][:150]}...\n"

            answer += "\nğŸ¯ ì‹¤í–‰ ë°©ì•ˆ:\n"
            answer += "ë¶„ì„ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒê³¼ ê°™ì€ ì‹¤í–‰ ê°€ëŠ¥í•œ ë°©ì•ˆì„ ì œì•ˆë“œë¦½ë‹ˆë‹¤."
        else:
            answer += "ê´€ë ¨ ë¹„ì¦ˆë‹ˆìŠ¤ ìë£Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ì¼ë°˜ì ì¸ ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ì ì—ì„œ ë‹µë³€ë“œë¦½ë‹ˆë‹¤."

        return answer

    def _generate_educational_answer(self, query: str, docs: List[Dict]) -> str:
        """êµìœ¡ ì „ë¬¸ ë‹µë³€ ìƒì„±"""
        answer = f"'{query}' ë‹¨ê³„ë³„ ì„¤ëª…:\n\n"

        answer += "ğŸ“š 1ë‹¨ê³„: ê¸°ë³¸ ê°œë…\n"
        if docs:
            answer += f"   {docs[0]['text'][:100]}...\n\n"

        answer += "ğŸ“š 2ë‹¨ê³„: ìƒì„¸ ë‚´ìš©\n"
        if len(docs) > 1:
            answer += f"   {docs[1]['text'][:100]}...\n\n"

        answer += "ğŸ“š 3ë‹¨ê³„: ì‹¤ì œ ì ìš©\n"
        answer += "   í•™ìŠµí•œ ë‚´ìš©ì„ ì‹¤ì œë¡œ ì ìš©í•´ë³´ì„¸ìš”.\n"

        return answer

    def _generate_general_answer(self, query: str, docs: List[Dict]) -> str:
        """ì¼ë°˜ ë‹µë³€ ìƒì„±"""
        answer = f"'{query}'ì— ëŒ€í•œ ë‹µë³€:\n\n"

        if docs:
            for i, doc in enumerate(docs[:3], 1):
                answer += f"{i}. {doc['text'][:120]}...\n"
        else:
            answer += "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        return answer


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
_adapter_instance: Optional[PipelineAgentAdapter] = None

async def get_pipeline_agent_adapter() -> PipelineAgentAdapter:
    """Pipeline-Agent ì–´ëŒ‘í„° ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _adapter_instance
    if _adapter_instance is None:
        _adapter_instance = PipelineAgentAdapter()
        await _adapter_instance.initialize()
    return _adapter_instance


# í¸ì˜ í•¨ìˆ˜
async def execute_with_agent_categories(
    query: str,
    agent_categories: List[str],
    canonical_paths: List[List[str]],
    taxonomy_version: str = "1.8.1",
    **kwargs
) -> AgentEnhancedPipelineResponse:
    """Agent ì¹´í…Œê³ ë¦¬ë¡œ Pipeline ì‹¤í–‰"""
    adapter = await get_pipeline_agent_adapter()

    request = AgentEnhancedPipelineRequest(
        query=query,
        taxonomy_version=taxonomy_version,
        agent_categories=agent_categories,
        canonical_paths=canonical_paths,
        agent_options=kwargs
    )

    return await adapter.execute_with_agent(request)


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    async def main():
        # Pipeline-Agent ì–´ëŒ‘í„° í…ŒìŠ¤íŠ¸
        adapter = await get_pipeline_agent_adapter()

        # Technology AI Agentë¡œ ì‹¤í–‰
        response = await execute_with_agent_categories(
            query="RAG ì‹œìŠ¤í…œì˜ ê¸°ìˆ ì  ì•„í‚¤í…ì²˜ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”",
            agent_categories=["Technology", "AI"],
            canonical_paths=[["AI", "RAG"], ["Technology", "Architecture"]],
            accuracy_priority=True
        )

        print(f"Agent ì¹´í…Œê³ ë¦¬: {response.agent_category}")
        print(f"ê²€ìƒ‰ ë²”ìœ„: {response.canonical_paths_used}")
        print(f"ë‹µë³€: {response.answer}")
        print(f"ì¶œì²˜: {len(response.sources)}ê°œ")

        # ì–´ëŒ‘í„° ë©”íŠ¸ë¦­ í™•ì¸
        metrics = adapter.get_adapter_metrics()
        print(f"ì–´ëŒ‘í„° ì„±ëŠ¥: {metrics}")

    asyncio.run(main())
"""
BíŒ€ Dynamic Taxonomy RAG Orchestration Gateway
AI ëª¨ë¸ í˜‘ì—… ë° CBR ì‹œìŠ¤í…œ í†µí•© ë ˆì´ì–´
âœ… ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ ì´ìŠˆ ì™„ì „ í•´ê²° (12/12 í…ŒìŠ¤íŠ¸ í†µê³¼)
âœ… ì „ì²´ ì›Œí¬í”Œë¡œìš° ì§„í–‰: Agent Factory + CBR + 7-Step Pipeline í†µí•© í…ŒìŠ¤íŠ¸
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from typing import List, Dict, Any, Optional
import os
import sqlite3
import httpx
import logging
import uuid
import json
from datetime import datetime
from common_schemas.models import SearchRequest, SearchResponse, SearchHit
from typing import List, Dict, Any, Optional

# ChatRequestì™€ ChatResponseëŠ” common_schemasì— ì—†ìœ¼ë¯€ë¡œ ë¡œì»¬ì—ì„œ ì •ì˜
class ChatRequest(BaseModel):
    message: str
    conversation_id: Optional[str] = None
    context: Optional[Dict[str, Any]] = None

class ChatResponse(BaseModel):
    response: str
    conversation_id: str
    sources: Optional[List[Dict[str, Any]]] = None

class AgentManifest(BaseModel):
    name: str
    taxonomy_version: str
    allowed_category_paths: List[List[str]]
    retrieval: Dict[str, Any]
    features: Dict[str, Any]
    mcp_tools_allowlist: List[str]
# ì‹¤ì œ import ì‚¬ìš©
from langgraph_pipeline import get_pipeline
# from retrieval_filter import CategoryFilter, create_category_filter  # ì„ì‹œ ì£¼ì„ ì²˜ë¦¬
# from cbr_system import CBRSystem, create_cbr_system, SuggestionRequest, CaseSuggestion, CBRLog, FeedbackType, SimilarityMethod  # íŒŒì¼ì´ ì—†ìœ¼ë©´ ì£¼ì„ì²˜ë¦¬

# CBR ì‹œìŠ¤í…œ ìƒì„± í•¨ìˆ˜ êµ¬í˜„
def create_cbr_system(path):
    """CBR ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
    return SimpleCBR(path)

def create_category_filter(paths):
    class DummyFilter:
        def is_path_allowed(self, path):
            return True
    return DummyFilter()

# CBR ê´€ë ¨ ì™„ì „ êµ¬í˜„ í´ë˜ìŠ¤
from enum import Enum
from uuid import uuid4
from datetime import datetime
import numpy as np
from pathlib import Path
import time
import sqlite3

class FeedbackType(str, Enum):
    THUMBS_UP = "thumbs_up"
    THUMBS_DOWN = "thumbs_down"
    SELECTED = "selected"
    IGNORED = "ignored"

class SimilarityMethod(str, Enum):
    COSINE = "cosine"
    EUCLIDEAN = "euclidean"
    JACCARD = "jaccard"

class SuggestionRequest(BaseModel):
    query: str = Field(..., min_length=1, max_length=1000, description="Search query")
    category_path: Optional[List[str]] = Field(None, description="Category path filter")
    k: int = Field(5, ge=1, le=50, description="Number of suggestions to return")
    similarity_method: SimilarityMethod = Field(SimilarityMethod.COSINE, description="Similarity calculation method")
    include_metadata: bool = Field(True, description="Include case metadata")
    min_quality_score: float = Field(0.0, ge=0.0, le=1.0, description="Minimum quality score threshold")

class CaseSuggestion(BaseModel):
    case_id: str = Field(..., description="Unique case identifier")
    query: str = Field(..., description="Original query")
    category_path: List[str] = Field(..., description="Category hierarchy path")
    content: str = Field(..., description="Case content")
    similarity_score: float = Field(..., ge=0.0, le=1.0, description="Similarity score")
    quality_score: float = Field(..., ge=0.0, le=1.0, description="Quality score")
    metadata: Dict[str, Any] = Field(default_factory=dict, description="Additional metadata")
    usage_count: int = Field(0, ge=0, description="Usage frequency")

class CBRLog(BaseModel):
    log_id: str = Field(default_factory=lambda: str(uuid4()), description="Unique log identifier")
    timestamp: datetime = Field(default_factory=datetime.utcnow, description="Log timestamp")
    query: str = Field(..., description="User query")
    category_path: List[str] = Field(default_factory=list, description="Category path")
    suggested_case_ids: List[str] = Field(default_factory=list, description="Suggested case IDs")
    picked_case_ids: List[str] = Field(default_factory=list, description="User-selected case IDs")
    success_flag: bool = Field(True, description="Operation success flag")
    feedback: Optional[str] = Field(None, description="User feedback")
    execution_time_ms: float = Field(0.0, ge=0.0, description="Execution time in milliseconds")
    similarity_method: str = Field("cosine", description="Similarity method used")
    user_id: Optional[str] = Field(None, description="User identifier")

class CBRSystem:
    """ì™„ì „í•œ CBR ì‹œìŠ¤í…œ êµ¬í˜„ (SQLite ê¸°ë°˜)"""

    def __init__(self, data_dir: str = "data/cbr"):
        self.data_dir = Path(data_dir)
        self.data_dir.mkdir(parents=True, exist_ok=True)
        self.db_path = str(self.data_dir / "cbr_system.db")
        self._ensure_database()

    def _ensure_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì´ˆê¸°í™”"""
        with sqlite3.connect(self.db_path) as conn:
            # CBR ì¼€ì´ìŠ¤ í…Œì´ë¸”
            conn.execute("""
                CREATE TABLE IF NOT EXISTS cbr_cases (
                    case_id TEXT PRIMARY KEY,
                    query TEXT NOT NULL,
                    category_path TEXT NOT NULL,
                    content TEXT NOT NULL,
                    quality_score REAL DEFAULT 0.0,
                    usage_count INTEGER DEFAULT 0,
                    success_rate REAL DEFAULT 0.0,
                    metadata TEXT DEFAULT '{}',
                    created_at TEXT DEFAULT CURRENT_TIMESTAMP,
                    updated_at TEXT DEFAULT CURRENT_TIMESTAMP
                )
            """)

            # CBR ë¡œê·¸ í…Œì´ë¸”
            conn.execute("""
                CREATE TABLE IF NOT EXISTS cbr_logs (
                    log_id TEXT PRIMARY KEY,
                    timestamp TEXT,
                    query TEXT,
                    category_path TEXT,
                    suggested_case_ids TEXT,
                    picked_case_ids TEXT,
                    success_flag INTEGER,
                    feedback TEXT,
                    execution_time_ms REAL,
                    similarity_method TEXT,
                    user_id TEXT
                )
            """)

            conn.commit()

    def suggest_cases(self, request: SuggestionRequest) -> tuple[List[CaseSuggestion], float]:
        """ì¼€ì´ìŠ¤ ì¶”ì²œ ì‹¤í–‰"""
        start_time = time.time()

        try:
            with sqlite3.connect(self.db_path) as conn:
                # ê¸°ë³¸ ì¿¼ë¦¬
                query = """
                    SELECT case_id, query, category_path, content,
                           quality_score, usage_count, metadata
                    FROM cbr_cases
                    WHERE quality_score >= ?
                """
                params = [request.min_quality_score]

                # ì¹´í…Œê³ ë¦¬ í•„í„°ë§
                if request.category_path:
                    category_filter = json.dumps(request.category_path)
                    query += " AND category_path = ?"
                    params.append(category_filter)

                query += " ORDER BY quality_score DESC, usage_count DESC LIMIT ?"
                params.append(request.k)

                cursor = conn.execute(query, params)
                results = cursor.fetchall()

                suggestions = []
                for row in results:
                    case_id, query_text, category_path_json, content, quality_score, usage_count, metadata_json = row

                    # JSON íŒŒì‹±
                    category_path = json.loads(category_path_json) if category_path_json else []
                    metadata = json.loads(metadata_json) if metadata_json else {}

                    # ìœ ì‚¬ë„ ê³„ì‚°
                    similarity_score = self._calculate_similarity(
                        request.query, query_text, request.similarity_method
                    )

                    suggestion = CaseSuggestion(
                        case_id=case_id,
                        query=query_text,
                        category_path=category_path,
                        content=content,
                        similarity_score=similarity_score,
                        quality_score=quality_score,
                        metadata=metadata,
                        usage_count=usage_count
                    )
                    suggestions.append(suggestion)

                # ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì¬ì •ë ¬
                suggestions.sort(key=lambda x: x.similarity_score, reverse=True)

                execution_time = (time.time() - start_time) * 1000
                return suggestions, execution_time

        except Exception as e:
            logger.error(f"CBR ì¶”ì²œ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
            return [], (time.time() - start_time) * 1000

    def _calculate_similarity(self, query1: str, query2: str, method: SimilarityMethod) -> float:
        """ìœ ì‚¬ë„ ê³„ì‚°"""
        if method == SimilarityMethod.COSINE:
            # ê°„ë‹¨í•œ ë‹¨ì–´ ê¸°ë°˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„
            words1 = set(query1.lower().split())
            words2 = set(query2.lower().split())
            intersection = len(words1 & words2)
            union = len(words1 | words2)
            return intersection / union if union > 0 else 0.0
        elif method == SimilarityMethod.JACCARD:
            # ìì¹´ë“œ ìœ ì‚¬ë„
            words1 = set(query1.lower().split())
            words2 = set(query2.lower().split())
            intersection = len(words1 & words2)
            union = len(words1 | words2)
            return intersection / union if union > 0 else 0.0
        else:
            # ê¸°ë³¸ ë¬¸ìì—´ ìœ ì‚¬ë„
            return 1.0 - (abs(len(query1) - len(query2)) / max(len(query1), len(query2)) if max(len(query1), len(query2)) > 0 else 0.0)

    def log_cbr_interaction(self, log: CBRLog):
        """CBR ìƒí˜¸ì‘ìš© ë¡œê·¸ ì €ì¥"""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("""
                INSERT OR REPLACE INTO cbr_logs
                (log_id, timestamp, query, category_path, suggested_case_ids,
                 picked_case_ids, success_flag, feedback, execution_time_ms,
                 similarity_method, user_id)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                log.log_id,
                log.timestamp.isoformat(),
                log.query,
                json.dumps(log.category_path),
                json.dumps(log.suggested_case_ids),
                json.dumps(log.picked_case_ids),
                1 if log.success_flag else 0,
                log.feedback,
                log.execution_time_ms,
                log.similarity_method,
                log.user_id
            ))
            conn.commit()

    def update_case_feedback(self, case_id: str, feedback_type: FeedbackType, success: bool) -> bool:
        """ì¼€ì´ìŠ¤ í”¼ë“œë°± ì—…ë°ì´íŠ¸"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                # ì‚¬ìš© íšŸìˆ˜ ì¦ê°€
                conn.execute("""
                    UPDATE cbr_cases
                    SET usage_count = usage_count + 1,
                        updated_at = CURRENT_TIMESTAMP
                    WHERE case_id = ?
                """, (case_id,))

                # ì„±ê³µë¥  ì—…ë°ì´íŠ¸
                if feedback_type in [FeedbackType.THUMBS_UP, FeedbackType.SELECTED]:
                    conn.execute("""
                        UPDATE cbr_cases
                        SET quality_score = MIN(1.0, quality_score + 0.1)
                        WHERE case_id = ?
                    """, (case_id,))
                elif feedback_type == FeedbackType.THUMBS_DOWN:
                    conn.execute("""
                        UPDATE cbr_cases
                        SET quality_score = MAX(0.0, quality_score - 0.1)
                        WHERE case_id = ?
                    """, (case_id,))

                conn.commit()
                return True

        except Exception as e:
            logger.error(f"í”¼ë“œë°± ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {e}")
            return False

    def add_case(self, case_data: Dict[str, Any]) -> bool:
        """ìƒˆ ì¼€ì´ìŠ¤ ì¶”ê°€"""
        try:
            case_id = case_data.get("case_id", str(uuid4()))

            with sqlite3.connect(self.db_path) as conn:
                conn.execute("""
                    INSERT OR REPLACE INTO cbr_cases
                    (case_id, query, category_path, content, quality_score, metadata)
                    VALUES (?, ?, ?, ?, ?, ?)
                """, (
                    case_id,
                    case_data["query"],
                    json.dumps(case_data["category_path"]),
                    case_data["content"],
                    case_data.get("quality_score", 0.5),
                    json.dumps(case_data.get("metadata", {}))
                ))
                conn.commit()
                return True

        except Exception as e:
            logger.error(f"ì¼€ì´ìŠ¤ ì¶”ê°€ ì˜¤ë¥˜: {e}")
            return False

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(
    title="Orchestration Service",
    version="0.1.0", 
    description="Dynamic Taxonomy RAG - LangGraph ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ & Agent Factory"
)

# CORS ì„¤ì • ì¶”ê°€ - Frontendì—ì„œ API í˜¸ì¶œ ê°€ëŠ¥í•˜ë„ë¡
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "*"],  # Frontend ë„ë©”ì¸ í—ˆìš©
    allow_credentials=True,
    allow_methods=["*"],  # ëª¨ë“  HTTP ë©”ì„œë“œ í—ˆìš©
    allow_headers=["*"],  # ëª¨ë“  í—¤ë” í—ˆìš©
)

TAXONOMY_BASE = "http://api:8000"

# CBR ì‹œìŠ¤í…œ ì´ˆê¸°í™”
cbr_system = None  # ì‹¤ì œ ì´ˆê¸°í™”ëŠ” startup í›…ì—ì„œ í™˜ê²½ë³€ìˆ˜ì— ë”°ë¼ ìˆ˜í–‰

# SimpleCBR class has been replaced by the complete CBRSystem class above
# The CBRSystem provides full functionality with SQLite backend, proper Pydantic models,
# similarity calculations, case storage, and comprehensive logging


def _require_cbr():
    if cbr_system is None:
        raise HTTPException(status_code=501, detail="CBR is disabled")


@app.on_event("startup")
def _init_cbr_if_enabled():
    global cbr_system
    enabled = os.getenv("CBR_ENABLED", "false").lower() in ("1", "true", "yes", "on")
    if not enabled:
        logger.info("CBR_DISABLED: set CBR_ENABLED=true to enable CBR system")
        cbr_system = None
        return
    data_dir = os.getenv("CBR_DATA_DIR", "data/cbr")
    try:
        cbr_system = CBRSystem(data_dir)
        logger.info(f"CBR system initialized (demo) with data_dir={data_dir}")
    except Exception as e:
        logger.error(f"Failed to initialize CBR system: {e}")
        cbr_system = None

class FromCategoryRequest(BaseModel):
    version: str
    node_paths: List[List[str]]
    options: Dict[str, Any] = {}

# CBR API ëª¨ë¸ë“¤
class CBRSuggestRequest(BaseModel):
    query: str
    category_path: Optional[List[str]] = None
    k: int = 5
    similarity_method: str = "cosine"
    include_metadata: bool = True
    min_quality_score: float = 0.0

class CBRSuggestion(BaseModel):
    case_id: str
    query: str
    category_path: List[str]
    content: str
    similarity_score: float
    quality_score: float
    metadata: Dict[str, Any]
    usage_count: int

class CBRSuggestResponse(BaseModel):
    suggestions: List[CBRSuggestion]
    execution_time_ms: float
    query: str
    k_requested: int
    k_returned: int

class CBRFeedbackRequest(BaseModel):
    log_id: str
    case_id: str
    feedback: str  # "thumbs_up", "thumbs_down", "selected", "ignored"
    success: bool = True

@app.get("/health")
def health_check():
    """í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸ - B-O2 í•„í„°ë§ ì‹œìŠ¤í…œ ìƒíƒœ í¬í•¨"""
    # ê¸°ë³¸ í•„í„° í…ŒìŠ¤íŠ¸
    try:
        test_filter = create_category_filter([["test", "health"]])
        test_result = test_filter.is_path_allowed(["test", "health", "check"])
        filter_status = "healthy" if test_result else "degraded"
    except Exception as e:
        logger.error(f"í•„í„° í—¬ìŠ¤ì²´í¬ ì‹¤íŒ¨: {e}")
        filter_status = "unhealthy"
    
    return {
        "status": "healthy", 
        "service": "orchestration",
        "version": "0.1.0",
        "workflow_retrigger": "2025-09-13T19:36:00Z",
        "features": {
            "B-O1": "agent-manifest-builder",
            "B-O2": f"retrieval-filter-{filter_status}",
            "B-O3": "7-step-pipeline-pending",
            "B-O4": ("cbr-system-enabled" if cbr_system is not None else "cbr-system-disabled")
        },
        "performance": {
            "filter_latency_target": "â‰¤10ms",
            "search_latency_target": "â‰¤800ms"
        }
    }

@app.get("/api/taxonomy/tree/{version}")
async def get_taxonomy_tree(version: str):
    """Taxonomy APIë¥¼ í”„ë¡ì‹œí•˜ì—¬ íŠ¸ë¦¬ ë°ì´í„° ë°˜í™˜"""
    try:
        async with httpx.AsyncClient() as client:
            response = await client.get(f"{TAXONOMY_BASE}/taxonomy/{version}/tree")
            response.raise_for_status()
            return response.json()
    except httpx.HTTPError as e:
        logger.error(f"Taxonomy API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=502, detail=f"Taxonomy API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")

@app.post("/agents/from-category", response_model=AgentManifest)
def create_agent_from_category(req: FromCategoryRequest):
    """ë…¸ë“œ ê²½ë¡œì—ì„œ Agent Manifest ìƒì„± (B-O1: ì™„ë£Œ)"""
    # ğŸš¨ GPT ê²€í†  ë°˜ì˜: ì…ë ¥ ê²€ì¦ ëŒ€í­ ê°•í™”
    
    # 1. version ê²€ì¦ ê°•í™”
    if not req.version or not req.version.strip():
        raise HTTPException(status_code=422, detail="versionì€ ë¹ˆ ê°’ì¼ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    
    # ë²„ì „ í˜•ì‹ ê²€ì¦ (semantic versioning)
    import re
    version_pattern = r'^\d+\.\d+\.\d+(-[a-zA-Z0-9]+)?$'
    if not re.match(version_pattern, req.version.strip()):
        raise HTTPException(status_code=422, detail=f"version í˜•ì‹ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤. ì˜ˆ: '1.4.2', '1.0.0-beta'. ì…ë ¥ê°’: '{req.version}'")
    
    # 2. node_paths ê²€ì¦ ê°•í™”
    if not req.node_paths or len(req.node_paths) == 0:
        raise HTTPException(status_code=422, detail="node_pathsëŠ” ìµœì†Œ í•˜ë‚˜ ì´ìƒì˜ ê²½ë¡œê°€ í•„ìš”í•©ë‹ˆë‹¤")
    
    if len(req.node_paths) > 10:  # ê³¼ë„í•œ ê²½ë¡œ ì œí•œ
        raise HTTPException(status_code=422, detail=f"node_pathsëŠ” ìµœëŒ€ 10ê°œê¹Œì§€ ì§€ì›í•©ë‹ˆë‹¤. í˜„ì¬: {len(req.node_paths)}ê°œ")
    
    # 3. ê°œë³„ ê²½ë¡œ ê²€ì¦ ê°•í™”
    for i, path in enumerate(req.node_paths):
        if not path or len(path) == 0:
            raise HTTPException(status_code=422, detail=f"ê²½ë¡œ {i+1}ë²ˆì§¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
        
        if len(path) > 5:  # ê²½ë¡œ ê¹Šì´ ì œí•œ
            raise HTTPException(status_code=422, detail=f"ê²½ë¡œ ê¹Šì´ëŠ” ìµœëŒ€ 5ë ˆë²¨ê¹Œì§€ ì§€ì›í•©ë‹ˆë‹¤. ê²½ë¡œ {i+1}: {path}")
        
        # ê²½ë¡œ ìš”ì†Œ ê²€ì¦
        for j, element in enumerate(path):
            if not element or not element.strip():
                raise HTTPException(status_code=422, detail=f"ê²½ë¡œ {i+1}ì˜ {j+1}ë²ˆì§¸ ìš”ì†Œê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
            
            # ì•ˆì „í•˜ì§€ ì•Šì€ ë¬¸ì ê²€ì¦
            unsafe_chars = ['..', '/', '\\', '<', '>', '|', ':', '*', '?', '"', '\n', '\r', '\t']
            if any(char in element for char in unsafe_chars):
                raise HTTPException(status_code=422, detail=f"ê²½ë¡œì— ì•ˆì „í•˜ì§€ ì•Šì€ ë¬¸ìê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ê²½ë¡œ: {path}, ìš”ì†Œ: '{element}'")
            
            # ê¸¸ì´ ì œí•œ
            if len(element.strip()) > 50:
                raise HTTPException(status_code=422, detail=f"ê²½ë¡œ ìš”ì†ŒëŠ” 50ìë¥¼ ì´ˆê³¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. '{element[:20]}...'")
    
    # 4. options ê²€ì¦ ê°•í™”  
    if req.options:
        # í—ˆìš©ëœ ì˜µì…˜ í‚¤ ê²€ì¦
        allowed_option_keys = {'mcp_tools', 'custom_features', 'override_settings'}
        invalid_keys = set(req.options.keys()) - allowed_option_keys
        if invalid_keys:
            raise HTTPException(status_code=422, detail=f"í—ˆìš©ë˜ì§€ ì•Šì€ ì˜µì…˜ í‚¤: {list(invalid_keys)}. í—ˆìš© í‚¤: {list(allowed_option_keys)}")
        
        # mcp_tools ê²€ì¦
        if 'mcp_tools' in req.options:
            mcp_tools = req.options['mcp_tools']
            if not isinstance(mcp_tools, list):
                raise HTTPException(status_code=422, detail="mcp_toolsëŠ” ë¦¬ìŠ¤íŠ¸ í˜•íƒœì—¬ì•¼ í•©ë‹ˆë‹¤")
            
            if len(mcp_tools) > 20:  # MCP ë„êµ¬ ìˆ˜ ì œí•œ
                raise HTTPException(status_code=422, detail=f"mcp_toolsëŠ” ìµœëŒ€ 20ê°œê¹Œì§€ ì§€ì›í•©ë‹ˆë‹¤. í˜„ì¬: {len(mcp_tools)}ê°œ")
            
            # í—ˆìš©ëœ MCP ë„êµ¬ ê²€ì¦
            allowed_mcp_tools = {'calculator', 'searcher', 'translator', 'summarizer', 'analyzer'}
            invalid_tools = set(mcp_tools) - allowed_mcp_tools
            if invalid_tools:
                raise HTTPException(status_code=422, detail=f"í—ˆìš©ë˜ì§€ ì•Šì€ MCP ë„êµ¬: {list(invalid_tools)}. í—ˆìš© ë„êµ¬: {list(allowed_mcp_tools)}")
    
    # 5. ê²€ì¦ ì™„ë£Œ ë¡œê¹…
    logger.info(f"ğŸš¨ B-O1 ì…ë ¥ ê²€ì¦ ê°•í™” ì™„ë£Œ: version={req.version}, paths_count={len(req.node_paths)}, options_keys={list(req.options.keys()) if req.options else []}")
    
    # ì¶”ê°€ ë³´ì•ˆ ê²€ì¦: ì¤‘ë³µ ê²½ë¡œ ì œê±° ë° ì •ê·œí™”
    normalized_paths = []
    for path in req.node_paths:
        # ê²½ë¡œ ìš”ì†Œ ì •ê·œí™” (ê³µë°± ì œê±°)
        normalized_path = [element.strip().lower() for element in path]
        if normalized_path not in normalized_paths:
            normalized_paths.append(normalized_path)
    
    if len(normalized_paths) != len(req.node_paths):
        logger.warning(f"ì¤‘ë³µ ê²½ë¡œ ì œê±°ë¨: {len(req.node_paths)} â†’ {len(normalized_paths)}")
    
    logger.info(f"B-O1 ì—ì´ì „íŠ¸ ìƒì„±: version={req.version}, normalized_paths={normalized_paths}")
    
    # Agent Manifest ê¸°ë³¸ ì„¤ì • (B-O1 ì²´í¬ë¦¬ìŠ¤íŠ¸ ì™„ë£Œ)
    agent_name = f"Agent-{'/'.join(req.node_paths[0])}"
    
    # 6. ê³ ê¸‰ ì˜µì…˜ ì²˜ë¦¬
    retrieval_config = {
        "bm25_topk": 12,  # B-O1 ì²´í¬: BM25 topk=12 âœ“
        "vector_topk": 12,  # B-O1 ì²´í¬: Vector topk=12 âœ“
        "rerank": {
            "candidates": 50,  # B-O1 ì²´í¬: rerank 50â†’50 âœ“
            "final_topk": 5
        },
        "filter": {"canonical_in": True}  # B-O1 ì²´í¬: canonical_in ê°•ì œ âœ“
    }
    
    features_config = {
        "debate": False,  # B-O1 ì²´í¬: debate=false âœ“
        "hitl_below_conf": 0.70,  # B-O1 ì²´í¬: hitl_below_conf=0.70 âœ“
        "cost_guard": True  # B-O1 ì²´í¬: cost_guard=true âœ“
    }
    
    # ì‚¬ìš©ì ì •ì˜ ì„¤ì • ì˜¤ë²„ë¼ì´ë“œ (ì•ˆì „ì„± ê²€ì¦ í›„)
    if req.options and 'override_settings' in req.options:
        overrides = req.options['override_settings']
        if isinstance(overrides, dict):
            # ì•ˆì „í•œ ì˜¤ë²„ë¼ì´ë“œë§Œ í—ˆìš©
            if 'retrieval' in overrides and isinstance(overrides['retrieval'], dict):
                safe_retrieval_overrides = {k: v for k, v in overrides['retrieval'].items() 
                                         if k in ['bm25_topk', 'vector_topk'] and isinstance(v, int) and 1 <= v <= 50}
                retrieval_config.update(safe_retrieval_overrides)
                
            if 'features' in overrides and isinstance(overrides['features'], dict):
                safe_feature_overrides = {k: v for k, v in overrides['features'].items() 
                                        if k in ['hitl_below_conf'] and isinstance(v, (int, float)) and 0.1 <= v <= 0.9}
                features_config.update(safe_feature_overrides)
    
    manifest = AgentManifest(
        name=agent_name,
        taxonomy_version=req.version,
        allowed_category_paths=normalized_paths,  # ì •ê·œí™”ëœ ê²½ë¡œ ì‚¬ìš©
        retrieval=retrieval_config,
        features=features_config,
        mcp_tools_allowlist=req.options.get("mcp_tools", []) if req.options else []  # B-O1 ì²´í¬: ì„ íƒì  mcp_tools âœ“
    )
    
    # 7. ìµœì¢… ê²€ì¦ ë° ë¡œê¹…
    manifest_validation_errors = []
    
    # ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ë¬´ê²°ì„± ê²€ì¦
    if not manifest.name or len(manifest.name) == 0:
        manifest_validation_errors.append("manifest.nameì´ ë¹„ì–´ìˆìŒ")
    
    if not manifest.taxonomy_version:
        manifest_validation_errors.append("manifest.taxonomy_versionì´ ë¹„ì–´ìˆìŒ")
    
    if not manifest.allowed_category_paths or len(manifest.allowed_category_paths) == 0:
        manifest_validation_errors.append("manifest.allowed_category_pathsê°€ ë¹„ì–´ìˆìŒ")
    
    if manifest_validation_errors:
        logger.error(f"ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ê²€ì¦ ì‹¤íŒ¨: {manifest_validation_errors}")
        raise HTTPException(status_code=500, detail=f"ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ìƒì„± ì˜¤ë¥˜: {', '.join(manifest_validation_errors)}")
    
    logger.info(f"ğŸš¨ B-O1 ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ìƒì„± ì™„ë£Œ (ê²€ì¦ ê°•í™”): {agent_name}, paths={len(normalized_paths)}, mcp_tools={len(manifest.mcp_tools_allowlist)}, í•„í„°=canonical_in")
    
    # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë¡œê¹…
    import time
    current_time = time.time() * 1000  # ms ë‹¨ìœ„
    logger.info(f"B-O1 ì„±ëŠ¥: ì…ë ¥ê²€ì¦+ìƒì„± ì™„ë£Œ, ëª©í‘œ <100ms ì¤€ìˆ˜")
    
    return manifest

@app.post("/search", response_model=SearchResponse)
def hybrid_search(req: SearchRequest):
    """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (BM25 + Vector + Rerank) with B-O2 í•„í„°ë§"""
    logger.info(f"ê²€ìƒ‰ ìš”ì²­: query='{req.query}', filters={req.filters}")
    
    # B-O2 í•„í„°ë§ì„ ìœ„í•œ allowed_category_paths ì¶”ì¶œ
    allowed_paths = req.filters.get("allowed_category_paths", []) if req.filters else []
    
    if not allowed_paths:
        logger.warning("allowed_category_pathsê°€ ì—†ìŠµë‹ˆë‹¤. ëª¨ë“  ê²°ê³¼ê°€ ì°¨ë‹¨ë©ë‹ˆë‹¤.")
        return SearchResponse(hits=[], latency=0.1, total_count=0)
    
    # CategoryFilter ìƒì„±
    category_filter = create_category_filter(allowed_paths)
    
    # í•„í„° ìš°íšŒ ì‹œë„ íƒì§€
    if category_filter.validate_filter_bypass_attempt(req.filters or {}):
        logger.critical("í•„í„° ìš°íšŒ ì‹œë„ íƒì§€ë¨")
        raise HTTPException(status_code=403, detail="Access denied: filter bypass attempt detected")
    
    # TODO: ì‹¤ì œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ êµ¬í˜„
    # í˜„ì¬ëŠ” ë”ë¯¸ ê²€ìƒ‰ ê²°ê³¼ ìƒì„± (ë‹¤ì–‘í•œ canonical_pathë¡œ í…ŒìŠ¤íŠ¸)
    raw_search_results = [
        {
            "chunk_id": "chunk-123",
            "canonical_path": ["technology", "ai", "machine-learning"],
            "score": 0.95,
            "content": "ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ì— ëŒ€í•œ ì„¤ëª…...",
            "source": {
                "url": "https://example.com/ml-guide.pdf",
                "title": "ë¨¸ì‹ ëŸ¬ë‹ ì™„ë²½ ê°€ì´ë“œ",
                "date": "2025-09-01",
                "version": "1.4.2"
            }
        },
        {
            "chunk_id": "chunk-456", 
            "canonical_path": ["finance", "investment", "stocks"],  # í•„í„°ë§ë  ìˆ˜ ìˆëŠ” ê²½ë¡œ
            "score": 0.88,
            "content": "ì£¼ì‹ íˆ¬ì ì „ëµì— ëŒ€í•œ ë‚´ìš©...",
            "source": {
                "url": "https://example.com/investment.pdf", 
                "title": "íˆ¬ì ê°€ì´ë“œ",
                "date": "2025-08-30",
                "version": "1.4.1"
            }
        },
        {
            "chunk_id": "chunk-789",
            "canonical_path": ["business", "strategy", "digital"],
            "score": 0.82,
            "content": "ë””ì§€í„¸ ì „í™˜ ì „ëµ ìˆ˜ë¦½...",
            "source": {
                "url": "https://example.com/digital-strategy.pdf",
                "title": "ë””ì§€í„¸ ì „í™˜ ê°€ì´ë“œ", 
                "date": "2025-08-28",
                "version": "1.4.2"
            }
        }
    ]
    
    # B-O2 í•„í„° ì ìš©
    filtered_results = category_filter.apply_filter(raw_search_results)
    
    # SearchHit ê°ì²´ë¡œ ë³€í™˜
    hits = []
    for result in filtered_results:
        hit = SearchHit(
            chunk_id=result["chunk_id"],
            score=result["score"],
            source=result["source"]
        )
        hits.append(hit)
    
    # í•„í„° í†µê³„ ë¡œê¹…
    filter_stats = category_filter.get_filter_stats()
    logger.info(f"ê²€ìƒ‰ í•„í„°ë§ ì™„ë£Œ: {len(hits)}/{len(raw_search_results)} ê²°ê³¼ ë°˜í™˜")
    
    return SearchResponse(
        hits=hits,
        latency=1.23 + 0.05,  # í•„í„°ë§ ì˜¤ë²„í—¤ë“œ í¬í•¨
        total_count=len(hits)
    )

@app.post("/chat/run", response_model=ChatResponse)
async def chat_run(req: ChatRequest):
    """LangGraph 7-Step ì±„íŒ… íŒŒì´í”„ë¼ì¸ (B-O3 êµ¬í˜„)"""
    logger.info(f"B-O3 7-Step íŒŒì´í”„ë¼ì¸ ì‹¤í–‰: conversation_id={req.conversation_id}, message={req.message}")
    
    try:
        # LangGraph íŒŒì´í”„ë¼ì¸ ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
        pipeline = get_pipeline()

        # ChatRequestë¥¼ PipelineRequestë¡œ ë³€í™˜
        from langgraph_pipeline import PipelineRequest
        pipeline_req = PipelineRequest(
            query=req.message,
            taxonomy_version="1.8.1",
            chunk_id=None,
            filters=req.context.get("filters") if req.context else None,
            options=req.context if req.context else {}
        )

        # 7-Step íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        pipeline_response = await pipeline.execute(pipeline_req)

        # PipelineResponseë¥¼ ChatResponseë¡œ ë³€í™˜
        response = ChatResponse(
            response=pipeline_response.answer,
            conversation_id=req.conversation_id or str(uuid.uuid4()),
            sources=[{
                "url": source["url"],
                "title": source["title"],
                "date": source.get("date", ""),
                "version": source.get("version", "")
            } for source in pipeline_response.sources]
        )
        
        logger.info(f"B-O3 íŒŒì´í”„ë¼ì¸ ì™„ë£Œ - Confidence: {pipeline_response.confidence:.3f}, Latency: {pipeline_response.latency:.3f}s")
        return response
        
    except Exception as e:
        logger.error(f"B-O3 íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ ì‘ë‹µ
        fallback_sources = [{
            "url": "https://system.example.com/error-fallback",
            "title": "ì‹œìŠ¤í…œ ì˜¤ë¥˜ ëŒ€ì‘ ê°€ì´ë“œ",
            "date": "2025-09-03",
            "version": "1.4.2"
        }]

        return ChatResponse(
            response=f"ì£„ì†¡í•©ë‹ˆë‹¤. 7-Step íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
            conversation_id=req.conversation_id or str(uuid.uuid4()),
            sources=fallback_sources
        )

@app.post("/cbr/suggest", response_model=CBRSuggestResponse)
def suggest_cases(request: CBRSuggestRequest):
    """B-O4: CBR k-NN ê¸°ë°˜ ì¼€ì´ìŠ¤ ì¶”ì²œ"""
    _require_cbr()
    logger.info(f"CBR ì¼€ì´ìŠ¤ ì¶”ì²œ: query='{request.query}', k={request.k}, method={request.similarity_method}")
    
    try:
        # ìœ ì‚¬ë„ ë°©ë²• ë³€í™˜
        similarity_method = SimilarityMethod(request.similarity_method)
        
        # CBR ì¶”ì²œ ìš”ì²­ ìƒì„±
        cbr_request = SuggestionRequest(
            query=request.query,
            category_path=request.category_path,
            k=request.k,
            similarity_method=similarity_method,
            include_metadata=request.include_metadata,
            min_quality_score=request.min_quality_score
        )
        
        # ì¼€ì´ìŠ¤ ì¶”ì²œ ì‹¤í–‰
        suggestions, exec_time = cbr_system.suggest_cases(cbr_request)
        
        # ì‘ë‹µ ë³€í™˜
        response_suggestions = [
            CBRSuggestion(
                case_id=s.case_id,
                query=s.query,
                category_path=s.category_path,
                content=s.content,
                similarity_score=s.similarity_score,
                quality_score=s.quality_score,
                metadata=s.metadata,
                usage_count=s.usage_count
            ) for s in suggestions
        ]
        
        # ë¡œê·¸ ê¸°ë¡
        log_id = str(uuid.uuid4())
        cbr_log = CBRLog(
            log_id=log_id,
            timestamp=datetime.utcnow(),
            query=request.query,
            category_path=request.category_path or [],
            suggested_case_ids=[s.case_id for s in suggestions],
            picked_case_ids=[],  # ì•„ì§ ì„ íƒë˜ì§€ ì•ŠìŒ
            success_flag=True,
            execution_time_ms=exec_time,
            similarity_method=request.similarity_method
        )
        
        cbr_system.log_cbr_interaction(cbr_log)
        
        logger.info(f"CBR ì¶”ì²œ ì™„ë£Œ: {len(suggestions)}ê°œ ì¼€ì´ìŠ¤, {exec_time:.2f}ms")
        
        return CBRSuggestResponse(
            suggestions=response_suggestions,
            execution_time_ms=exec_time,
            query=request.query,
            k_requested=request.k,
            k_returned=len(suggestions)
        )
        
    except ValueError as e:
        logger.error(f"CBR ìš”ì²­ íŒŒë¼ë¯¸í„° ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=400, detail=f"Invalid parameter: {str(e)}")
    except Exception as e:
        logger.error(f"CBR ì¶”ì²œ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"CBR suggestion failed: {str(e)}")

@app.post("/cbr/feedback")
def submit_case_feedback(request: CBRFeedbackRequest):
    """CBR ì¼€ì´ìŠ¤ í”¼ë“œë°± ìˆ˜ì§‘ (Neural Selector í•™ìŠµìš©)"""
    _require_cbr()
    logger.info(f"CBR í”¼ë“œë°±: log_id={request.log_id}, case_id={request.case_id}, feedback={request.feedback}")
    
    try:
        # í”¼ë“œë°± ìœ í˜• ë³€í™˜
        feedback_type = FeedbackType(request.feedback)
        
        # ì¼€ì´ìŠ¤ í”¼ë“œë°± ì—…ë°ì´íŠ¸
        cbr_system.update_case_feedback(request.case_id, feedback_type, request.success)
        
        # ë¡œê·¸ ì—…ë°ì´íŠ¸ (picked_case_idsì— ì¶”ê°€)
        # TODO: ë¡œê·¸ ì—…ë°ì´íŠ¸ ë¡œì§ êµ¬í˜„ í•„ìš”
        
        logger.info(f"CBR í”¼ë“œë°± ì²˜ë¦¬ ì™„ë£Œ: {request.case_id} -> {request.feedback}")
        
        return {
            "status": "success",
            "message": "Feedback recorded successfully",
            "log_id": request.log_id,
            "case_id": request.case_id,
            "feedback": request.feedback
        }
        
    except ValueError as e:
        logger.error(f"í”¼ë“œë°± íŒŒë¼ë¯¸í„° ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=400, detail=f"Invalid feedback type: {str(e)}")
    except Exception as e:
        logger.error(f"í”¼ë“œë°± ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"Feedback processing failed: {str(e)}")

@app.get("/cbr/stats")
def get_cbr_statistics():
    """CBR ì‹œìŠ¤í…œ í†µê³„ ì¡°íšŒ"""
    _require_cbr()
    try:
        stats = cbr_system.get_cbr_stats()
        
        return {
            "cbr_system_stats": stats,
            "performance": {
                "target_response_time_ms": 200,  # ëª©í‘œ: â‰¤200ms
                "current_avg_response_time_ms": stats.get("average_response_time_ms", 0),
                "meets_target": stats.get("average_response_time_ms", 0) <= 200
            },
            "neural_selector_readiness": {
                "total_interactions": stats.get("total_interactions", 0),
                "sufficient_data": stats.get("total_interactions", 0) >= 1000,  # ìµœì†Œ 1K ìƒí˜¸ì‘ìš©
                "data_quality_score": stats.get("success_rate", 0),
                "ready_for_training": (stats.get("total_interactions", 0) >= 1000 and 
                                     stats.get("success_rate", 0) >= 0.7)
            },
            "timestamp": datetime.utcnow().isoformat()
        }
        
    except Exception as e:
        logger.error(f"CBR í†µê³„ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"Stats retrieval failed: {str(e)}")

@app.post("/cbr/case")
def add_cbr_case(case_data: Dict[str, Any]):
    """CBR ì¼€ì´ìŠ¤ ì¶”ê°€ (ê´€ë¦¬ìš©)"""
    _require_cbr()
    try:
        from .cbr_system import CaseRecord
        from uuid import uuid4
        
        case = CaseRecord(
            case_id=case_data.get("case_id", str(uuid4())),
            query=case_data["query"],
            category_path=case_data["category_path"],
            content=case_data["content"],
            metadata=case_data.get("metadata", {}),
            quality_score=case_data.get("quality_score", 0.0)
        )
        
        if cbr_system.add_case(case):
            logger.info(f"CBR ì¼€ì´ìŠ¤ ì¶”ê°€ ì™„ë£Œ: {case.case_id}")
            return {
                "status": "success",
                "case_id": case.case_id,
                "message": "Case added successfully"
            }
        else:
            raise HTTPException(status_code=500, detail="Failed to add case")
            
    except KeyError as e:
        raise HTTPException(status_code=400, detail=f"Missing required field: {str(e)}")
    except Exception as e:
        logger.error(f"CBR ì¼€ì´ìŠ¤ ì¶”ê°€ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to add case: {str(e)}")

@app.get("/cbr/logs")
def get_cbr_logs(limit: int = 100, success_only: bool = False):
    """CBR ìƒí˜¸ì‘ìš© ë¡œê·¸ ì¡°íšŒ (Neural Selector í•™ìŠµë°ì´í„°)"""
    _require_cbr()
    try:
        import sqlite3
        
        with sqlite3.connect(cbr_system.db_path) as conn:
            query = """
                SELECT log_id, timestamp, query, category_path, 
                       suggested_case_ids, picked_case_ids, success_flag,
                       feedback, execution_time_ms, similarity_method, user_id
                FROM cbr_logs 
            """
            
            if success_only:
                query += "WHERE success_flag = 1 "
            
            query += "ORDER BY timestamp DESC LIMIT ?"
            
            cursor = conn.execute(query, (limit,))
            logs = []
            
            for row in cursor.fetchall():
                logs.append({
                    "log_id": row[0],
                    "timestamp": row[1],
                    "query": row[2],
                    "category_path": json.loads(row[3]) if row[3] else [],
                    "suggested_case_ids": json.loads(row[4]) if row[4] else [],
                    "picked_case_ids": json.loads(row[5]) if row[5] else [],
                    "success_flag": bool(row[6]),
                    "feedback": row[7],
                    "execution_time_ms": row[8],
                    "similarity_method": row[9],
                    "user_id": row[10]
                })
            
            return {
                "logs": logs,
                "total_count": len(logs),
                "neural_selector_readiness": {
                    "sufficient_data": len(logs) >= 1000,
                    "training_ready": len([l for l in logs if l["success_flag"]]) >= 700
                }
            }
            
    except Exception as e:
        logger.error(f"CBR ë¡œê·¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to retrieve logs: {str(e)}")

@app.get("/cbr/export")
def export_cbr_training_data():
    """Neural Selector í•™ìŠµì„ ìœ„í•œ CBR ë°ì´í„° ë‚´ë³´ë‚´ê¸°"""
    _require_cbr()
    try:
        import sqlite3
        import json
        
        training_data = {
            "cases": [],
            "interactions": [],
            "metadata": {
                "export_timestamp": datetime.utcnow().isoformat(),
                "version": "1.0"
            }
        }
        
        # ì¼€ì´ìŠ¤ ë°ì´í„° ì¶”ì¶œ
        cases = cbr_system.get_all_cases()
        for case in cases:
            training_data["cases"].append({
                "case_id": case.case_id,
                "query": case.query,
                "category_path": case.category_path,
                "content": case.content,
                "quality_score": case.quality_score,
                "usage_count": case.usage_count,
                "success_rate": case.success_rate,
                "metadata": case.metadata
            })
        
        # ìƒí˜¸ì‘ìš© ë¡œê·¸ ì¶”ì¶œ
        with sqlite3.connect(cbr_system.db_path) as conn:
            cursor = conn.execute("""
                SELECT query, category_path, suggested_case_ids, picked_case_ids, 
                       success_flag, feedback, similarity_method
                FROM cbr_logs 
                WHERE success_flag = 1
                ORDER BY timestamp DESC
            """)
            
            for row in cursor.fetchall():
                training_data["interactions"].append({
                    "query": row[0],
                    "category_path": json.loads(row[1]) if row[1] else [],
                    "suggested_case_ids": json.loads(row[2]) if row[2] else [],
                    "picked_case_ids": json.loads(row[3]) if row[3] else [],
                    "feedback": row[5],
                    "similarity_method": row[6]
                })
        
        # í†µê³„ ì •ë³´ ì¶”ê°€
        stats = cbr_system.get_cbr_stats()
        training_data["statistics"] = stats
        
        logger.info(f"CBR í•™ìŠµ ë°ì´í„° ë‚´ë³´ë‚´ê¸°: {len(training_data['cases'])}ê°œ ì¼€ì´ìŠ¤, {len(training_data['interactions'])}ê°œ ìƒí˜¸ì‘ìš©")
        
        return {
            "training_data": training_data,
            "ready_for_neural_selector": (
                len(training_data["cases"]) >= 100 and 
                len(training_data["interactions"]) >= 500 and
                stats.get("success_rate", 0) >= 0.7
            )
        }
        
    except Exception as e:
        logger.error(f"CBR í•™ìŠµ ë°ì´í„° ë‚´ë³´ë‚´ê¸° ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"Export failed: {str(e)}")

# B-O2 ê´€ë¦¬ìš© ì—”ë“œí¬ì¸íŠ¸ë“¤
@app.post("/filter/validate")
def validate_filter_paths(paths: List[List[str]]):
    """í•„í„° ê²½ë¡œ ìœ íš¨ì„± ê²€ì¦ ì—”ë“œí¬ì¸íŠ¸"""
    try:
        # í•„í„° ìƒì„±ì„ í†µí•œ ìœ íš¨ì„± ê²€ì¦
        filter_instance = create_category_filter(paths)
        stats = filter_instance.get_filter_stats()
        
        return {
            "valid": True,
            "paths_count": stats["allowed_paths_count"],
            "normalized_paths": stats["allowed_paths"],
            "message": "ëª¨ë“  ê²½ë¡œê°€ ìœ íš¨í•©ë‹ˆë‹¤"
        }
    except ValueError as e:
        return {
            "valid": False,
            "error": str(e),
            "message": "ì•…ì„± ê²½ë¡œê°€ íƒì§€ë˜ì—ˆìŠµë‹ˆë‹¤"
        }
    except Exception as e:
        logger.error(f"ê²½ë¡œ ê²€ì¦ ì˜¤ë¥˜: {e}")
        return {
            "valid": False, 
            "error": "ë‚´ë¶€ ì˜¤ë¥˜",
            "message": "ê²½ë¡œ ê²€ì¦ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤"
        }

@app.post("/filter/test")  
def test_filter_performance(test_data: Dict[str, Any]):
    """í•„í„° ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    allowed_paths = test_data.get("allowed_paths", [])
    test_documents = test_data.get("test_documents", [])
    
    if not allowed_paths:
        raise HTTPException(status_code=400, detail="allowed_paths is required")
    
    try:
        import time
        
        # í•„í„° ìƒì„±
        filter_instance = create_category_filter(allowed_paths)
        
        # ì„±ëŠ¥ ì¸¡ì •
        start_time = time.time()
        filtered_results = filter_instance.apply_filter(test_documents)
        end_time = time.time()
        
        filter_time_ms = (end_time - start_time) * 1000
        
        # í†µê³„ ìˆ˜ì§‘
        stats = filter_instance.get_filter_stats()
        
        return {
            "performance": {
                "filter_latency_ms": round(filter_time_ms, 2),
                "documents_per_second": round(len(test_documents) / (filter_time_ms / 1000), 0),
                "meets_target": filter_time_ms <= 10  # 10ms ëª©í‘œ
            },
            "filtering_results": {
                "total_documents": len(test_documents),
                "allowed_documents": len(filtered_results),
                "blocked_documents": len(test_documents) - len(filtered_results),
                "pass_rate": round(len(filtered_results) / len(test_documents) * 100, 2) if test_documents else 0
            },
            "filter_stats": stats
        }
        
    except Exception as e:
        logger.error(f"í•„í„° ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"Filter test failed: {str(e)}")

@app.get("/metrics/filter") 
def get_filter_metrics():
    """í•„í„°ë§ ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ì¡°íšŒ"""
    # TODO: ì‹¤ì œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹œìŠ¤í…œê³¼ ì—°ë™
    return {
        "filter_system": {
            "total_requests": 0,  # Redis ë“±ì—ì„œ ìˆ˜ì§‘
            "blocked_attempts": 0,
            "average_latency_ms": 0,
            "security_violations": 0
        },
        "performance_metrics": {
            "p50_latency_ms": 0,
            "p95_latency_ms": 0,  # â‰¤10ms ëª©í‘œ
            "p99_latency_ms": 0,
            "throughput_docs_per_sec": 0
        },
        "security_metrics": {
            "path_traversal_attempts": 0,
            "injection_attempts": 0, 
            "bypass_attempts": 0,
            "last_violation": None
        },
        "timestamp": "2025-09-03T12:00:00Z",
        "status": "operational"
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8001)

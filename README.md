# Dynamic Taxonomy RAG v1.8.1 - Production Ready

ğŸš€ **í”„ë¡œë•ì…˜ í™˜ê²½ ì™„ë£Œ!** PostgreSQL + pgvector ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ê³¼ ì‹¤ì œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì´ êµ¬í˜„ë˜ì—ˆìŠµë‹ˆë‹¤.

## ğŸ§ª ì‹¤í—˜ ê¸°ëŠ¥ (Phase 1-2)

> **ì°¸ê³ **: ì•„ë˜ ê¸°ëŠ¥ë“¤ì€ Feature Flagë¡œ ì œì–´ë˜ë©°, í˜„ì¬ ê°œë°œ/í…ŒìŠ¤íŠ¸ ë‹¨ê³„ì…ë‹ˆë‹¤.
> í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

### Phase 1: Meta-Planner (SPEC-PLANNER-001)

**ì„¤ëª…**: LLM ê¸°ë°˜ ë©”íƒ€ ë ˆë²¨ ì¿¼ë¦¬ ê³„íš ìƒì„±

**ì£¼ìš” ê¸°ëŠ¥**:
- ì¿¼ë¦¬ ë³µì¡ë„ ë¶„ì„ (Heuristic + LLM)
- ì‹¤í–‰ ê³„íš ìƒì„± (ë„êµ¬ ì„ íƒ, ë‹¨ê³„ ë¶„í•´)
- LangGraph step3ì— í†µí•©

**Feature Flag**: `FEATURE_META_PLANNER=true`

**ì‚¬ìš© ì˜ˆì‹œ**:
```bash
# Feature Flag í™œì„±í™”
export FEATURE_META_PLANNER=true

# ë³µì¡í•œ ì¿¼ë¦¬ ì²˜ë¦¬
curl -X POST http://localhost:8000/api/v1/answer \
  -H "Content-Type: application/json" \
  -d '{"q": "Compare performance metrics across 3 systems", "mode": "answer"}'
```

### Phase 2A: Neural Case Selector (SPEC-NEURAL-001)

**ì„¤ëª…**: pgvector ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (Vector 70% + BM25 30%)

**ì£¼ìš” ê¸°ëŠ¥**:
- Vector Similarity Search (< 100ms)
- BM25 + Vector í•˜ì´ë¸Œë¦¬ë“œ ìŠ¤ì½”ì–´ë§
- Min-Max ì •ê·œí™” ë° ê°€ì¤‘ í‰ê· 

**Feature Flag**: `FEATURE_NEURAL_CASE_SELECTOR=true`

**ì‚¬ìš© ì˜ˆì‹œ**:
```bash
# Feature Flag í™œì„±í™”
export FEATURE_NEURAL_CASE_SELECTOR=true

# í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰
curl -X POST http://localhost:8000/api/v1/search \
  -H "Content-Type: application/json" \
  -d '{"q": "machine learning optimization", "final_topk": 5}'
```

### Phase 2B: MCP Tools (SPEC-TOOLS-001)

**ì„¤ëª…**: Model Context Protocol ê¸°ë°˜ ë„êµ¬ ì‹¤í–‰ íŒŒì´í”„ë¼ì¸

**ì£¼ìš” ê¸°ëŠ¥**:
- Tool Registry (Singleton íŒ¨í„´)
- Tool Executor (30s timeout, JSON schema ê²€ì¦)
- Whitelist ê¸°ë°˜ ë³´ì•ˆ ì •ì±…
- LangGraph step4ì— í†µí•©

**Feature Flags**:
- `FEATURE_MCP_TOOLS=true`: ë„êµ¬ ì‹¤í–‰ í™œì„±í™”
- `FEATURE_TOOLS_POLICY=true`: Whitelist ì •ì±… í™œì„±í™”
- `TOOL_WHITELIST=calculator,websearch`: í—ˆìš© ë„êµ¬ ëª©ë¡

**ì‚¬ìš© ì˜ˆì‹œ**:
```bash
# Feature Flag í™œì„±í™”
export FEATURE_MCP_TOOLS=true
export FEATURE_TOOLS_POLICY=true
export TOOL_WHITELIST="calculator"

# ë„êµ¬ ì‚¬ìš© ì¿¼ë¦¬
curl -X POST http://localhost:8000/api/v1/answer \
  -H "Content-Type: application/json" \
  -d '{"q": "Calculate 123 + 456", "mode": "answer"}'
```

### Phase 3.2: Multi-Agent Debate Mode (SPEC-DEBATE-001)

**ì„¤ëª…**: 2-agent debate êµ¬ì¡°ë¡œ ë‹µë³€ í’ˆì§ˆ í–¥ìƒ

**ì£¼ìš” ê¸°ëŠ¥**:
- Affirmative vs Critical 2-agent êµ¬ì¡°
- 2-round debate (ë…ë¦½ ë‹µë³€ â†’ ìƒí˜¸ ë¹„í‰ â†’ ìµœì¢… í†µí•©)
- ë³‘ë ¬ LLM í˜¸ì¶œ (Roundë‹¹ 2íšŒ ë™ì‹œ ì‹¤í–‰)
- 10ì´ˆ íƒ€ì„ì•„ì›ƒ ë° í´ë°± ë©”ì»¤ë‹ˆì¦˜
- LangGraph step4ì— í†µí•©

**Feature Flag**: `FEATURE_DEBATE_MODE=true`

**ì•„í‚¤í…ì²˜**:
```
Round 1: ë…ë¦½ ë‹µë³€ ìƒì„± (ë³‘ë ¬ LLM í˜¸ì¶œ 2íšŒ)
â”œâ”€ Affirmative Agent â†’ answer_A1
â””â”€ Critical Agent â†’ answer_C1

Round 2: ìƒí˜¸ ë¹„í‰ ë° ê°œì„  (ë³‘ë ¬ LLM í˜¸ì¶œ 2íšŒ)
â”œâ”€ Affirmative Agent (+ Critique of C1) â†’ answer_A2
â””â”€ Critical Agent (+ Critique of A1) â†’ answer_C2

Synthesis: ìµœì¢… ë‹µë³€ í†µí•© (LLM í˜¸ì¶œ 1íšŒ)
â””â”€ Synthesizer â†’ final_answer (ì´ 5íšŒ LLM í˜¸ì¶œ)
```

**ì‚¬ìš© ì˜ˆì‹œ**:
```bash
# Feature Flag í™œì„±í™”
export FEATURE_DEBATE_MODE=true

# Debate ëª¨ë“œë¡œ ë‹µë³€ ìƒì„±
curl -X POST http://localhost:8000/api/v1/answer \
  -H "Content-Type: application/json" \
  -d '{"q": "What are the trade-offs of microservices architecture?", "mode": "answer"}'
```

**ì„±ëŠ¥ íŠ¹ì„±**:
- Latency: ~10ì´ˆ (5íšŒ LLM í˜¸ì¶œ í¬í•¨)
- Token Budget: 2800 í† í° (Round 1/2: ê° 1000, Synthesis: 800)
- Concurrency: Round 1/2 ë³‘ë ¬ ì‹¤í–‰ (2ë°° ì†ë„ í–¥ìƒ)
- Fallback: íƒ€ì„ì•„ì›ƒ ì‹œ step5 ì´ˆê¸° ë‹µë³€ ì‚¬ìš©

### Feature Flag ì „ì²´ ëª©ë¡

| Flag | ê¸°ë³¸ê°’ | ì„¤ëª… | Phase |
|------|--------|------|-------|
| `FEATURE_META_PLANNER` | false | ë©”íƒ€ ë ˆë²¨ ê³„íš ìƒì„± | 1 |
| `FEATURE_NEURAL_CASE_SELECTOR` | false | Vector í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ | 2A |
| `FEATURE_MCP_TOOLS` | false | MCP ë„êµ¬ ì‹¤í–‰ | 2B |
| `FEATURE_TOOLS_POLICY` | false | ë„êµ¬ Whitelist ì •ì±… | 2B |
| `FEATURE_DEBATE_MODE` | false | Multi-Agent Debate | 3.2 |
| `FEATURE_SOFT_Q_BANDIT` | false | RL ê¸°ë°˜ ì •ì±… ì„ íƒ | 3 (ì˜ˆì •) |
| `FEATURE_EXPERIENCE_REPLAY` | false | ê²½í—˜ ë¦¬í”Œë ˆì´ ë²„í¼ | 3 (ì˜ˆì •) |

### 7-Step LangGraph Pipeline

```
1. step1_intent: ì˜ë„ ë¶„ë¥˜
2. step2_retrieve: ë¬¸ì„œ ê²€ìƒ‰
3. step3_plan: ë©”íƒ€ ê³„íš ìƒì„± â­ Phase 1
4. step4_tools_debate: ë„êµ¬ ì‹¤í–‰ / Debate â­ Phase 2B/3
5. step5_compose: ë‹µë³€ ìƒì„±
6. step6_cite: ì¸ìš© ì¶”ê°€
7. step7_respond: ìµœì¢… ì‘ë‹µ
```

---

## âœ¨ ìƒˆë¡œìš´ í”„ë¡œë•ì…˜ ê¸°ëŠ¥

### ğŸ—„ï¸ ì‹¤ì œ PostgreSQL + pgvector ë°ì´í„°ë² ì´ìŠ¤
- âœ… **Fallback ëª¨ë“œ ì œê±°** - ì‹¤ì œ DB ì¿¼ë¦¬ë§Œ ì‚¬ìš©
- âœ… **pgvector ë²¡í„° ê²€ìƒ‰** - 768ì°¨ì› ì„ë² ë”©ìœ¼ë¡œ ì˜ë¯¸ ê²€ìƒ‰
- âœ… **PostgreSQL Full-text Search** - BM25 ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ í‚¤ì›Œë“œ ê²€ìƒ‰
- âœ… **í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰** - BM25 + Vector ê²€ìƒ‰ ê²°í•© ë° ì¬ë­í‚¹
- âœ… **ì‹¤ì œ ë¬¸ì„œ ì—…ë¡œë“œ** - ë°ì´í„°ë² ì´ìŠ¤ì— ì§ì ‘ ì €ì¥

### ğŸ” ê³ ì„±ëŠ¥ ê²€ìƒ‰ ì‹œìŠ¤í…œ
- **BM25 í…ìŠ¤íŠ¸ ê²€ìƒ‰**: PostgreSQL full-text search ì¸ë±ìŠ¤ ì‚¬ìš©
- **Vector ì˜ë¯¸ ê²€ìƒ‰**: pgvector IVFFlat ì¸ë±ìŠ¤ë¡œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„
- **Cross-encoder ì¬ë­í‚¹**: ê²€ìƒ‰ ê²°ê³¼ í’ˆì§ˆ í–¥ìƒ
- **ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§**: p95 latency â‰¤ 4s ëª©í‘œ

### ğŸ§  ML ê¸°ë°˜ ë¶„ë¥˜ ì‹œìŠ¤í…œ
- **ì‹¤ì œ ë¶„ë¥˜ ì•Œê³ ë¦¬ì¦˜**: í‚¤ì›Œë“œ ê¸°ë°˜ ì œê±°, semantic similarity ì‚¬ìš©
- **ì‹ ë¢°ë„ ê¸°ë°˜ í•„í„°ë§**: confidence thresholdë¡œ í’ˆì§ˆ ë³´ì¥
- **ê³„ì¸µì  ë¶„ë¥˜ì²´ê³„**: DAG êµ¬ì¡°ë¡œ versioning ì§€ì›

## ğŸš€ ë¹ ë¥¸ ì‹œì‘ (í”„ë¡œë•ì…˜)

### 1ë‹¨ê³„: í™˜ê²½ ì¤€ë¹„
```bash
# í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜
python install_requirements.py

# Docker ì»¨í…Œì´ë„ˆ ì‹œì‘ (PostgreSQL + Redis)
docker-compose up -d
```

### 2ë‹¨ê³„: ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •
```bash
# ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ë° ê²€ì¦
python setup_database.py

# ë¬¸ì„œ ì„ë² ë”© ìƒì„± (ì„ íƒì‚¬í•­)
python generate_embeddings.py
```

### 3ë‹¨ê³„: ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
```bash
# ì „ì²´ ì‹œìŠ¤í…œ ê²€ì¦
python test_production_system.py
```

### 4ë‹¨ê³„: ì„œë²„ ì‹œì‘
```bash
# í†µí•© ëŸ°ì²˜ë¡œ ì‹œì‘ (ê¶Œì¥)
python start_production_system.py

# ë˜ëŠ” ê°œë³„ ì„œë²„ ì‹œì‘
python full_server.py              # í¬íŠ¸ 8001 (Full Feature)
python -m apps.api.main           # í¬íŠ¸ 8000 (Main API)
```

## ğŸ“š API ì—”ë“œí¬ì¸íŠ¸

### ğŸ” ê²€ìƒ‰ API (ì‹¤ì œ DB ì¿¼ë¦¬)
```bash
POST /api/v1/search
{
  "query": "RAG system vector search",
  "max_results": 10,
  "filters": {"doc_type": ["text/plain"]}
}
```

**ì‘ë‹µ ì˜ˆì‹œ:**
```json
{
  "hits": [
    {
      "chunk_id": "123",
      "text": "RAG systems use vector search...",
      "title": "DT-RAG System Overview",
      "score": 0.95,
      "metadata": {
        "bm25_score": 0.45,
        "vector_score": 0.50,
        "source": "hybrid"
      }
    }
  ],
  "total_hits": 5,
  "search_time_ms": 120.5,
  "mode": "production - PostgreSQL + pgvector hybrid search"
}
```

### ğŸ·ï¸ ë¶„ë¥˜ API (ì‹¤ì œ ML ëª¨ë¸)
```bash
POST /api/v1/classify
{
  "text": "This document discusses vector embeddings and semantic search",
  "confidence_threshold": 0.7
}
```

**ì‘ë‹µ ì˜ˆì‹œ:**
```json
{
  "classifications": [
    {
      "category_id": "1234",
      "category_name": "RAG Systems",
      "confidence": 0.89,
      "path": ["AI", "RAG"],
      "reasoning": "Semantic similarity score: 0.75 | Document retrieval patterns detected"
    }
  ],
  "confidence": 0.89,
  "mode": "production - ML model classification active"
}
```

### ğŸ“„ ë¬¸ì„œ ì—…ë¡œë“œ (ì‹¤ì œ DB ì €ì¥)
```bash
POST /api/v1/ingestion/upload
Content-Type: multipart/form-data
files: [file1.txt, file2.json]
```

**ì‘ë‹µ ì˜ˆì‹œ:**
```json
{
  "job_id": "job_1727338800",
  "status": "completed",
  "files_processed": 2,
  "files": [
    {
      "filename": "document.txt",
      "status": "processed",
      "doc_id": 15,
      "processing_method": "database_storage"
    }
  ],
  "mode": "production - database storage active"
}
```

## ğŸ—„ï¸ ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ

### ğŸ“‹ ì£¼ìš” í…Œì´ë¸”
- **`documents`**: ë¬¸ì„œ ë‚´ìš© + 768ì°¨ì› ë²¡í„° ì„ë² ë”©
- **`taxonomy`**: ê³„ì¸µì  ë¶„ë¥˜ì²´ê³„ (ë¶€ëª¨-ìì‹ ê´€ê³„)
- **`document_taxonomy`**: ë¬¸ì„œ-ë¶„ë¥˜ ë§¤í•‘ (ì‹ ë¢°ë„ í¬í•¨)
- **`search_logs`**: RAGAS í‰ê°€ë¥¼ ìœ„í•œ ê²€ìƒ‰ ë¡œê·¸

### ğŸ” ì¸ë±ìŠ¤ ìµœì í™”
- **Vector Index**: `ivfflat (embedding vector_cosine_ops)`
- **Full-text Index**: `gin(to_tsvector('english', content || title))`
- **Performance Index**: created_at, parent_id ë“±

## ğŸ¯ ì„±ëŠ¥ ëª©í‘œ ë° ë‹¬ì„±

| ë©”íŠ¸ë¦­ | ëª©í‘œ | í˜„ì¬ ìƒíƒœ |
|--------|------|-----------|
| **Faithfulness** | â‰¥ 0.85 | âœ… ì‹¤ì œ DB ì¿¼ë¦¬ë¡œ ê°œì„  |
| **p95 Latency** | â‰¤ 4s | âœ… í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ìµœì í™” |
| **Cost per Query** | â‰¤ â‚©10 | âœ… pgvectorë¡œ ë¹„ìš© ì ˆê° |
| **HITL Rate** | â‰¤ 30% | âœ… ML ë¶„ë¥˜ ì‹ ë¢°ë„ í–¥ìƒ |
| **Rollback TTR** | â‰¤ 15ë¶„ | âœ… ìë™í™” ìŠ¤í¬ë¦½íŠ¸ êµ¬ì¶• |

## ğŸ”§ ê°œë°œì ë„êµ¬

### ğŸ§ª ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
```bash
# ì „ì²´ ì‹œìŠ¤í…œ ê²€ì¦ (6ê°œ í…ŒìŠ¤íŠ¸ ëª¨ë“ˆ)
python test_production_system.py

# ê°œë³„ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
pytest tests/ -v

# ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
python benchmark_search.py
```

### ğŸ“Š ëª¨ë‹ˆí„°ë§
```bash
# ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
curl http://localhost:8001/health
curl http://localhost:8000/api/v1/monitoring/health

# ê²€ìƒ‰ ì„±ëŠ¥ ì§€í‘œ
curl http://localhost:8000/api/v1/monitoring/search-analytics
```

### ğŸ› ï¸ ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬
```bash
# í…Œì´ë¸” ìƒíƒœ í™•ì¸
python -c "
import asyncio
from apps.api.database import get_search_performance_metrics
print(asyncio.run(get_search_performance_metrics()))
"

# ì¸ë±ìŠ¤ ìµœì í™”
python -c "
import asyncio
from apps.api.database import SearchDAO, db_manager
async def optimize():
    async with db_manager.async_session() as session:
        result = await SearchDAO.optimize_search_indices(session)
        print(result)
asyncio.run(optimize())
"
```

## ğŸŒ í”„ë¡œë•ì…˜ ë°°í¬

### ğŸ³ Docker êµ¬ì„±
```yaml
# docker-compose.yml
services:
  postgres:
    image: ankane/pgvector:v0.6.0
    environment:
      POSTGRES_DB: dt_rag
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql
```

### ğŸ” í™˜ê²½ ë³€ìˆ˜
```env
# .env
DATABASE_URL=postgresql+asyncpg://postgres:postgres@localhost:5432/dt_rag
OPENAI_API_KEY=your-openai-api-key-here
GEMINI_API_KEY=your-gemini-api-key-here
DT_RAG_ENV=production
DEBUG=false
```

### ğŸš€ í”„ë¡œë•ì…˜ ì²´í¬ë¦¬ìŠ¤íŠ¸
- [ ] PostgreSQL + pgvector ì»¨í…Œì´ë„ˆ ì‹¤í–‰
- [ ] ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì´ˆê¸°í™” ì™„ë£Œ
- [ ] ë¬¸ì„œ ì„ë² ë”© ìƒì„± ì™„ë£Œ
- [ ] ë²¡í„° ì¸ë±ìŠ¤ ìµœì í™” ì™„ë£Œ
- [ ] ì „ì²´ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ í†µê³¼ (80% ì´ìƒ)
- [ ] API ë¬¸ì„œí™” í™•ì¸
- [ ] ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ í™œì„±í™”
- [ ] ë°±ì—… ë° ë³µêµ¬ ê³„íš ìˆ˜ë¦½

## ğŸ”— ê´€ë ¨ ë§í¬

- ğŸ“– **API ë¬¸ì„œ**: http://localhost:8001/docs
- ğŸ“Š **ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§**: http://localhost:8000/api/v1/monitoring/health
- ğŸ³ **Docker Hub**: ankane/pgvector
- ğŸ“š **pgvector ë¬¸ì„œ**: https://github.com/pgvector/pgvector

## ğŸ’¡ ë¬¸ì œ í•´ê²°

### ì¼ë°˜ì ì¸ ë¬¸ì œë“¤

**Q: "Database connection failed" ì˜¤ë¥˜**
```bash
# Docker ì»¨í…Œì´ë„ˆ ìƒíƒœ í™•ì¸
docker ps | grep postgres

# ì»¨í…Œì´ë„ˆ ì¬ì‹œì‘
docker-compose restart postgres

# ë¡œê·¸ í™•ì¸
docker logs dt_rag_postgres
```

**Q: "pgvector extension not found" ì˜¤ë¥˜**
```bash
# pgvector ì„¤ì¹˜ í™•ì¸
docker exec -it dt_rag_postgres psql -U postgres -d dt_rag -c "\dx"

# ìˆ˜ë™ ì„¤ì¹˜
docker exec -it dt_rag_postgres psql -U postgres -d dt_rag -c "CREATE EXTENSION IF NOT EXISTS vector;"
```

**Q: ê²€ìƒ‰ ê²°ê³¼ê°€ ë‚˜ì˜¤ì§€ ì•ŠìŒ**
```bash
# ë¬¸ì„œ ìˆ˜ í™•ì¸
python -c "
import asyncio
from apps.api.database import db_manager
from sqlalchemy import text
async def check():
    async with db_manager.async_session() as session:
        result = await session.execute(text('SELECT COUNT(*) FROM documents'))
        print(f'Documents: {result.scalar()}')
asyncio.run(check())
"

# ì„ë² ë”© ìƒì„±
python generate_embeddings.py
```

---

## ğŸ‰ í”„ë¡œë•ì…˜ ì™„ë£Œ!

DT-RAG v1.8.1ì€ ì´ì œ ì™„ì „í•œ í”„ë¡œë•ì…˜ í™˜ê²½ì…ë‹ˆë‹¤:

âœ… **Mock ë°ì´í„° ì™„ì „ ì œê±°** - 100% ì‹¤ì œ ë°ì´í„°ë§Œ ì‚¬ìš©
âœ… **PostgreSQL + pgvector ì—°ê²°** - ì‹¤ì œ ë²¡í„° ê²€ìƒ‰
âœ… **í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹œìŠ¤í…œ** - BM25 + Vector + ì¬ë­í‚¹
âœ… **ML ê¸°ë°˜ ë¶„ë¥˜ ì‹œìŠ¤í…œ** - semantic similarity ì‚¬ìš©
âœ… **í”„ë¡œë•ì…˜ ë ˆë”” ì¸í”„ë¼** - ëª¨ë‹ˆí„°ë§, ë¡œê¹…, ì—ëŸ¬ ì²˜ë¦¬

ğŸš€ **ì‹œì‘í•˜ì„¸ìš”**: `python start_production_system.py`
# Norade ì²´ê³„ì  ë¦¬íŒ©í† ë§ ê³„íšì„œ

**í”„ë¡œì íŠ¸**: Norade (êµ¬ DT-RAG) v1.8.1
**ì‘ì„±ì¼**: 2025-11-30
**ê¸°ë°˜ ë¬¸ì„œ**: [CODE-REVIEW-REPORT.md](./CODE-REVIEW-REPORT.md)
**ì´ ì˜ˆìƒ ê¸°ê°„**: 5ì£¼ (25 ì˜ì—…ì¼)
**ëª©í‘œ**: 1ì¸ ê°œë°œì ì§€ì† ê°€ëŠ¥í•œ ìš´ì˜ì„ ìœ„í•œ ìë™í™”ìœ¨ 90%+ ë‹¬ì„±

---

## ëª©ì°¨

1. [ë¦¬íŒ©í† ë§ ì›ì¹™](#1-ë¦¬íŒ©í† ë§-ì›ì¹™)
2. [Phase 0: ì‚¬ì „ ì¤€ë¹„](#2-phase-0-ì‚¬ì „-ì¤€ë¹„)
3. [Phase 1: Critical ì´ìŠˆ í•´ê²°](#3-phase-1-critical-ì´ìŠˆ-í•´ê²°)
4. [Phase 2: High ì´ìŠˆ í•´ê²°](#4-phase-2-high-ì´ìŠˆ-í•´ê²°)
5. [Phase 3: êµ¬ì¡° ê°œì„ ](#5-phase-3-êµ¬ì¡°-ê°œì„ )
6. [Phase 4: í’ˆì§ˆ ê°•í™”](#6-phase-4-í’ˆì§ˆ-ê°•í™”)
7. [**ğŸ¤– ìë™í™” íŠ¸ë™: 1ì¸ ê°œë°œì ìƒì¡´ ì „ëµ**](#7-ìë™í™”-íŠ¸ë™-1ì¸-ê°œë°œì-ìƒì¡´-ì „ëµ) â† NEW!
8. [ë¡¤ë°± ì „ëµ](#8-ë¡¤ë°±-ì „ëµ)
9. [ì²´í¬ë¦¬ìŠ¤íŠ¸](#9-ì²´í¬ë¦¬ìŠ¤íŠ¸)

---

## 1. ë¦¬íŒ©í† ë§ ì›ì¹™

### 1.1 ì•ˆì „í•œ ë¦¬íŒ©í† ë§ ì›ì¹™

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Safe Refactoring Principles                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. í…ŒìŠ¤íŠ¸ ë¨¼ì € (Test First)                             â”‚
â”‚     â†’ ë³€ê²½ ì „ í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ í™•ë³´                        â”‚
â”‚                                                          â”‚
â”‚  2. ì‘ì€ ë‹¨ìœ„ ì»¤ë°‹ (Small Commits)                       â”‚
â”‚     â†’ ë‹¨ì¼ ì±…ì„ ì›ì¹™ ì ìš©, ë¡¤ë°± ìš©ì´                      â”‚
â”‚                                                          â”‚
â”‚  3. ê¸°ëŠ¥ ë™ê²° (Feature Freeze)                           â”‚
â”‚     â†’ ë¦¬íŒ©í† ë§ ì¤‘ ì‹ ê·œ ê¸°ëŠ¥ ì¶”ê°€ ê¸ˆì§€                     â”‚
â”‚                                                          â”‚
â”‚  4. ì ì§„ì  ë³€ê²½ (Incremental Changes)                    â”‚
â”‚     â†’ Big Bang ê¸ˆì§€, ë‹¨ê³„ë³„ ê²€ì¦                         â”‚
â”‚                                                          â”‚
â”‚  5. ë¬¸ì„œí™” ìš°ì„  (Documentation First)                    â”‚
â”‚     â†’ ë³€ê²½ ì „ ì˜í–¥ ë²”ìœ„ ë¬¸ì„œí™”                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 ë¸Œëœì¹˜ ì „ëµ

```
master
  â”‚
  â”œâ”€â”€ feature/refactor-phase-1-critical
  â”‚   â”œâ”€â”€ fix/qtable-persistence
  â”‚   â”œâ”€â”€ fix/import-paths
  â”‚   â””â”€â”€ fix/reranker-spec
  â”‚
  â”œâ”€â”€ feature/refactor-phase-2-high
  â”‚   â”œâ”€â”€ fix/postgres-test-env
  â”‚   â”œâ”€â”€ fix/search-service-naming
  â”‚   â””â”€â”€ feat/frontend-tests
  â”‚
  â””â”€â”€ feature/refactor-phase-3-structure
      â”œâ”€â”€ refactor/database-split
      â””â”€â”€ chore/branding-cleanup
```

### 1.3 ìœ„í—˜ë„ ë¶„ë¥˜

| ìœ„í—˜ë„ | ê¸°ì¤€ | ëŒ€ì‘ |
|--------|------|------|
| ğŸ”´ High | DB ìŠ¤í‚¤ë§ˆ ë³€ê²½, í•µì‹¬ ë¡œì§ ìˆ˜ì • | ìŠ¤í…Œì´ì§• í•„ìˆ˜, ë¡¤ë°± ê³„íš |
| ğŸŸ¡ Medium | ì¸í„°í˜ì´ìŠ¤ ë³€ê²½, ëª¨ë“ˆ ë¶„ë¦¬ | ë¡œì»¬ í…ŒìŠ¤íŠ¸ í›„ ë°°í¬ |
| ğŸŸ¢ Low | ëª…ì¹­ ë³€ê²½, ë¬¸ì„œ ìˆ˜ì • | ì¦‰ì‹œ ë°°í¬ ê°€ëŠ¥ |

---

## 2. Phase 0: ì‚¬ì „ ì¤€ë¹„ (Day 1)

### 2.1 í˜„ì¬ ìƒíƒœ ìŠ¤ëƒ…ìƒ·

```bash
# í˜„ì¬ í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ ê¸°ë¡
pytest apps/api --cov=apps/api --cov-report=html
# ê²°ê³¼: coverage_baseline.html

# í˜„ì¬ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ê¸°ë¡
./scripts/e2e-test.sh > baseline_e2e_results.txt

# DB ìŠ¤í‚¤ë§ˆ ë¤í”„
pg_dump -s dt_rag > schema_baseline.sql
```

### 2.2 í…ŒìŠ¤íŠ¸ í™˜ê²½ í™•ì¸

| í•­ëª© | ìƒíƒœ | ì¡°ì¹˜ |
|------|------|------|
| Unit Tests | âœ… 42ê°œ | ê¸°ì¡´ ìœ ì§€ |
| Integration Tests | âœ… 33ê°œ | ê¸°ì¡´ ìœ ì§€ |
| E2E Tests | âš ï¸ í™•ì¸ í•„ìš” | ì»¤ë²„ë¦¬ì§€ ì¸¡ì • |
| PostgreSQL í…ŒìŠ¤íŠ¸ | âŒ ë¶€ì¬ | Docker Compose ì¶”ê°€ |

### 2.3 Feature Flag ì¤€ë¹„

```python
# apps/api/env_manager.pyì— ì¶”ê°€
REFACTORING_FLAGS = {
    "use_persistent_qtable": False,     # Phase 1
    "use_new_import_paths": False,      # Phase 1
    "use_cross_encoder_reranker": False, # Phase 1 (ì„ íƒ)
    "use_postgres_test": False,         # Phase 2
}
```

### ğŸ“‹ Phase 0 ì²´í¬ë¦¬ìŠ¤íŠ¸

> **ì™„ë£Œ ì¡°ê±´**: ëª¨ë“  í•­ëª© ì²´í¬ ì‹œ Phase 1 ì§„í–‰ ê°€ëŠ¥

#### ì¤€ë¹„ ì‘ì—…
- [ ] í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ ê¸°ì¤€ì„  ê¸°ë¡ (`pytest --cov` ì‹¤í–‰ â†’ `coverage_baseline.html`)
- [ ] E2E í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìŠ¤ëƒ…ìƒ· ì €ì¥
- [ ] DB ìŠ¤í‚¤ë§ˆ ë°±ì—… ì™„ë£Œ (`pg_dump -s dt_rag > schema_baseline.sql`)

#### í™˜ê²½ êµ¬ì„±
- [ ] Feature Flag í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (`.env`ì— `REFACTORING_FLAGS` ì¶”ê°€)
- [ ] í…ŒìŠ¤íŠ¸ìš© Docker Compose í™•ì¸ (`docker-compose.test.yml`)
- [ ] ë¦¬íŒ©í† ë§ ë¸Œëœì¹˜ ìƒì„± (`feature/refactor-phase-1-critical`)

#### ìë™í™” ë³‘í–‰ (Week 1)
- [ ] Pre-commit hooks ì„¤ì¹˜ (`pre-commit install`)
- [ ] `.pre-commit-config.yaml` ìƒì„± ë° í…ŒìŠ¤íŠ¸

**ë‹¤ìŒ ë‹¨ê³„**: â†’ Phase 1ë¡œ ì´ë™

---

## 3. Phase 1: Critical ì´ìŠˆ í•´ê²° (Day 2-8)

### 3.1 ğŸ”´ Task 1: Import ê²½ë¡œ ì˜¤ë¥˜ ìˆ˜ì •

**ìœ„í—˜ë„**: ğŸŸ¢ Low | **ì˜ˆìƒ ì†Œìš”**: 1ì‹œê°„ | **ë‹´ë‹¹**: Backend

#### í˜„ì¬ ìƒíƒœ
```python
# main.py:243 - ì˜¤ë¥˜
from cache.redis_manager import get_redis_manager

# main.py:340 - ì˜¤ë¥˜
from routers.monitoring import track_request_metrics
```

#### ìˆ˜ì • ê³„íš
```python
# ì˜µì…˜ A: ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš© (ê¶Œì¥)
from apps.api.cache.redis_manager import get_redis_manager
from apps.api.routers.monitoring import track_request_metrics

# ì˜µì…˜ B: ìƒëŒ€ ê²½ë¡œ ì‚¬ìš©
from .cache.redis_manager import get_redis_manager
from .routers.monitoring import track_request_metrics
```

#### ê²€ì¦ ë°©ë²•
```bash
# ì„œë²„ êµ¬ë™ í…ŒìŠ¤íŠ¸
cd apps/api && python -c "import main"

# ì „ì²´ ì„í¬íŠ¸ ê²€ì¦
python -m py_compile apps/api/**/*.py
```

#### ë¡¤ë°± ê³„íš
```bash
git revert <commit-hash>  # ë‹¨ì¼ ì»¤ë°‹ìœ¼ë¡œ ë¡¤ë°± ê°€ëŠ¥
```

---

### 3.2 ğŸ”´ Task 2: Q-Table ì˜ì†ì„± ë§ˆì´ê·¸ë ˆì´ì…˜

**ìœ„í—˜ë„**: ğŸ”´ High | **ì˜ˆìƒ ì†Œìš”**: 2-3ì¼ | **ë‹´ë‹¹**: Backend

#### í˜„ì¬ ìƒíƒœ (ë¬¸ì œ)
```python
# database.py:1893
class QTableDAO:
    def __init__(self) -> None:
        self.q_table_storage: Dict[str, List[float]] = {}  # ì¸ë©”ëª¨ë¦¬!
```

#### ë§ˆì´ê·¸ë ˆì´ì…˜ ì˜µì…˜

| ì˜µì…˜ | ì¥ì  | ë‹¨ì  | ë³µì¡ë„ |
|------|------|------|--------|
| **A. PostgreSQL JSON** | ê¸°ì¡´ DB í™œìš©, íŠ¸ëœì­ì…˜ | ì¿¼ë¦¬ ë³µì¡ | ì¤‘ |
| **B. Redis** | ë¹ ë¥¸ ì ‘ê·¼, TTL ì§€ì› | ì¶”ê°€ ì¸í”„ë¼ | ì¤‘ |
| **C. íŒŒì¼ ê¸°ë°˜** | ë‹¨ìˆœ, ì¶”ê°€ ì˜ì¡´ì„± ì—†ìŒ | ë™ì‹œì„± ì´ìŠˆ | ë‚® |

#### ê¶Œì¥: ì˜µì…˜ A (PostgreSQL JSON)

```python
# ìƒˆë¡œìš´ í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ
class QTableEntry(Base):
    __tablename__ = "q_table_entries"

    id: Mapped[int] = mapped_column(primary_key=True)
    state_hash: Mapped[str] = mapped_column(String(64), unique=True, index=True)
    q_values: Mapped[dict] = mapped_column(JSON)  # List[float]
    updated_at: Mapped[datetime] = mapped_column(DateTime(timezone=True))
    access_count: Mapped[int] = mapped_column(Integer, default=0)
```

#### ë§ˆì´ê·¸ë ˆì´ì…˜ ë‹¨ê³„

```
Day 2:
â”œâ”€â”€ 1. QTableEntry ëª¨ë¸ ìƒì„±
â”œâ”€â”€ 2. Alembic ë§ˆì´ê·¸ë ˆì´ì…˜ ì‘ì„±
â””â”€â”€ 3. QTableDAO ì¸í„°í˜ì´ìŠ¤ ìœ ì§€, êµ¬í˜„ ë³€ê²½

Day 3:
â”œâ”€â”€ 4. Feature Flagë¡œ ìƒˆ êµ¬í˜„ í™œì„±í™”
â”œâ”€â”€ 5. ê¸°ì¡´ ì¸ë©”ëª¨ë¦¬ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸
â””â”€â”€ 6. í†µí•© í…ŒìŠ¤íŠ¸

Day 4:
â”œâ”€â”€ 7. ìŠ¤í…Œì´ì§• ë°°í¬ ë° ê²€ì¦
â””â”€â”€ 8. í”„ë¡œë•ì…˜ ë¡¤ì•„ì›ƒ
```

#### Alembic ë§ˆì´ê·¸ë ˆì´ì…˜
```python
# alembic/versions/xxxx_add_qtable_persistence.py
def upgrade():
    op.create_table(
        'q_table_entries',
        sa.Column('id', sa.Integer(), primary_key=True),
        sa.Column('state_hash', sa.String(64), unique=True, index=True),
        sa.Column('q_values', sa.JSON()),
        sa.Column('updated_at', sa.DateTime(timezone=True)),
        sa.Column('access_count', sa.Integer(), default=0),
    )

def downgrade():
    op.drop_table('q_table_entries')
```

#### ìƒˆë¡œìš´ QTableDAO êµ¬í˜„
```python
class PersistentQTableDAO:
    """PostgreSQL ê¸°ë°˜ Q-Table DAO"""

    def __init__(self, session: AsyncSession):
        self.session = session

    async def save_q_table(self, state_hash: str, q_values: List[float]) -> None:
        entry = await self.session.get(QTableEntry, state_hash)
        if entry:
            entry.q_values = q_values
            entry.updated_at = datetime.now(timezone.utc)
            entry.access_count += 1
        else:
            entry = QTableEntry(
                state_hash=state_hash,
                q_values=q_values,
                updated_at=datetime.now(timezone.utc)
            )
            self.session.add(entry)
        await self.session.commit()

    async def load_q_table(self, state_hash: str) -> Optional[List[float]]:
        entry = await self.session.get(QTableEntry, state_hash)
        return entry.q_values if entry else None
```

#### ë¡¤ë°± ê³„íš
```bash
# DB ë¡¤ë°±
alembic downgrade -1

# ì½”ë“œ ë¡¤ë°±
git revert <commit-range>

# Feature Flagë¡œ ì¦‰ì‹œ ë¹„í™œì„±í™”
REFACTORING_FLAGS["use_persistent_qtable"] = False
```

---

### 3.3 ğŸ”´ Task 3: HybridScoreReranker ëª…ì„¸ ì •ë ¬

**ìœ„í—˜ë„**: ğŸŸ¡ Medium | **ì˜ˆìƒ ì†Œìš”**: 3-5ì¼ | **ë‹´ë‹¹**: ML/Backend

#### í˜„ì¬ ìƒíƒœ (ë¬¸ì œ)
```python
class HybridScoreReranker:
    """Heuristic-based reranking"""  # ëª…ì„¸: Cross-Encoder

    def rerank(self, ...):
        return self._heuristic_rerank(...)  # íœ´ë¦¬ìŠ¤í‹± ì‚¬ìš©
```

#### í•´ê²° ì˜µì…˜

| ì˜µì…˜ | ì„¤ëª… | ê²€ìƒ‰ í’ˆì§ˆ | ë¹„ìš© |
|------|------|-----------|------|
| **A. ëª…ì„¸ ìˆ˜ì •** | ë¬¸ì„œë¥¼ í˜„ì¬ êµ¬í˜„ì— ë§ì¶¤ | ìœ ì§€ | ë‚®ìŒ |
| **B. Cross-Encoder êµ¬í˜„** | sentence-transformers ì—°ë™ | í–¥ìƒ | ë†’ìŒ |
| **C. í•˜ì´ë¸Œë¦¬ë“œ** | íœ´ë¦¬ìŠ¤í‹± + ì„ íƒì  CE | ìœ ì—° | ì¤‘ê°„ |

#### ê¶Œì¥: ì˜µì…˜ C (í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼)

```python
class HybridScoreReranker:
    """
    Hybrid reranking strategy:
    - Default: Fast heuristic scoring
    - Optional: Cross-Encoder for high-precision queries
    """

    def __init__(self, use_cross_encoder: bool = False):
        self.use_cross_encoder = use_cross_encoder
        self._cross_encoder = None

        if use_cross_encoder:
            self._load_cross_encoder()

    def _load_cross_encoder(self):
        from sentence_transformers import CrossEncoder
        self._cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')

    def rerank(self, query: str, results: List[SearchResult], top_k: int = 5):
        if self.use_cross_encoder and self._cross_encoder:
            return self._cross_encoder_rerank(query, results, top_k)
        return self._heuristic_rerank(query, results, top_k)
```

#### ëª…ì„¸ ìˆ˜ì • (ì˜µì…˜ A ì„ íƒ ì‹œ)
```markdown
## ê²€ìƒ‰ ì•„í‚¤í…ì²˜

### Reranking ì „ëµ
- **ê¸°ë³¸**: íœ´ë¦¬ìŠ¤í‹± ê¸°ë°˜ í’ˆì§ˆ ì ìˆ˜ (term overlap, length penalty, diversity)
- **ê³ ê¸‰** (ì„ íƒì ): Cross-Encoder ëª¨ë¸ ì§€ì› (v2.0 ì˜ˆì •)
```

### ğŸ“‹ Phase 1 ì²´í¬ë¦¬ìŠ¤íŠ¸

> **ì™„ë£Œ ì¡°ê±´**: ëª¨ë“  Critical ì´ìŠˆ í•´ê²° ë° í…ŒìŠ¤íŠ¸ í†µê³¼

#### Task 1: Import ê²½ë¡œ ìˆ˜ì •
- [ ] `main.py:243` â†’ `from apps.api.cache.redis_manager import get_redis_manager`
- [ ] `main.py:340` â†’ `from apps.api.routers.monitoring import track_request_metrics`
- [ ] `python -c "import main"` ì„±ê³µ í™•ì¸
- [ ] ì „ì²´ ì„í¬íŠ¸ ê²€ì¦ í†µê³¼ (`python -m py_compile apps/api/**/*.py`)
- [ ] ì»¤ë°‹ ìƒì„± (`fix: correct import paths in main.py`)

#### Task 2: Q-Table ì˜ì†ì„±
- [ ] `QTableEntry` ëª¨ë¸ ìƒì„± (`apps/api/database.py`)
- [ ] Alembic ë§ˆì´ê·¸ë ˆì´ì…˜ ì‘ì„± (`alembic revision -m "add_qtable_persistence"`)
- [ ] ë§ˆì´ê·¸ë ˆì´ì…˜ ì ìš© (`alembic upgrade head`)
- [ ] `PersistentQTableDAO` êµ¬í˜„ ì™„ë£Œ
- [ ] Feature Flag ì—°ë™ (`use_persistent_qtable`)
- [ ] í†µí•© í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] ìŠ¤í…Œì´ì§• ë°°í¬ ë° ê²€ì¦
- [ ] ê¸°ì¡´ ì¸ë©”ëª¨ë¦¬ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ (í•„ìš”ì‹œ)
- [ ] ì»¤ë°‹ ìƒì„± (`feat: add Q-Table PostgreSQL persistence`)

#### Task 3: Reranker ëª…ì„¸ ì •ë ¬
- [ ] êµ¬í˜„ ë°©í–¥ ê²°ì •: [ ] ì˜µì…˜ A (ëª…ì„¸ ìˆ˜ì •) / [ ] ì˜µì…˜ B (CE êµ¬í˜„) / [ ] ì˜µì…˜ C (í•˜ì´ë¸Œë¦¬ë“œ)
- [ ] ì„ íƒí•œ ì˜µì…˜ êµ¬í˜„ ì™„ë£Œ
- [ ] ê´€ë ¨ í…ŒìŠ¤íŠ¸ ì‘ì„± ë° í†µê³¼
- [ ] ë¬¸ì„œ ì—…ë°ì´íŠ¸ (SPEC ë˜ëŠ” README)
- [ ] ì»¤ë°‹ ìƒì„± (`feat/docs: align reranker spec with implementation`)

#### ìë™í™” ë³‘í–‰ (Week 1-2)
- [ ] CI Pipeline (`ci.yml`) êµ¬í˜„ ë° í™œì„±í™”
- [ ] Dependabot ì„¤ì • (`.github/dependabot.yml`)
- [ ] ì²« PRì—ì„œ CI í…ŒìŠ¤íŠ¸ í†µê³¼ í™•ì¸

#### Phase 1 ì™„ë£Œ ê²€ì¦
- [ ] ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼ (`pytest apps/api -v`)
- [ ] ì»¤ë²„ë¦¬ì§€ ê¸°ì¤€ì„  ìœ ì§€ ë˜ëŠ” í–¥ìƒ
- [ ] ì„œë²„ ì •ìƒ êµ¬ë™ í™•ì¸ (`uvicorn main:app`)
- [ ] Feature Flag ë¡¤ë°± í…ŒìŠ¤íŠ¸ ì™„ë£Œ

**ë‹¤ìŒ ë‹¨ê³„**: â†’ Phase 2ë¡œ ì´ë™ (ë¸Œëœì¹˜: `feature/refactor-phase-2-high`)

---

## 4. Phase 2: High ì´ìŠˆ í•´ê²° (Day 9-14)

### 4.1 âš ï¸ Task 4: PostgreSQL í…ŒìŠ¤íŠ¸ í™˜ê²½ í†µì¼

**ìœ„í—˜ë„**: ğŸŸ¡ Medium | **ì˜ˆìƒ ì†Œìš”**: 2ì¼

#### docker-compose.test.yml ì¶”ê°€
```yaml
version: '3.8'

services:
  postgres_test:
    image: pgvector/pgvector:pg16
    environment:
      POSTGRES_DB: dt_rag_test
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
    ports:
      - "5433:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 5s
      timeout: 5s
      retries: 5

  redis_test:
    image: redis:7-alpine
    ports:
      - "6380:6379"
```

#### í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
```bash
#!/bin/bash
# scripts/test-with-postgres.sh

docker-compose -f docker-compose.test.yml up -d
sleep 5

export DATABASE_URL=postgresql+asyncpg://postgres:postgres@localhost:5433/dt_rag_test
export REDIS_URL=redis://localhost:6380

pytest apps/api -v --cov=apps/api

docker-compose -f docker-compose.test.yml down
```

---

### 4.2 âš ï¸ Task 5: SearchService ëª…ì¹­ ì¶©ëŒ í•´ê²°

**ìœ„í—˜ë„**: ğŸŸ¡ Medium | **ì˜ˆìƒ ì†Œìš”**: 3ì¼

#### í˜„ì¬ êµ¬ì¡° (ë¬¸ì œ)
```
apps/api/
â”œâ”€â”€ routers/search_router.py    â†’ class SearchService (1,094 LOC)
â””â”€â”€ services/search_service.py  â†’ class SearchService (449 LOC)
```

#### ëª©í‘œ êµ¬ì¡°
```
apps/api/
â”œâ”€â”€ routers/search_router.py    â†’ SearchRouter (ë¼ìš°í„° ë¡œì§ë§Œ)
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ search_service.py       â†’ SearchService (ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§)
â”‚   â””â”€â”€ search_orchestrator.py  â†’ SearchOrchestrator (ë³µì¡í•œ ê²€ìƒ‰ ì¡°í•©)
```

#### ë§ˆì´ê·¸ë ˆì´ì…˜ ë‹¨ê³„

```
Day 9:
â”œâ”€â”€ 1. routers/search_router.pyì˜ SearchService â†’ ProductionSearchHandler ë¡œ ì´ë¦„ ë³€ê²½
â”œâ”€â”€ 2. ê¸°ì¡´ í˜¸ì¶œë¶€ ì—…ë°ì´íŠ¸
â””â”€â”€ 3. í…ŒìŠ¤íŠ¸

Day 10:
â”œâ”€â”€ 4. services/search_service.py ì—­í•  ëª…í™•í™”
â”œâ”€â”€ 5. SearchOrchestrator ë¶„ë¦¬ (í•„ìš”ì‹œ)
â””â”€â”€ 6. í†µí•© í…ŒìŠ¤íŠ¸

Day 11:
â””â”€â”€ 7. ë¬¸ì„œ ì—…ë°ì´íŠ¸
```

---

### 4.3 âš ï¸ Task 6: í”„ë¡ íŠ¸ì—”ë“œ í…ŒìŠ¤íŠ¸ ì¶”ê°€

**ìœ„í—˜ë„**: ğŸŸ¢ Low | **ì˜ˆìƒ ì†Œìš”**: 1ì£¼

#### Jest ì„¤ì •
```javascript
// apps/frontend/jest.config.js
module.exports = {
  testEnvironment: 'jsdom',
  setupFilesAfterEnv: ['<rootDir>/jest.setup.js'],
  moduleNameMapper: {
    '^@/(.*)$': '<rootDir>/$1',
  },
  collectCoverageFrom: [
    'components/**/*.{ts,tsx}',
    'lib/**/*.{ts,tsx}',
    '!**/*.d.ts',
  ],
};
```

#### ìš°ì„  í…ŒìŠ¤íŠ¸ ëŒ€ìƒ
```
1. stores/ (Zustand ìŠ¤í† ì–´) - ìƒíƒœ ê´€ë¦¬ ë¡œì§
2. lib/api/ - API í´ë¼ì´ì–¸íŠ¸ í•¨ìˆ˜
3. components/ui/ - ê¸°ë³¸ UI ì»´í¬ë„ŒíŠ¸
4. components/chat/ - ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
```

### ğŸ“‹ Phase 2 ì²´í¬ë¦¬ìŠ¤íŠ¸

> **ì™„ë£Œ ì¡°ê±´**: High ì´ìŠˆ í•´ê²° ë° í…ŒìŠ¤íŠ¸ í™˜ê²½ í†µì¼

#### Task 4: PostgreSQL í…ŒìŠ¤íŠ¸ í™˜ê²½
- [ ] `docker-compose.test.yml` ìƒì„±/ìˆ˜ì •
- [ ] PostgreSQL í…ŒìŠ¤íŠ¸ ì»¨í…Œì´ë„ˆ ì„¤ì • (port: 5433)
- [ ] Redis í…ŒìŠ¤íŠ¸ ì»¨í…Œì´ë„ˆ ì„¤ì • (port: 6380)
- [ ] `scripts/test-with-postgres.sh` ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±
- [ ] ë¡œì»¬ í…ŒìŠ¤íŠ¸ í†µê³¼ í™•ì¸
- [ ] GitHub Actions CIì— PostgreSQL ì„œë¹„ìŠ¤ ì¶”ê°€
- [ ] CI í…ŒìŠ¤íŠ¸ í†µê³¼ í™•ì¸
- [ ] ì»¤ë°‹ ìƒì„± (`feat: add PostgreSQL test environment`)

#### Task 5: SearchService ëª…ì¹­ ë¶„ë¦¬
- [ ] `routers/search_router.py` ë‚´ `SearchService` â†’ `ProductionSearchHandler` ë¦¬ë„¤ì„
- [ ] ëª¨ë“  í˜¸ì¶œë¶€ ì—…ë°ì´íŠ¸ í™•ì¸ (grepìœ¼ë¡œ ê²€ì¦)
- [ ] `services/search_service.py` ì—­í•  ë¬¸ì„œí™”
- [ ] í•„ìš”ì‹œ `SearchOrchestrator` ë¶„ë¦¬
- [ ] ê´€ë ¨ í…ŒìŠ¤íŠ¸ ì—…ë°ì´íŠ¸ ë° í†µê³¼
- [ ] ì»¤ë°‹ ìƒì„± (`refactor: rename SearchService to clarify roles`)

#### Task 6: í”„ë¡ íŠ¸ì—”ë“œ í…ŒìŠ¤íŠ¸ ì¶”ê°€
- [ ] Jest ì„¤ì • (`jest.config.js` ìƒì„±)
- [ ] `jest.setup.js` ìƒì„±
- [ ] `stores/` í…ŒìŠ¤íŠ¸ 3ê°œ ì´ìƒ ì‘ì„±
- [ ] `lib/api/` í…ŒìŠ¤íŠ¸ 3ê°œ ì´ìƒ ì‘ì„±
- [ ] `components/ui/` í…ŒìŠ¤íŠ¸ 2ê°œ ì´ìƒ ì‘ì„±
- [ ] ì „ì²´ í”„ë¡ íŠ¸ì—”ë“œ í…ŒìŠ¤íŠ¸ í†µê³¼ (`npm test`)
- [ ] ì»¤ë°‹ ìƒì„± (`test: add frontend Jest tests`)

#### ìë™í™” ë³‘í–‰ (Week 2)
- [ ] CD Pipeline (`deploy.yml`) êµ¬í˜„
- [ ] Railway/Vercel ë°°í¬ webhook ì„¤ì •
- [ ] Staging í™˜ê²½ ë°°í¬ í…ŒìŠ¤íŠ¸
- [ ] Slack ì•Œë¦¼ ì—°ë™

#### Phase 2 ì™„ë£Œ ê²€ì¦
- [ ] Backend í…ŒìŠ¤íŠ¸ ì „ì²´ í†µê³¼ (PostgreSQL í™˜ê²½)
- [ ] Frontend í…ŒìŠ¤íŠ¸ ì „ì²´ í†µê³¼
- [ ] Staging ë°°í¬ ì„±ê³µ
- [ ] SearchService ë¶„ë¦¬ë¡œ ì¸í•œ regression ì—†ìŒ

**ë‹¤ìŒ ë‹¨ê³„**: â†’ Phase 3ë¡œ ì´ë™ (ë¸Œëœì¹˜: `feature/refactor-phase-3-structure`)

---

## 5. Phase 3: êµ¬ì¡° ê°œì„  (Day 15-18)

### 5.1 ğŸŸ¡ Task 7: database.py God Object ë¶„ë¦¬

**ìœ„í—˜ë„**: ğŸ”´ High | **ì˜ˆìƒ ì†Œìš”**: 3ì¼

#### í˜„ì¬ êµ¬ì¡° (1,936 LOC)
```python
# apps/api/database.py
- ORM ëª¨ë¸ (Document, Chunk, Agent, Taxonomy...)
- DAO í´ë˜ìŠ¤ (SearchDAO, QTableDAO...)
- ìœ í‹¸ë¦¬í‹° (BM25Scorer...)
- ì—°ê²° ê´€ë¦¬ (engine, session...)
```

#### ëª©í‘œ êµ¬ì¡°
```
apps/api/
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ __init__.py          # ê³µê°œ ì¸í„°í˜ì´ìŠ¤
â”‚   â”œâ”€â”€ connection.py        # ì—”ì§„, ì„¸ì…˜ ê´€ë¦¬
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ document.py      # Document, Chunk
â”‚   â”‚   â”œâ”€â”€ agent.py         # Agent
â”‚   â”‚   â””â”€â”€ taxonomy.py      # Taxonomy
â”‚   â”œâ”€â”€ daos/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ search_dao.py    # SearchDAO
â”‚   â”‚   â””â”€â”€ q_table_dao.py   # QTableDAO (ìƒˆ ì˜ì†ì„± í¬í•¨)
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ bm25_scorer.py   # BM25Scorer
```

#### ë§ˆì´ê·¸ë ˆì´ì…˜ ì „ëµ

```
1. ê¸°ì¡´ database.py ìœ ì§€ (í•˜ìœ„ í˜¸í™˜ì„±)
2. ìƒˆ íŒ¨í‚¤ì§€ êµ¬ì¡° ìƒì„±
3. ì ì§„ì ìœ¼ë¡œ import ë³€ê²½
4. ê¸°ì¡´ database.pyë¥¼ facadeë¡œ ìœ ì§€
5. ì¶©ë¶„í•œ í…ŒìŠ¤íŠ¸ í›„ ë ˆê±°ì‹œ ì œê±°
```

#### Facade íŒ¨í„´ ì ìš©
```python
# apps/api/database.py (ë ˆê±°ì‹œ í˜¸í™˜)
"""
DEPRECATED: ì´ ëª¨ë“ˆì€ ë ˆê±°ì‹œ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€ë©ë‹ˆë‹¤.
ìƒˆë¡œìš´ ì½”ë“œëŠ” apps.api.database íŒ¨í‚¤ì§€ë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ì„¸ìš”.
"""
from apps.api.database.connection import engine, async_session, get_async_session
from apps.api.database.models import Document, Chunk, Agent, Taxonomy
from apps.api.database.daos import SearchDAO, QTableDAO
from apps.api.database.utils import BM25Scorer

__all__ = [
    "engine", "async_session", "get_async_session",
    "Document", "Chunk", "Agent", "Taxonomy",
    "SearchDAO", "QTableDAO", "BM25Scorer",
]
```

### ğŸ“‹ Phase 3 ì²´í¬ë¦¬ìŠ¤íŠ¸

> **ì™„ë£Œ ì¡°ê±´**: êµ¬ì¡° ê°œì„  ì™„ë£Œ, ë ˆê±°ì‹œ í˜¸í™˜ì„± ìœ ì§€

#### Task 7: database.py ë¶„ë¦¬
- [ ] `apps/api/database/` íŒ¨í‚¤ì§€ ë””ë ‰í† ë¦¬ ìƒì„±
- [ ] `database/__init__.py` ìƒì„±
- [ ] `database/connection.py` ìƒì„± (engine, session ê´€ë ¨)
- [ ] `database/models/` ë””ë ‰í† ë¦¬ ìƒì„±
  - [ ] `models/__init__.py`
  - [ ] `models/document.py` (Document, Chunk)
  - [ ] `models/agent.py` (Agent)
  - [ ] `models/taxonomy.py` (Taxonomy)
- [ ] `database/daos/` ë””ë ‰í† ë¦¬ ìƒì„±
  - [ ] `daos/__init__.py`
  - [ ] `daos/search_dao.py` (SearchDAO)
  - [ ] `daos/q_table_dao.py` (QTableDAO + PersistentQTableDAO)
- [ ] `database/utils/` ë””ë ‰í† ë¦¬ ìƒì„±
  - [ ] `utils/bm25_scorer.py` (BM25Scorer)
- [ ] ê¸°ì¡´ `database.py` â†’ Facade íŒ¨í„´ ì ìš© (í•˜ìœ„ í˜¸í™˜)
- [ ] ëª¨ë“  import ê²½ë¡œ ì—…ë°ì´íŠ¸
- [ ] ì „ì²´ í…ŒìŠ¤íŠ¸ í†µê³¼ í™•ì¸
- [ ] ì»¤ë°‹ ìƒì„± (`refactor: split database.py into modular package`)

#### ìë™í™” ë³‘í–‰ (Week 3)
- [ ] Health monitoring workflow (`monitoring.yml`) êµ¬í˜„
- [ ] Backup workflow (`backup.yml`) êµ¬í˜„
- [ ] Slack/PagerDuty ì•Œë¦¼ ì—°ë™ í…ŒìŠ¤íŠ¸

#### Phase 3 ì™„ë£Œ ê²€ì¦
- [ ] ëª¨ë“  ê¸°ì¡´ í…ŒìŠ¤íŠ¸ í†µê³¼ (regression ì—†ìŒ)
- [ ] ìƒˆ íŒ¨í‚¤ì§€ êµ¬ì¡°ë¡œ import ê°€ëŠ¥ í™•ì¸
- [ ] ë ˆê±°ì‹œ `database.py` importë„ ì—¬ì „íˆ ë™ì‘
- [ ] ì„œë²„ ì •ìƒ êµ¬ë™ í™•ì¸

**ë‹¤ìŒ ë‹¨ê³„**: â†’ Phase 4ë¡œ ì´ë™ (ë¸Œëœì¹˜: `feature/refactor-phase-4-quality`)

---

## 6. Phase 4: í’ˆì§ˆ ê°•í™” (Day 19-20)

### 6.1 ë¸Œëœë”© í†µì¼

```bash
# DT-RAG â†’ Norade ë³€ê²½ ëŒ€ìƒ
grep -r "DT-RAG\|dt-rag\|dt_rag" --include="*.md" --include="*.py" --include="*.tsx"
```

| ìœ„ì¹˜ | ë³€ê²½ ì „ | ë³€ê²½ í›„ |
|------|---------|---------|
| config.py | `dt-rag.com` | `norade.ai` |
| package.json | `dt-rag` | `norade` |
| README.md | DT-RAG | Norade |

### 6.2 í”„ë¡ íŠ¸ì—”ë“œ ì½”ë“œ ì •ë¦¬ (NEW!)

#### 6.2.1 í˜„ì¬ êµ¬ì¡° ë¶„ì„

```
apps/frontend/
â”œâ”€â”€ src/                    # ğŸ†• NEW - Clean Architecture (ë¯¸ì‚¬ìš©!)
â”‚   â”œâ”€â”€ domain/            # ì—”í‹°í‹°, ë¦¬í¬ì§€í† ë¦¬ ì¸í„°í˜ì´ìŠ¤, ìœ ìŠ¤ì¼€ì´ìŠ¤
â”‚   â”œâ”€â”€ data/              # ë°ì´í„°ì†ŒìŠ¤, ë§¤í¼, ë¦¬í¬ì§€í† ë¦¬ êµ¬í˜„
â”‚   â”œâ”€â”€ presentation/      # í›…, ìŠ¤í† ì–´, ì»¨í…Œì´ë„ˆ
â”‚   â””â”€â”€ shared/            # DI ì»¨í…Œì´ë„ˆ, ì„¤ì •
â”‚
â”œâ”€â”€ lib/                    # âš ï¸ LEGACY - í˜„ì¬ ì‚¬ìš© ì¤‘
â”‚   â””â”€â”€ api/               # agents.ts, client.ts, research.ts, types.ts
â”‚
â”œâ”€â”€ hooks/                  # âš ï¸ LEGACY - í˜„ì¬ ì‚¬ìš© ì¤‘
â”‚   â”œâ”€â”€ useAgents.ts
â”‚   â”œâ”€â”€ useAgent.ts
â”‚   â””â”€â”€ useCoverageHistory.ts
â”‚
â”œâ”€â”€ stores/                 # âš ï¸ LEGACY - í˜„ì¬ ì‚¬ìš© ì¤‘
â”‚   â”œâ”€â”€ researchStore.ts
â”‚   â””â”€â”€ useTaxonomyStore.ts
â”‚
â”œâ”€â”€ components/             # âš ï¸ LEGACY - í˜„ì¬ ì‚¬ìš© ì¤‘
â”‚   â”œâ”€â”€ agent-card/
â”‚   â”œâ”€â”€ agent-detail/
â”‚   â”œâ”€â”€ chat/
â”‚   â”œâ”€â”€ constellation/
â”‚   â””â”€â”€ ui/
â”‚
â””â”€â”€ public/
    â””â”€â”€ avatars/robots/     # ğŸ—‘ï¸ DEPRECATED (DEPRECATED.md í™•ì¸ë¨)
```

#### 6.2.2 Clean Architecture ë§ˆì´ê·¸ë ˆì´ì…˜ ì „ëµ

**ê²°ì • í•„ìš”**: Clean Architecture(`src/`) í™œì„±í™” ì—¬ë¶€

| ì˜µì…˜ | ì„¤ëª… | ì¥ì  | ë‹¨ì  |
|------|------|------|------|
| **A. í™œì„±í™”** | src/ êµ¬ì¡°ë¥¼ ì‹¤ì œ ì‚¬ìš©ìœ¼ë¡œ ì „í™˜ | ê¹”ë”í•œ êµ¬ì¡°, í…ŒìŠ¤íŠ¸ ìš©ì´ | ëŒ€ê·œëª¨ ë³€ê²½, ìœ„í—˜ |
| **B. ì œê±°** | src/ ì‚­ì œ, ê¸°ì¡´ êµ¬ì¡° ìœ ì§€ | ì•ˆì •ì , ë¹ ë¦„ | ê¸°ìˆ  ë¶€ì±„ ìœ ì§€ |
| **C. ì ì§„ì ** | ìƒˆ ê¸°ëŠ¥ë§Œ src/ì—, ê¸°ì¡´ì€ ìœ ì§€ | ì•ˆì „, ì ì§„ì  ì „í™˜ | êµ¬ì¡° í˜¼ì¬ |

**ê¶Œì¥: ì˜µì…˜ C (ì ì§„ì  ì „í™˜)**

```
Phase 1: src/ë¥¼ ì‹¤ì œ í”„ë¡œë•ì…˜ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ì„¤ì •
â”œâ”€â”€ tsconfig.json path alias í™•ì¸
â”œâ”€â”€ DI ì»¨í…Œì´ë„ˆ ì´ˆê¸°í™” ì—°ê²°
â””â”€â”€ í…ŒìŠ¤íŠ¸ë¡œ ë™ì‘ í™•ì¸

Phase 2: ìƒˆ ê¸°ëŠ¥ì€ src/ì— ì‘ì„±
â”œâ”€â”€ ìƒˆ API ì—°ë™ â†’ src/data/datasources/
â”œâ”€â”€ ìƒˆ ìƒíƒœê´€ë¦¬ â†’ src/presentation/stores/
â””â”€â”€ ìƒˆ í›… â†’ src/presentation/hooks/

Phase 3: ê¸°ì¡´ ë ˆê±°ì‹œ ì ì§„ì  ë§ˆì´ê·¸ë ˆì´ì…˜
â”œâ”€â”€ lib/api/ â†’ src/data/
â”œâ”€â”€ hooks/ â†’ src/presentation/hooks/
â””â”€â”€ stores/ â†’ src/presentation/stores/
```

#### 6.2.3 ë ˆê±°ì‹œ â†’ ì‹ ê·œ ë§¤í•‘

| Legacy ê²½ë¡œ | New ê²½ë¡œ | ë§ˆì´ê·¸ë ˆì´ì…˜ ìš°ì„ ìˆœìœ„ |
|-------------|----------|----------------------|
| `lib/api/client.ts` | `src/data/datasources/api-client.ts` | ğŸ”´ ë†’ìŒ (í•µì‹¬) |
| `lib/api/agents.ts` | `src/data/repositories/agent-repository.ts` | ğŸŸ¡ ì¤‘ê°„ |
| `hooks/useAgents.ts` | `src/presentation/hooks/use-agents.ts` | ğŸŸ¡ ì¤‘ê°„ |
| `stores/researchStore.ts` | `src/presentation/stores/research-store.ts` | ğŸ”´ ë†’ìŒ |
| `stores/useTaxonomyStore.ts` | `src/presentation/stores/taxonomy-store.ts` | ğŸŸ¡ ì¤‘ê°„ |

#### 6.2.4 DEPRECATED ë¦¬ì†ŒìŠ¤ ì •ë¦¬

```bash
# í™•ì¸ë¨: public/avatars/robots/DEPRECATED.md
# â†’ SVG ì•„ë°”íƒ€ê°€ PNG ë¡œë´‡ìœ¼ë¡œ ëŒ€ì²´ë¨

# ì‚­ì œ ëŒ€ìƒ
rm -rf apps/frontend/public/avatars/robots/*.svg

# ìƒˆë¡œìš´ ì—ì…‹ ìœ„ì¹˜ í™•ì¸
ls apps/frontend/public/assets/agents/nobg/  # ìƒˆ ë¡œë´‡ PNG íŒŒì¼
```

#### 6.2.5 ë¡œê³  íŒŒì¼ ì •ë¦¬

```bash
# í˜„ì¬ public/ ë‚´ ë¡œê³  íŒŒì¼ë“¤ (ì •ë¦¬ í•„ìš”)
apps/frontend/public/
â”œâ”€â”€ norade-logo-final.png    # âœ… ìµœì¢… ë¡œê³  (ìœ ì§€)
â”œâ”€â”€ norade-logo-main-v2.png  # â“ ë²„ì „ ì •ë¦¬ í•„ìš”
â”œâ”€â”€ norade-logo-main.png     # â“ ì¤‘ë³µ í™•ì¸
â””â”€â”€ unnamed.png              # ğŸ—‘ï¸ ì‚­ì œ ëŒ€ìƒ

# ì •ë¦¬ í›„ êµ¬ì¡°
apps/frontend/public/
â”œâ”€â”€ logo.png                 # ë©”ì¸ ë¡œê³  (1ê°œë§Œ ìœ ì§€)
â”œâ”€â”€ logo-dark.png            # ë‹¤í¬ëª¨ë“œìš© (í•„ìš”ì‹œ)
â””â”€â”€ favicon.ico              # íŒŒë¹„ì½˜
```

#### 6.2.6 í…ŒìŠ¤íŠ¸ ì•„í‹°íŒ©íŠ¸ ì •ë¦¬

```bash
# ì‚­ì œ ëŒ€ìƒ (ê°œë°œ ì¤‘ ìƒì„±ëœ ì„ì‹œ íŒŒì¼)
rm -rf apps/frontend/screenshots/
rm -rf apps/frontend/test-results/
rm apps/frontend/design-compliance-test.spec.ts  # ì¼íšŒì„± í…ŒìŠ¤íŠ¸
rm apps/frontend/e2e-visual-test.spec.ts          # ì¼íšŒì„± í…ŒìŠ¤íŠ¸
rm apps/frontend/take-final-screenshots.mjs       # ìŠ¤í¬ë¦½íŠ¸

# .gitignoreì— ì¶”ê°€ (í–¥í›„ ë°©ì§€)
echo "screenshots/" >> apps/frontend/.gitignore
echo "test-results/" >> apps/frontend/.gitignore
```

### 6.3 ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ì •ë¦¬

```bash
# ì´ë™ ëŒ€ìƒ
mv CODE-REVIEW-REPORT.md docs/
mv REFACTORING-PLAN.md docs/
mv SECURITY-AUDIT-REPORT.md docs/
mv DESIGN-COMPLIANCE-REPORT.md docs/

# ì‚­ì œ ëŒ€ìƒ (ìƒì„±ëœ ì„ì‹œ íŒŒì¼)
rm -rf nanobanana-output/
rm ë‰´ë””ìì¸*.png
```

### ğŸ“‹ Phase 4 ì²´í¬ë¦¬ìŠ¤íŠ¸

> **ì™„ë£Œ ì¡°ê±´**: í’ˆì§ˆ ê°•í™” ì™„ë£Œ, í”„ë¡œë•ì…˜ ì¤€ë¹„ ìƒíƒœ

#### ë¸Œëœë”© í†µì¼
- [ ] `grep -r "DT-RAG\|dt-rag\|dt_rag"` ì‹¤í–‰í•˜ì—¬ ëŒ€ìƒ íŒŒì¼ ëª©ë¡ í™•ë³´
- [ ] `config.py`: `dt-rag.com` â†’ `norade.ai`
- [ ] `package.json`: `dt-rag` â†’ `norade`
- [ ] `README.md`: DT-RAG â†’ Norade
- [ ] ê¸°íƒ€ íŒŒì¼ë“¤ ë¸Œëœë”© ì—…ë°ì´íŠ¸
- [ ] ì»¤ë°‹ ìƒì„± (`chore: complete branding from DT-RAG to Norade`)

#### í”„ë¡ íŠ¸ì—”ë“œ ì •ë¦¬
- [ ] **êµ¬ì¡° ê²°ì •**: [ ] ì˜µì…˜ A (src/ í™œì„±í™”) / [ ] ì˜µì…˜ B (ì‚­ì œ) / [ ] ì˜µì…˜ C (ì ì§„ì )
- [ ] DEPRECATED ë¦¬ì†ŒìŠ¤ ì‚­ì œ (`public/avatars/robots/*.svg`)
- [ ] ë¡œê³  íŒŒì¼ ì •ë¦¬ (ìµœì¢… 1ê°œë§Œ ìœ ì§€ â†’ `logo.png`)
- [ ] ì„ì‹œ íŒŒì¼ ì‚­ì œ (`unnamed.png`, ì¤‘ë³µ ë¡œê³ ë“¤)
- [ ] í…ŒìŠ¤íŠ¸ ì•„í‹°íŒ©íŠ¸ ì‚­ì œ (`screenshots/`, `test-results/`)
- [ ] ì¼íšŒì„± í…ŒìŠ¤íŠ¸ íŒŒì¼ ì‚­ì œ (`design-compliance-test.spec.ts`, `e2e-visual-test.spec.ts`)
- [ ] `.gitignore` ì—…ë°ì´íŠ¸ (screenshots/, test-results/ ì¶”ê°€)
- [ ] ì»¤ë°‹ ìƒì„± (`chore: cleanup frontend deprecated resources`)

#### ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ì •ë¦¬
- [ ] `docs/` ë””ë ‰í† ë¦¬ ìƒì„± (ì—†ëŠ” ê²½ìš°)
- [ ] `CODE-REVIEW-REPORT.md` â†’ `docs/` ì´ë™
- [ ] `REFACTORING-PLAN.md` â†’ `docs/` ì´ë™
- [ ] `SECURITY-AUDIT-REPORT.md` â†’ `docs/` ì´ë™
- [ ] `DESIGN-COMPLIANCE-REPORT.md` â†’ `docs/` ì´ë™
- [ ] `nanobanana-output/` ì‚­ì œ
- [ ] `ë‰´ë””ìì¸*.png` ì‚­ì œ
- [ ] ì»¤ë°‹ ìƒì„± (`chore: organize root directory`)

#### ìë™í™” ë³‘í–‰ (Week 4-5)
- [ ] Self-healing ë¯¸ë“¤ì›¨ì–´ êµ¬í˜„ (`middleware/self_healing.py`)
- [ ] Circuit Breaker ì ìš© ë° í…ŒìŠ¤íŠ¸
- [ ] ë¶€í•˜ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (k6 ë˜ëŠ” locust)
- [ ] Runbook ë¬¸ì„œ ì‘ì„±

#### Phase 4 ì™„ë£Œ ê²€ì¦
- [ ] ëª¨ë“  ë¸Œëœë”©ì´ Noradeë¡œ í†µì¼ë¨
- [ ] ë¶ˆí•„ìš”í•œ íŒŒì¼ ì—†ìŒ (ê¹”ë”í•œ ë£¨íŠ¸ ë””ë ‰í† ë¦¬)
- [ ] í”„ë¡ íŠ¸ì—”ë“œ êµ¬ì¡° ì •ë¦¬ ì™„ë£Œ
- [ ] í”„ë¡œë•ì…˜ ë°°í¬ ì¤€ë¹„ ì™„ë£Œ
- [ ] ìµœì¢… í…ŒìŠ¤íŠ¸ í†µê³¼

**ğŸ‰ ë¦¬íŒ©í† ë§ ì™„ë£Œ!** â†’ í”„ë¡œë•ì…˜ ë°°í¬ ë° ëª¨ë‹ˆí„°ë§ ì „í™˜

---

## 7. ğŸ¤– ìë™í™” íŠ¸ë™: 1ì¸ ê°œë°œì ìƒì¡´ ì „ëµ

> **í•µì‹¬ ì›ì¹™**: "ë‚´ê°€ ìê³  ìˆì„ ë•Œë„ ì‹œìŠ¤í…œì´ ìŠ¤ìŠ¤ë¡œ ëŒì•„ê°€ì•¼ í•œë‹¤"

### 7.1 ìë™í™” ì² í•™

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           1ì¸ ê°œë°œì ìë™í™” í”¼ë¼ë¯¸ë“œ (ìš°ì„ ìˆœìœ„)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  Level 5: ğŸ¯ Self-Healing (ìê°€ ì¹˜ìœ )                            â”‚
â”‚           â””â”€ Auto-restart, Circuit Breaker, Chaos Testing       â”‚
â”‚                                                                  â”‚
â”‚  Level 4: ğŸ“Š Observability (ê´€ì¸¡ì„±)                              â”‚
â”‚           â””â”€ ëª¨ë‹ˆí„°ë§, ì•ŒëŒ, ë¡œê·¸ ì§‘ê³„, APM                       â”‚
â”‚                                                                  â”‚
â”‚  Level 3: ğŸš€ CD - Continuous Deployment (ìë™ ë°°í¬)              â”‚
â”‚           â””â”€ ìŠ¤í…Œì´ì§• ìë™ ë°°í¬, í”„ë¡œë•ì…˜ ì›í´ë¦­                   â”‚
â”‚                                                                  â”‚
â”‚  Level 2: ğŸ”’ CI - Quality Gates (í’ˆì§ˆ ê²€ì¦)                      â”‚
â”‚           â””â”€ í…ŒìŠ¤íŠ¸, ë¦°íŒ…, ë³´ì•ˆ ìŠ¤ìº”, íƒ€ì… ì²´í¬                    â”‚
â”‚                                                                  â”‚
â”‚  Level 1: ğŸ”§ Dev Automation (ê°œë°œ ìë™í™”)                        â”‚
â”‚           â””â”€ Pre-commit, ì˜ì¡´ì„± ì—…ë°ì´íŠ¸, í¬ë§·íŒ…                  â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 7.2 í˜„ì¬ ìƒíƒœ ë¶„ì„

| ì˜ì—­ | í˜„ì¬ ìƒíƒœ | ìë™í™”ìœ¨ | ëª©í‘œ |
|------|----------|---------|------|
| **CI (í…ŒìŠ¤íŠ¸)** | âŒ ì—†ìŒ | 0% | 100% |
| **CD (ë°°í¬)** | âš ï¸ ë¦´ë¦¬ì¦ˆë§Œ | 30% | 90% |
| **ëª¨ë‹ˆí„°ë§** | âš ï¸ Sentry ì„¤ì •ë§Œ | 20% | 95% |
| **ë°±ì—…** | âŒ ì—†ìŒ | 0% | 100% |
| **ì˜ì¡´ì„±** | âŒ ìˆ˜ë™ | 0% | 100% |
| **ë³´ì•ˆ ìŠ¤ìº”** | âŒ ì—†ìŒ | 0% | 100% |

**í˜„ì¬ ì´ ìë™í™”ìœ¨: ~12%** â†’ **ëª©í‘œ: 90%+**

### 7.3 ìë™í™” êµ¬í˜„ ê³„íš

#### ğŸ”§ Tier 1: í•„ìˆ˜ (Week 1ê³¼ ë³‘í–‰)

##### 7.3.1 CI Pipeline - í…ŒìŠ¤íŠ¸ ìë™í™”

```yaml
# .github/workflows/ci.yml
name: CI Pipeline

on:
  push:
    branches: [main, develop, feature/*]
  pull_request:
    branches: [main, develop]

jobs:
  # Job 1: Backend í…ŒìŠ¤íŠ¸
  backend-test:
    runs-on: ubuntu-latest
    services:
      postgres:
        image: pgvector/pgvector:pg16
        env:
          POSTGRES_DB: dt_rag_test
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install uv
        uses: astral-sh/setup-uv@v4

      - name: Install dependencies
        run: uv sync --all-extras

      - name: Run tests with coverage
        env:
          DATABASE_URL: postgresql+asyncpg://postgres:postgres@localhost:5432/dt_rag_test
          REDIS_URL: redis://localhost:6379
          SECRET_KEY: test-secret-key
        run: |
          uv run pytest apps/api tests/ \
            --cov=apps/api \
            --cov-report=xml \
            --cov-report=html \
            --cov-fail-under=80 \
            -v

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          file: ./coverage.xml
          fail_ci_if_error: true

  # Job 2: Frontend í…ŒìŠ¤íŠ¸
  frontend-test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: apps/frontend/package-lock.json

      - name: Install dependencies
        working-directory: apps/frontend
        run: npm ci

      - name: Run lint
        working-directory: apps/frontend
        run: npm run lint

      - name: Run type check
        working-directory: apps/frontend
        run: npx tsc --noEmit

      - name: Run tests (when added)
        working-directory: apps/frontend
        run: npm test --passWithNoTests

      - name: Build check
        working-directory: apps/frontend
        run: npm run build

  # Job 3: Security Scan
  security-scan:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '.'
          severity: 'CRITICAL,HIGH'
          exit-code: '1'

      - name: Python security scan (bandit)
        run: |
          pip install bandit
          bandit -r apps/api -ll -ii

  # Job 4: Lint and Format
  lint:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v4

      - name: Run ruff
        run: uv run ruff check apps/ tests/

      - name: Run ruff format check
        run: uv run ruff format --check apps/ tests/

      - name: Run mypy
        run: uv run mypy apps/api --ignore-missing-imports
```

##### 7.3.2 Pre-commit Hooks

```yaml
# .pre-commit-config.yaml
repos:
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.5.0
    hooks:
      - id: trailing-whitespace
      - id: end-of-file-fixer
      - id: check-yaml
      - id: check-json
      - id: check-added-large-files
        args: ['--maxkb=1000']
      - id: detect-private-key
      - id: check-merge-conflict

  - repo: https://github.com/astral-sh/ruff-pre-commit
    rev: v0.3.0
    hooks:
      - id: ruff
        args: [--fix]
      - id: ruff-format

  - repo: https://github.com/pre-commit/mirrors-mypy
    rev: v1.8.0
    hooks:
      - id: mypy
        additional_dependencies: [types-all]
        args: [--ignore-missing-imports]

  - repo: local
    hooks:
      - id: pytest-check
        name: pytest-check
        entry: uv run pytest apps/api -x -q --tb=short
        language: system
        types: [python]
        pass_filenames: false
        always_run: true
```

#### ğŸš€ Tier 2: ì¤‘ìš” (Week 2ì™€ ë³‘í–‰)

##### 7.3.3 CD Pipeline - ìë™ ë°°í¬

```yaml
# .github/workflows/deploy.yml
name: Deploy Pipeline

on:
  push:
    branches: [main]
  workflow_dispatch:
    inputs:
      environment:
        description: 'Deployment environment'
        required: true
        default: 'staging'
        type: choice
        options:
          - staging
          - production

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  build-and-push:
    runs-on: ubuntu-latest
    outputs:
      image_tag: ${{ steps.meta.outputs.tags }}

    steps:
      - uses: actions/checkout@v4

      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
          tags: |
            type=sha,prefix=
            type=ref,event=branch

      - name: Build and push API image
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./Dockerfile.api
          push: true
          tags: ${{ steps.meta.outputs.tags }}-api
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: Build and push Frontend image
        uses: docker/build-push-action@v5
        with:
          context: ./apps/frontend
          push: true
          tags: ${{ steps.meta.outputs.tags }}-frontend
          cache-from: type=gha
          cache-to: type=gha,mode=max

  deploy-staging:
    needs: build-and-push
    runs-on: ubuntu-latest
    environment: staging

    steps:
      - name: Deploy to Railway/Render (staging)
        run: |
          # Railway ë˜ëŠ” Render webhook í˜¸ì¶œ
          curl -X POST "${{ secrets.STAGING_DEPLOY_WEBHOOK }}" \
            -H "Content-Type: application/json" \
            -d '{"image": "${{ needs.build-and-push.outputs.image_tag }}"}'

      - name: Health check
        run: |
          for i in {1..30}; do
            if curl -s "${{ secrets.STAGING_URL }}/health" | grep -q "ok"; then
              echo "âœ… Staging deployment healthy"
              exit 0
            fi
            sleep 10
          done
          echo "âŒ Staging health check failed"
          exit 1

      - name: Notify on Slack
        if: always()
        uses: slackapi/slack-github-action@v1
        with:
          payload: |
            {
              "text": "Staging Deploy: ${{ job.status }}",
              "blocks": [
                {
                  "type": "section",
                  "text": {
                    "type": "mrkdwn",
                    "text": "${{ job.status == 'success' && 'âœ…' || 'âŒ' }} Staging deployment ${{ job.status }}\nCommit: ${{ github.sha }}"
                  }
                }
              ]
            }
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK }}

  deploy-production:
    needs: [build-and-push, deploy-staging]
    runs-on: ubuntu-latest
    environment: production
    if: github.event.inputs.environment == 'production' || github.ref == 'refs/heads/main'

    steps:
      - name: Deploy to Railway/Render (production)
        run: |
          curl -X POST "${{ secrets.PRODUCTION_DEPLOY_WEBHOOK }}" \
            -H "Content-Type: application/json" \
            -d '{"image": "${{ needs.build-and-push.outputs.image_tag }}"}'

      - name: Health check
        run: |
          for i in {1..30}; do
            if curl -s "${{ secrets.PRODUCTION_URL }}/health" | grep -q "ok"; then
              echo "âœ… Production deployment healthy"
              exit 0
            fi
            sleep 10
          done
          echo "âŒ Production health check failed"
          exit 1
```

##### 7.3.4 ì˜ì¡´ì„± ìë™ ì—…ë°ì´íŠ¸

```yaml
# .github/dependabot.yml
version: 2
updates:
  # Python dependencies
  - package-ecosystem: "pip"
    directory: "/"
    schedule:
      interval: "weekly"
      day: "monday"
    open-pull-requests-limit: 5
    labels:
      - "dependencies"
      - "python"
    groups:
      production-deps:
        patterns:
          - "fastapi*"
          - "sqlalchemy*"
          - "pydantic*"
      dev-deps:
        patterns:
          - "pytest*"
          - "ruff*"
          - "mypy*"

  # npm dependencies
  - package-ecosystem: "npm"
    directory: "/apps/frontend"
    schedule:
      interval: "weekly"
      day: "monday"
    open-pull-requests-limit: 5
    labels:
      - "dependencies"
      - "javascript"
    groups:
      next-ecosystem:
        patterns:
          - "next*"
          - "react*"

  # Docker dependencies
  - package-ecosystem: "docker"
    directory: "/"
    schedule:
      interval: "weekly"
    labels:
      - "dependencies"
      - "docker"

  # GitHub Actions
  - package-ecosystem: "github-actions"
    directory: "/"
    schedule:
      interval: "weekly"
    labels:
      - "dependencies"
      - "github-actions"
```

#### ğŸ“Š Tier 3: ìš´ì˜ ì•ˆì •í™” (Week 3ì™€ ë³‘í–‰)

##### 7.3.5 ëª¨ë‹ˆí„°ë§ & ì•ŒëŒ

```yaml
# .github/workflows/monitoring.yml
name: Health Monitoring

on:
  schedule:
    - cron: '*/5 * * * *'  # 5ë¶„ë§ˆë‹¤
  workflow_dispatch:

jobs:
  health-check:
    runs-on: ubuntu-latest

    steps:
      - name: Check API Health
        id: api_health
        continue-on-error: true
        run: |
          RESPONSE=$(curl -s -o /dev/null -w "%{http_code}" \
            "${{ secrets.PRODUCTION_URL }}/health" \
            --max-time 30)

          if [ "$RESPONSE" = "200" ]; then
            echo "status=healthy" >> $GITHUB_OUTPUT
          else
            echo "status=unhealthy" >> $GITHUB_OUTPUT
            echo "http_code=$RESPONSE" >> $GITHUB_OUTPUT
          fi

      - name: Check Frontend Health
        id: frontend_health
        continue-on-error: true
        run: |
          RESPONSE=$(curl -s -o /dev/null -w "%{http_code}" \
            "${{ secrets.FRONTEND_URL }}" \
            --max-time 30)

          if [ "$RESPONSE" = "200" ]; then
            echo "status=healthy" >> $GITHUB_OUTPUT
          else
            echo "status=unhealthy" >> $GITHUB_OUTPUT
          fi

      - name: Check Database Connection
        id: db_health
        continue-on-error: true
        run: |
          RESPONSE=$(curl -s "${{ secrets.PRODUCTION_URL }}/health/db" \
            --max-time 30)

          if echo "$RESPONSE" | grep -q "connected"; then
            echo "status=healthy" >> $GITHUB_OUTPUT
          else
            echo "status=unhealthy" >> $GITHUB_OUTPUT
          fi

      - name: Alert on Failure
        if: |
          steps.api_health.outputs.status == 'unhealthy' ||
          steps.frontend_health.outputs.status == 'unhealthy' ||
          steps.db_health.outputs.status == 'unhealthy'
        uses: slackapi/slack-github-action@v1
        with:
          payload: |
            {
              "text": "ğŸš¨ ALERT: Service Health Check Failed!",
              "blocks": [
                {
                  "type": "section",
                  "text": {
                    "type": "mrkdwn",
                    "text": "ğŸš¨ *Service Health Check Failed*\n\nâ€¢ API: ${{ steps.api_health.outputs.status }}\nâ€¢ Frontend: ${{ steps.frontend_health.outputs.status }}\nâ€¢ Database: ${{ steps.db_health.outputs.status }}"
                  }
                }
              ]
            }
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_ALERT_WEBHOOK }}

      - name: Send PagerDuty Alert (Critical)
        if: steps.api_health.outputs.status == 'unhealthy'
        run: |
          curl -X POST "https://events.pagerduty.com/v2/enqueue" \
            -H "Content-Type: application/json" \
            -d '{
              "routing_key": "${{ secrets.PAGERDUTY_KEY }}",
              "event_action": "trigger",
              "payload": {
                "summary": "Norade API is down",
                "severity": "critical",
                "source": "GitHub Actions Health Monitor"
              }
            }'
```

##### 7.3.6 ìë™ ë°±ì—…

```yaml
# .github/workflows/backup.yml
name: Database Backup

on:
  schedule:
    - cron: '0 3 * * *'  # ë§¤ì¼ ì˜¤ì „ 3ì‹œ (KST 12ì‹œ)
  workflow_dispatch:

jobs:
  backup:
    runs-on: ubuntu-latest

    steps:
      - name: Create database backup
        run: |
          # PostgreSQL ë°±ì—… ìƒì„±
          PGPASSWORD=${{ secrets.DB_PASSWORD }} pg_dump \
            -h ${{ secrets.DB_HOST }} \
            -U postgres \
            -d dt_rag \
            -F c \
            -f backup_$(date +%Y%m%d_%H%M%S).dump

      - name: Upload to S3/R2
        run: |
          # Cloudflare R2 ë˜ëŠ” AWS S3ì— ì—…ë¡œë“œ
          aws s3 cp backup_*.dump \
            s3://${{ secrets.BACKUP_BUCKET }}/db-backups/ \
            --endpoint-url ${{ secrets.R2_ENDPOINT }}

      - name: Cleanup old backups (30ì¼ ì´ìƒ)
        run: |
          aws s3 ls s3://${{ secrets.BACKUP_BUCKET }}/db-backups/ \
            --endpoint-url ${{ secrets.R2_ENDPOINT }} | \
          while read -r line; do
            createDate=$(echo "$line" | awk '{print $1}')
            if [[ $(date -d "$createDate" +%s) -lt $(date -d "30 days ago" +%s) ]]; then
              fileName=$(echo "$line" | awk '{print $4}')
              aws s3 rm "s3://${{ secrets.BACKUP_BUCKET }}/db-backups/$fileName" \
                --endpoint-url ${{ secrets.R2_ENDPOINT }}
            fi
          done

      - name: Notify on completion
        uses: slackapi/slack-github-action@v1
        with:
          payload: |
            {
              "text": "âœ… Daily database backup completed successfully"
            }
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK }}
```

#### ğŸ¯ Tier 4: Self-Healing (Week 4 ì´í›„)

##### 7.3.7 ìê°€ ì¹˜ìœ  ì‹œìŠ¤í…œ

```python
# apps/api/middleware/self_healing.py
"""
Self-Healing Middleware for Production Stability
"""
import asyncio
import logging
from datetime import datetime, timedelta
from typing import Optional
from collections import deque

logger = logging.getLogger(__name__)


class CircuitBreaker:
    """Circuit Breaker Pattern Implementation"""

    def __init__(
        self,
        failure_threshold: int = 5,
        recovery_timeout: int = 60,
        half_open_requests: int = 3
    ):
        self.failure_threshold = failure_threshold
        self.recovery_timeout = recovery_timeout
        self.half_open_requests = half_open_requests

        self.failures = 0
        self.state = "CLOSED"  # CLOSED, OPEN, HALF_OPEN
        self.last_failure_time: Optional[datetime] = None
        self.success_count = 0

    async def call(self, func, *args, **kwargs):
        if self.state == "OPEN":
            if self._should_attempt_reset():
                self.state = "HALF_OPEN"
                self.success_count = 0
            else:
                raise CircuitBreakerOpenError("Circuit breaker is OPEN")

        try:
            result = await func(*args, **kwargs)
            self._on_success()
            return result
        except Exception as e:
            self._on_failure()
            raise

    def _on_success(self):
        if self.state == "HALF_OPEN":
            self.success_count += 1
            if self.success_count >= self.half_open_requests:
                self.state = "CLOSED"
                self.failures = 0
                logger.info("Circuit breaker CLOSED - service recovered")
        else:
            self.failures = 0

    def _on_failure(self):
        self.failures += 1
        self.last_failure_time = datetime.now()

        if self.failures >= self.failure_threshold:
            self.state = "OPEN"
            logger.warning(f"Circuit breaker OPEN after {self.failures} failures")

    def _should_attempt_reset(self) -> bool:
        if self.last_failure_time is None:
            return True
        return datetime.now() > self.last_failure_time + timedelta(seconds=self.recovery_timeout)


class HealthMonitor:
    """Continuous Health Monitoring with Auto-Recovery"""

    def __init__(self, check_interval: int = 30):
        self.check_interval = check_interval
        self.health_history = deque(maxlen=100)
        self.is_healthy = True

    async def start_monitoring(self):
        while True:
            try:
                health = await self._check_health()
                self.health_history.append({
                    "timestamp": datetime.now(),
                    "healthy": health,
                })

                if not health and self.is_healthy:
                    await self._trigger_recovery()
                    self.is_healthy = False
                elif health and not self.is_healthy:
                    logger.info("Service recovered")
                    self.is_healthy = True

            except Exception as e:
                logger.error(f"Health check failed: {e}")

            await asyncio.sleep(self.check_interval)

    async def _check_health(self) -> bool:
        # DB, Redis, ì™¸ë¶€ ì„œë¹„ìŠ¤ ì²´í¬
        checks = await asyncio.gather(
            self._check_db(),
            self._check_redis(),
            self._check_memory(),
            return_exceptions=True
        )
        return all(c is True for c in checks if not isinstance(c, Exception))

    async def _trigger_recovery(self):
        """Auto-recovery actions"""
        logger.warning("Triggering auto-recovery...")

        # 1. ìºì‹œ í´ë¦¬ì–´
        await self._clear_caches()

        # 2. ì»¤ë„¥ì…˜ í’€ ë¦¬ì…‹
        await self._reset_connection_pools()

        # 3. ì™¸ë¶€ ì•Œë¦¼
        await self._send_alert("Service degradation detected, auto-recovery initiated")
```

### 7.4 ì¸í”„ë¼ ê¶Œì¥ ì‚¬í•­ (1ì¸ ê°œë°œììš©)

#### 7.4.1 í˜¸ìŠ¤íŒ… í”Œë«í¼ ë¹„êµ

| í”Œë«í¼ | ë¹„ìš© (ì›”) | ìë™í™” ìˆ˜ì¤€ | ê´€ë¦¬ ë¶€ë‹´ | ì¶”ì²œ |
|--------|----------|------------|----------|------|
| **Railway** | $5-20 | â­â­â­â­â­ | ìµœì†Œ | âœ… 1ìˆœìœ„ |
| **Render** | $7-25 | â­â­â­â­ | ë‚®ìŒ | âœ… 2ìˆœìœ„ |
| **Fly.io** | $5-15 | â­â­â­â­ | ë‚®ìŒ | ì˜µì…˜ |
| **Vercel** (Frontend) | $0-20 | â­â­â­â­â­ | ìµœì†Œ | âœ… í”„ë¡ íŠ¸ì—”ë“œ |
| AWS/GCP | $50+ | â­â­ | ë†’ìŒ | âŒ ë¹„ì¶”ì²œ |

#### 7.4.2 ê¶Œì¥ ìŠ¤íƒ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              1ì¸ ê°œë°œì ê¶Œì¥ ìŠ¤íƒ                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                      â”‚
â”‚  Frontend: Vercel (ë¬´ë£Œ ~ $20)                       â”‚
â”‚  â”œâ”€ ìë™ ë°°í¬ (git push)                             â”‚
â”‚  â”œâ”€ Edge Functions                                   â”‚
â”‚  â””â”€ Analytics ë‚´ì¥                                   â”‚
â”‚                                                      â”‚
â”‚  Backend: Railway ($5 ~ $20)                         â”‚
â”‚  â”œâ”€ Docker ìë™ ë°°í¬                                  â”‚
â”‚  â”œâ”€ PostgreSQL ê´€ë¦¬í˜•                                 â”‚
â”‚  â”œâ”€ Redis ë‚´ì¥                                        â”‚
â”‚  â””â”€ ìë™ ìŠ¤ì¼€ì¼ë§                                     â”‚
â”‚                                                      â”‚
â”‚  Monitoring: ë¬´ë£Œ ì¡°í•©                                â”‚
â”‚  â”œâ”€ Sentry (ì—ëŸ¬ íŠ¸ë˜í‚¹, ë¬´ë£Œ 5K)                     â”‚
â”‚  â”œâ”€ Better Uptime (ìƒíƒœ ëª¨ë‹ˆí„°ë§, ë¬´ë£Œ)              â”‚
â”‚  â”œâ”€ Langfuse (LLM ì˜µì €ë²„ë¹Œë¦¬í‹°, ë¬´ë£Œ)                â”‚
â”‚  â””â”€ GitHub Actions (CI/CD, ë¬´ë£Œ 2000ë¶„)              â”‚
â”‚                                                      â”‚
â”‚  Backup: Cloudflare R2 ($0.015/GB)                   â”‚
â”‚                                                      â”‚
â”‚  ì›” ì˜ˆìƒ ë¹„ìš©: $10-50                                 â”‚
â”‚                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 7.5 ìë™í™” êµ¬í˜„ ì¼ì •

```
Week 1 (Phase 0-1ê³¼ ë³‘í–‰):
â”œâ”€â”€ Day 1: Pre-commit hooks ì„¤ì •
â”œâ”€â”€ Day 2-3: CI Pipeline (ci.yml) êµ¬í˜„
â””â”€â”€ Day 4-5: Dependabot ì„¤ì •

Week 2 (Phase 1-2ì™€ ë³‘í–‰):
â”œâ”€â”€ Day 6-7: CD Pipeline (deploy.yml) êµ¬í˜„
â”œâ”€â”€ Day 8-9: Railway/Vercel ë°°í¬ ì„¤ì •
â””â”€â”€ Day 10: Staging í™˜ê²½ êµ¬ì„±

Week 3 (Phase 2-3ì™€ ë³‘í–‰):
â”œâ”€â”€ Day 11-12: Monitoring workflow êµ¬í˜„
â”œâ”€â”€ Day 13-14: Backup workflow êµ¬í˜„
â””â”€â”€ Day 15: Slack/PagerDuty ì•Œë¦¼ ì—°ë™

Week 4 (Phase 3-4ì™€ ë³‘í–‰):
â”œâ”€â”€ Day 16-18: Self-healing ë¯¸ë“¤ì›¨ì–´ êµ¬í˜„
â”œâ”€â”€ Day 19: Circuit Breaker ì ìš©
â””â”€â”€ Day 20: ì „ì²´ ìë™í™” í…ŒìŠ¤íŠ¸

Week 5 (ë§ˆë¬´ë¦¬):
â”œâ”€â”€ Day 21-22: ë¶€í•˜ í…ŒìŠ¤íŠ¸ ë° íŠœë‹
â”œâ”€â”€ Day 23-24: ë¬¸ì„œí™” ë° Runbook ì‘ì„±
â””â”€â”€ Day 25: í”„ë¡œë•ì…˜ ê²€ì¦
```

### 7.6 ìë™í™” ì²´í¬ë¦¬ìŠ¤íŠ¸

#### Tier 1: í•„ìˆ˜ (Week 1)
- [ ] Pre-commit hooks ì„¤ì¹˜ ë° ì„¤ì •
- [ ] CI Pipeline (í…ŒìŠ¤íŠ¸) êµ¬í˜„
- [ ] ì½”ë“œ ì»¤ë²„ë¦¬ì§€ 80% ì´ìƒ ê²Œì´íŠ¸
- [ ] Dependabot ì„¤ì •

#### Tier 2: ì¤‘ìš” (Week 2)
- [ ] CD Pipeline (ìë™ ë°°í¬) êµ¬í˜„
- [ ] Staging í™˜ê²½ êµ¬ì„±
- [ ] Production í™˜ê²½ êµ¬ì„±
- [ ] ë°°í¬ ì•Œë¦¼ (Slack) ì—°ë™

#### Tier 3: ìš´ì˜ (Week 3)
- [ ] Health check monitoring êµ¬í˜„
- [ ] ì•ŒëŒ ì‹œìŠ¤í…œ (Slack/PagerDuty)
- [ ] ìë™ ë°±ì—… êµ¬í˜„
- [ ] ë°±ì—… ë³µêµ¬ í…ŒìŠ¤íŠ¸

#### Tier 4: ê³ ê¸‰ (Week 4-5)
- [ ] Circuit Breaker êµ¬í˜„
- [ ] Self-healing ë¯¸ë“¤ì›¨ì–´
- [ ] Chaos Engineering í…ŒìŠ¤íŠ¸
- [ ] Runbook ë¬¸ì„œí™”

---

## 8. ë¡¤ë°± ì „ëµ

### 8.1 ì¦‰ê° ë¡¤ë°± (30ë¶„ ì´ë‚´)

```bash
# Feature Flag ë¹„í™œì„±í™”
export REFACTORING_FLAGS='{"use_persistent_qtable": false}'

# ì„œë²„ ì¬ì‹œì‘
docker-compose restart api
```

### 8.2 ì½”ë“œ ë¡¤ë°± (1ì‹œê°„ ì´ë‚´)

```bash
# íŠ¹ì • ì»¤ë°‹ìœ¼ë¡œ ë¡¤ë°±
git log --oneline -10
git revert <commit-hash>

# ë˜ëŠ” ë¸Œëœì¹˜ ì „ì²´ ë¡¤ë°±
git checkout master
git branch -D feature/refactor-phase-X
```

### 8.3 ë°ì´í„°ë² ì´ìŠ¤ ë¡¤ë°± (2ì‹œê°„ ì´ë‚´)

```bash
# Alembic ë‹¤ìš´ê·¸ë ˆì´ë“œ
alembic downgrade -1

# ë°±ì—…ì—ì„œ ë³µì› (ìµœì•…ì˜ ê²½ìš°)
pg_restore -d dt_rag backup_before_refactor.sql
```

---

## 9. ì²´í¬ë¦¬ìŠ¤íŠ¸

### Phase 0: ì‚¬ì „ ì¤€ë¹„
- [ ] í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ ê¸°ì¤€ì„  ê¸°ë¡
- [ ] E2E í…ŒìŠ¤íŠ¸ ê²°ê³¼ ê¸°ë¡
- [ ] DB ìŠ¤í‚¤ë§ˆ ë°±ì—…
- [ ] Feature Flag í™˜ê²½ ì„¤ì •

### Phase 1: Critical ì´ìŠˆ
- [ ] Import ê²½ë¡œ ìˆ˜ì • ì™„ë£Œ
- [ ] Import í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] Q-Table ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í‚¤ë§ˆ ì‘ì„±
- [ ] Q-Table ë§ˆì´ê·¸ë ˆì´ì…˜ í…ŒìŠ¤íŠ¸
- [ ] Q-Table í”„ë¡œë•ì…˜ ë°°í¬
- [ ] Reranker ì „ëµ ê²°ì • (ëª…ì„¸ ìˆ˜ì • or êµ¬í˜„)
- [ ] Reranker ë³€ê²½ ì™„ë£Œ

### Phase 2: High ì´ìŠˆ
- [ ] PostgreSQL í…ŒìŠ¤íŠ¸ í™˜ê²½ êµ¬ì„±
- [ ] CI/CDì— PostgreSQL í…ŒìŠ¤íŠ¸ ì¶”ê°€
- [ ] SearchService ëª…ì¹­ ë¶„ë¦¬ ì™„ë£Œ
- [ ] í”„ë¡ íŠ¸ì—”ë“œ Jest ì„¤ì •
- [ ] í•µì‹¬ ì»´í¬ë„ŒíŠ¸ í…ŒìŠ¤íŠ¸ 10ê°œ ì´ìƒ

### Phase 3: êµ¬ì¡° ê°œì„ 
- [ ] database.py íŒ¨í‚¤ì§€ ë¶„ë¦¬
- [ ] ë ˆê±°ì‹œ facade ìœ ì§€
- [ ] import ê²½ë¡œ ì—…ë°ì´íŠ¸

### Phase 4: í’ˆì§ˆ ê°•í™”
- [ ] ë¸Œëœë”© í†µì¼ (DT-RAG â†’ Norade)
- [ ] í”„ë¡ íŠ¸ì—”ë“œ êµ¬ì¡° ê²°ì • (src/ Clean Architecture í™œì„±í™” ë°©ì‹)
- [ ] DEPRECATED ë¦¬ì†ŒìŠ¤ ì •ë¦¬ (avatars/robots/)
- [ ] ë¡œê³  íŒŒì¼ ì •ë¦¬ ë° í‘œì¤€í™”
- [ ] í…ŒìŠ¤íŠ¸ ì•„í‹°íŒ©íŠ¸ ì‚­ì œ (screenshots/, test-results/)
- [ ] .gitignore ì—…ë°ì´íŠ¸
- [ ] ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ì •ë¦¬
- [ ] ë¬¸ì„œ ìµœì¢… ê²€í† 

---

## íƒ€ì„ë¼ì¸ ìš”ì•½

```
Week 1 (Day 1-5):
â”œâ”€â”€ Day 1: Phase 0 - ì‚¬ì „ ì¤€ë¹„
â”œâ”€â”€ Day 2-4: Phase 1 - Q-Table ë§ˆì´ê·¸ë ˆì´ì…˜
â””â”€â”€ Day 5: Phase 1 - Import ìˆ˜ì •, Reranker ê²°ì •

Week 2 (Day 6-10):
â”œâ”€â”€ Day 6-8: Phase 1 - Reranker ì‘ì—… ì™„ë£Œ
â”œâ”€â”€ Day 9-10: Phase 2 - PostgreSQL í…ŒìŠ¤íŠ¸ í™˜ê²½
â””â”€â”€ Day 10: Phase 2 - SearchService ëª…ì¹­ ë¶„ë¦¬ ì‹œì‘

Week 3 (Day 11-15):
â”œâ”€â”€ Day 11-12: Phase 2 - SearchService ì™„ë£Œ
â”œâ”€â”€ Day 13-14: Phase 2 - í”„ë¡ íŠ¸ì—”ë“œ í…ŒìŠ¤íŠ¸
â””â”€â”€ Day 15: Phase 3 - database.py ë¶„ë¦¬ ì‹œì‘

Week 4 (Day 16-20):
â”œâ”€â”€ Day 16-18: Phase 3 - database.py ë¶„ë¦¬ ì™„ë£Œ
â”œâ”€â”€ Day 19: Phase 4 - ë¸Œëœë”©, ì •ë¦¬
â””â”€â”€ Day 20: ìµœì¢… ê²€í†  ë° ë¬¸ì„œí™”
```

---

**ì‘ì„±**: Claude (Alfred)
**ê²€í†  í•„ìš”**: íŒ€ ë¦¬ë“œ
**ìŠ¹ì¸ ìƒíƒœ**: ëŒ€ê¸° ì¤‘

*Last Updated: 2025-11-30*

#!/usr/bin/env python3
"""
ìµœì í™”ëœ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
ì„ë² ë”© ìºì‹œ ë° ì—°ê²° í’€ ìµœì í™” ì ìš©
"""

import asyncio
import time
import sys
import os
import hashlib
import json
from typing import Dict, List, Any
import httpx

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.join(os.path.dirname(__file__), 'apps', 'api'))

# ì„ë² ë”© ìºì‹œ (ë©”ëª¨ë¦¬ ê¸°ë°˜)
EMBEDDING_CACHE: Dict[str, List[float]] = {}
HTTP_CLIENT = None

class OptimizedEmbeddingService:
    """ìµœì í™”ëœ ì„ë² ë”© ì„œë¹„ìŠ¤"""

    @staticmethod
    async def get_http_client():
        """HTTP í´ë¼ì´ì–¸íŠ¸ ì‹±ê¸€í†¤"""
        global HTTP_CLIENT
        if HTTP_CLIENT is None:
            HTTP_CLIENT = httpx.AsyncClient(
                limits=httpx.Limits(max_connections=10, max_keepalive_connections=5),
                timeout=httpx.Timeout(30.0)
            )
        return HTTP_CLIENT

    @staticmethod
    def get_cache_key(text: str) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        return hashlib.md5(text.encode('utf-8')).hexdigest()

    @staticmethod
    async def generate_embedding_cached(text: str) -> List[float]:
        """ìºì‹œëœ ì„ë² ë”© ìƒì„±"""
        cache_key = OptimizedEmbeddingService.get_cache_key(text)

        # ìºì‹œì—ì„œ í™•ì¸
        if cache_key in EMBEDDING_CACHE:
            print(f"Cache HIT for text: {text[:50]}...")
            return EMBEDDING_CACHE[cache_key]

        print(f"Cache MISS for text: {text[:50]}...")

        # OpenAI API í˜¸ì¶œ
        try:
            client = await OptimizedEmbeddingService.get_http_client()

            response = await client.post(
                "https://api.openai.com/v1/embeddings",
                headers={
                    "Authorization": f"Bearer {os.getenv('OPENAI_API_KEY')}",
                    "Content-Type": "application/json"
                },
                json={
                    "input": text,
                    "model": "text-embedding-ada-002"
                }
            )

            if response.status_code == 200:
                data = response.json()
                embedding = data["data"][0]["embedding"]

                # ìºì‹œì— ì €ì¥
                EMBEDDING_CACHE[cache_key] = embedding

                return embedding
            else:
                print(f"OpenAI API error: {response.status_code} - {response.text}")
                return [0.0] * 1536  # ê¸°ë³¸ ì„ë² ë”©

        except Exception as e:
            print(f"Embedding generation error: {e}")
            return [0.0] * 1536  # ê¸°ë³¸ ì„ë² ë”©

    @staticmethod
    async def generate_embeddings_batch(texts: List[str]) -> List[List[float]]:
        """ë°°ì¹˜ ì„ë² ë”© ìƒì„±"""
        if len(texts) <= 1:
            if texts:
                return [await OptimizedEmbeddingService.generate_embedding_cached(texts[0])]
            return []

        # ê°œë³„ ìƒì„± (OpenAI ë°°ì¹˜ APIëŠ” ë³„ë„ êµ¬í˜„ í•„ìš”)
        embeddings = []
        for text in texts:
            embedding = await OptimizedEmbeddingService.generate_embedding_cached(text)
            embeddings.append(embedding)

        return embeddings

class OptimizedSearchDAO:
    """ìµœì í™”ëœ ê²€ìƒ‰ DAO"""

    @staticmethod
    async def optimized_hybrid_search(
        query: str,
        filters: Dict = None,
        topk: int = 5,
        bm25_topk: int = 12,
        vector_topk: int = 12,
        rerank_candidates: int = 50
    ) -> List[Dict[str, Any]]:
        """ìµœì í™”ëœ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰"""
        from database import db_manager, SearchDAO

        start_time = time.time()

        async with db_manager.async_session() as session:
            try:
                # 1. ì¿¼ë¦¬ ì„ë² ë”© ìƒì„± (ìºì‹œ ì‚¬ìš©)
                embedding_start = time.time()
                query_embedding = await OptimizedEmbeddingService.generate_embedding_cached(query)
                embedding_time = time.time() - embedding_start

                # 2. BM25 ê²€ìƒ‰ (ê¸°ì¡´ ë¡œì§)
                bm25_start = time.time()
                bm25_results = await SearchDAO._perform_bm25_search(
                    session, query, bm25_topk, filters
                )
                bm25_time = time.time() - bm25_start

                # 3. Vector ê²€ìƒ‰ (ê¸°ì¡´ ë¡œì§)
                vector_start = time.time()
                vector_results = await SearchDAO._perform_vector_search(
                    session, query_embedding, vector_topk, filters
                )
                vector_time = time.time() - vector_start

                # 4. ê²°ê³¼ í•©ì„± (ê°„ë‹¨í•œ ìŠ¤ì½”ì–´ ì¡°í•©)
                combine_start = time.time()
                combined_results = OptimizedSearchDAO._combine_results_optimized(
                    bm25_results, vector_results, rerank_candidates
                )
                combine_time = time.time() - combine_start

                # ì„±ëŠ¥ ì •ë³´ ì¶”ê°€
                total_time = time.time() - start_time

                # ê²°ê³¼ì— ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¶”ê°€
                for result in combined_results[:topk]:
                    result['_performance'] = {
                        'total_time': total_time,
                        'embedding_time': embedding_time,
                        'bm25_time': bm25_time,
                        'vector_time': vector_time,
                        'combine_time': combine_time,
                        'cache_hit': embedding_time < 0.1
                    }

                return combined_results[:topk]

            except Exception as e:
                print(f"Optimized hybrid search error: {e}")
                # í´ë°±: ê¸°ì¡´ ê²€ìƒ‰ ì‚¬ìš©
                return await SearchDAO.hybrid_search(query, filters, topk, bm25_topk, vector_topk, rerank_candidates)

    @staticmethod
    def _combine_results_optimized(
        bm25_results: List[Dict],
        vector_results: List[Dict],
        topk: int
    ) -> List[Dict[str, Any]]:
        """ìµœì í™”ëœ ê²°ê³¼ ì¡°í•© (ê°„ë‹¨í•œ ê°€ì¤‘í‰ê· )"""

        # ê²°ê³¼ë¥¼ chunk_idë¡œ ì¸ë±ì‹±
        all_results = {}

        # BM25 ê²°ê³¼ ì¶”ê°€
        for result in bm25_results:
            chunk_id = result.get('chunk_id')
            if chunk_id:
                all_results[chunk_id] = result.copy()
                all_results[chunk_id]['bm25_score'] = result.get('score', 0)
                all_results[chunk_id]['vector_score'] = 0

        # Vector ê²°ê³¼ ì¶”ê°€/ì—…ë°ì´íŠ¸
        for result in vector_results:
            chunk_id = result.get('chunk_id')
            if chunk_id:
                if chunk_id in all_results:
                    all_results[chunk_id]['vector_score'] = result.get('score', 0)
                else:
                    all_results[chunk_id] = result.copy()
                    all_results[chunk_id]['bm25_score'] = 0
                    all_results[chunk_id]['vector_score'] = result.get('score', 0)

        # í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ê³„ì‚° (ê°€ì¤‘í‰ê· )
        for chunk_id, result in all_results.items():
            bm25_score = result.get('bm25_score', 0)
            vector_score = result.get('vector_score', 0)

            # ì •ê·œí™” ë° ê°€ì¤‘ í‰ê· 
            hybrid_score = 0.3 * bm25_score + 0.7 * vector_score
            result['score'] = hybrid_score

        # ì ìˆ˜ìˆœ ì •ë ¬
        sorted_results = sorted(
            all_results.values(),
            key=lambda x: x.get('score', 0),
            reverse=True
        )

        return sorted_results[:topk]

async def benchmark_optimized_search():
    """ìµœì í™”ëœ ê²€ìƒ‰ ë²¤ì¹˜ë§ˆí¬"""
    print("=== ìµœì í™”ëœ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ë²¤ì¹˜ë§ˆí¬ ===")

    test_queries = [
        "machine learning algorithms",
        "vector similarity search",
        "BM25 ranking function",
        "hybrid search systems",
        "neural network deep learning",
        "natural language processing",
        "information retrieval",
        "embedding models AI",
        "cross encoder reranking",
        "document classification"
    ]

    # ì²« ë²ˆì§¸ ë¼ìš´ë“œ: ìºì‹œ MISS
    print("\n1. ì²« ë²ˆì§¸ ë¼ìš´ë“œ (ìºì‹œ MISS)")
    first_round_times = []

    for i, query in enumerate(test_queries):
        start_time = time.time()
        results = await OptimizedSearchDAO.optimized_hybrid_search(
            query=query,
            topk=3
        )
        latency = time.time() - start_time
        first_round_times.append(latency)

        print(f"  Query {i+1}: {len(results)} results, {latency*1000:.1f}ms")

        # ì„±ëŠ¥ ì •ë³´ ì¶œë ¥
        if results and '_performance' in results[0]:
            perf = results[0]['_performance']
            print(f"    Embedding: {perf['embedding_time']*1000:.1f}ms, "
                  f"BM25: {perf['bm25_time']*1000:.1f}ms, "
                  f"Vector: {perf['vector_time']*1000:.1f}ms")

    # ë‘ ë²ˆì§¸ ë¼ìš´ë“œ: ìºì‹œ HIT
    print("\n2. ë‘ ë²ˆì§¸ ë¼ìš´ë“œ (ìºì‹œ HIT)")
    second_round_times = []

    for i, query in enumerate(test_queries):
        start_time = time.time()
        results = await OptimizedSearchDAO.optimized_hybrid_search(
            query=query,
            topk=3
        )
        latency = time.time() - start_time
        second_round_times.append(latency)

        print(f"  Query {i+1}: {len(results)} results, {latency*1000:.1f}ms")

        # ì„±ëŠ¥ ì •ë³´ ì¶œë ¥
        if results and '_performance' in results[0]:
            perf = results[0]['_performance']
            print(f"    Embedding: {perf['embedding_time']*1000:.1f}ms, "
                  f"Cache Hit: {perf['cache_hit']}")

    # ì„±ëŠ¥ ë¹„êµ
    print(f"\n=== ì„±ëŠ¥ ë¹„êµ ===")
    avg_first = sum(first_round_times) / len(first_round_times) * 1000
    avg_second = sum(second_round_times) / len(second_round_times) * 1000
    improvement = (avg_first - avg_second) / avg_first * 100

    print(f"ì²« ë²ˆì§¸ ë¼ìš´ë“œ í‰ê· : {avg_first:.1f}ms")
    print(f"ë‘ ë²ˆì§¸ ë¼ìš´ë“œ í‰ê· : {avg_second:.1f}ms")
    print(f"ì„±ëŠ¥ í–¥ìƒ: {improvement:.1f}%")

    # ìºì‹œ í†µê³„
    print(f"\n=== ìºì‹œ í†µê³„ ===")
    print(f"ìºì‹œëœ ì„ë² ë”© ìˆ˜: {len(EMBEDDING_CACHE)}")

    return {
        'first_round_avg': avg_first,
        'second_round_avg': avg_second,
        'improvement_percent': improvement,
        'cache_size': len(EMBEDDING_CACHE)
    }

async def benchmark_concurrent_optimized():
    """ìµœì í™”ëœ ë™ì‹œ ê²€ìƒ‰ ë²¤ì¹˜ë§ˆí¬"""
    print("\n=== ìµœì í™”ëœ ë™ì‹œ ê²€ìƒ‰ ë²¤ì¹˜ë§ˆí¬ ===")

    concurrent_queries = [
        "AI technology trends",
        "machine learning models",
        "data processing algorithms",
        "software optimization",
        "neural network architecture",
        "search engine design",
        "vector databases",
        "text embedding methods"
    ]

    print(f"ì‹¤í–‰: {len(concurrent_queries)}ê°œ ë™ì‹œ ì¿¼ë¦¬")

    start_time = time.time()

    # ë™ì‹œ ì‹¤í–‰
    tasks = []
    for query in concurrent_queries:
        task = OptimizedSearchDAO.optimized_hybrid_search(
            query=query,
            topk=3
        )
        tasks.append(task)

    results = await asyncio.gather(*tasks, return_exceptions=True)
    total_time = time.time() - start_time

    successful_results = [r for r in results if not isinstance(r, Exception)]
    failed_results = [r for r in results if isinstance(r, Exception)]

    print(f"ì´ ì‹¤í–‰ì‹œê°„: {total_time*1000:.1f}ms")
    print(f"ì„±ê³µ: {len(successful_results)}/{len(concurrent_queries)}")
    print(f"ì‹¤íŒ¨: {len(failed_results)}")

    if successful_results:
        avg_results = sum(len(r) for r in successful_results) / len(successful_results)
        print(f"í‰ê·  ê²°ê³¼ ìˆ˜: {avg_results:.1f}")

        # ë™ì‹œ ì²˜ë¦¬ íš¨ìœ¨ì„±
        sequential_estimate = len(concurrent_queries) * 100  # 100ms per query ì¶”ì • (ìºì‹œ ì ìš©)
        efficiency = max(0, (sequential_estimate - total_time*1000) / sequential_estimate * 100)
        print(f"ë™ì‹œ ì²˜ë¦¬ íš¨ìœ¨ì„±: {efficiency:.1f}%")

        # ìºì‹œ íˆíŠ¸ìœ¨ ê³„ì‚°
        cache_hits = 0
        total_searches = 0
        for result_list in successful_results:
            for result in result_list:
                if '_performance' in result and result['_performance'].get('cache_hit'):
                    cache_hits += 1
                total_searches += 1

        hit_rate = (cache_hits / total_searches * 100) if total_searches > 0 else 0
        print(f"ìºì‹œ íˆíŠ¸ìœ¨: {hit_rate:.1f}%")

    return {
        'total_time': total_time * 1000,
        'success_rate': len(successful_results) / len(concurrent_queries) * 100,
        'efficiency': efficiency if successful_results else 0
    }

async def cleanup():
    """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
    global HTTP_CLIENT
    if HTTP_CLIENT:
        await HTTP_CLIENT.aclose()
        HTTP_CLIENT = None

async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("Dynamic Taxonomy RAG v1.8.1 - ìµœì í™”ëœ ê²€ìƒ‰ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬")
    print("="*70)

    try:
        # ìµœì í™”ëœ ê²€ìƒ‰ ë²¤ì¹˜ë§ˆí¬
        search_results = await benchmark_optimized_search()

        # ìµœì í™”ëœ ë™ì‹œ ê²€ìƒ‰ ë²¤ì¹˜ë§ˆí¬
        concurrent_results = await benchmark_concurrent_optimized()

        # ìµœì¢… ìš”ì•½
        print(f"\n{'='*70}")
        print("ìµœì í™” ì„±ëŠ¥ ìš”ì•½")
        print(f"{'='*70}")

        print(f"ë‹¨ì¼ ê²€ìƒ‰ ì„±ëŠ¥:")
        print(f"  ìºì‹œ ë¯¸ì ìš©ì‹œ: {search_results['first_round_avg']:.1f}ms")
        print(f"  ìºì‹œ ì ìš©ì‹œ: {search_results['second_round_avg']:.1f}ms")
        print(f"  ì„±ëŠ¥ í–¥ìƒ: {search_results['improvement_percent']:.1f}%")

        print(f"\në™ì‹œ ê²€ìƒ‰ ì„±ëŠ¥:")
        print(f"  ì´ ì‹¤í–‰ì‹œê°„: {concurrent_results['total_time']:.1f}ms")
        print(f"  ì„±ê³µë¥ : {concurrent_results['success_rate']:.1f}%")
        print(f"  ì²˜ë¦¬ íš¨ìœ¨ì„±: {concurrent_results['efficiency']:.1f}%")

        # ëª©í‘œ ë‹¬ì„±ë„ í‰ê°€
        print(f"\nëª©í‘œ ë‹¬ì„±ë„:")
        if search_results['second_round_avg'] < 100:
            print("âœ… ìºì‹œ ì ìš©ì‹œ ì§€ì—°ì‹œê°„ ëª©í‘œ ë‹¬ì„±")
        else:
            print("âŒ ì§€ì—°ì‹œê°„ ëª©í‘œ ë¯¸ë‹¬ì„±")

        if concurrent_results['success_rate'] >= 95:
            print("âœ… ì•ˆì •ì„± ëª©í‘œ ë‹¬ì„±")
        else:
            print("âŒ ì•ˆì •ì„± ëª©í‘œ ë¯¸ë‹¬ì„±")

        # ì¶”ê°€ ìµœì í™” ê¶Œì¥ì‚¬í•­
        print(f"\nì¶”ê°€ ìµœì í™” ê¶Œì¥:")
        if search_results['improvement_percent'] > 50:
            print("âœ… ìºì‹œ ìµœì í™” íš¨ê³¼ ìš°ìˆ˜")
        else:
            print("ğŸŸ¡ ì¶”ê°€ ìºì‹œ ìµœì í™” í•„ìš”")

        print("ğŸ”§ ë‹¤ìŒ ë‹¨ê³„: BM25 FTS ì¸ë±ìŠ¤ êµ¬í˜„")
        print("ğŸ”§ ë‹¤ìŒ ë‹¨ê³„: ë¹„ë™ê¸° íŒŒì´í”„ë¼ì¸ êµ¬í˜„")
        print("ğŸ”§ ë‹¤ìŒ ë‹¨ê³„: ë¡œì»¬ ì„ë² ë”© ëª¨ë¸ ê³ ë ¤")

    finally:
        await cleanup()

if __name__ == "__main__":
    asyncio.run(main())
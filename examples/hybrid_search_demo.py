"""
í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹œìŠ¤í…œ ì‚¬ìš© ì˜ˆì œ
ì‹¤ì œ ì‚¬ìš©ë²•ê³¼ ìµœì í™” íŒì„ í¬í•¨í•œ ë°ëª¨
"""

import asyncio
import time
import logging
from typing import List, Dict, Any
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession, async_sessionmaker

# í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹œìŠ¤í…œ import
from apps.search import (
    HybridSearchEngine,
    SearchConfig,
    SearchEngineFactory,
    FusionMethod,
    NormalizationMethod,
    get_cache,
    get_performance_monitor,
    QueryOptimizer
)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class HybridSearchDemo:
    """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ë°ëª¨ í´ë˜ìŠ¤"""

    def __init__(self, database_url: str):
        """
        Args:
            database_url: ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° URL
        """
        self.database_url = database_url
        self.engine = None
        self.session_maker = None
        self.search_engines = {}

    async def initialize(self):
        """ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        logger.info("Initializing hybrid search demo...")

        # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
        self.engine = create_async_engine(
            self.database_url,
            echo=False,
            pool_size=5,
            max_overflow=10
        )
        self.session_maker = async_sessionmaker(
            self.engine,
            class_=AsyncSession,
            expire_on_commit=False
        )

        # ë‹¤ì–‘í•œ ê²€ìƒ‰ ì—”ì§„ ìƒì„±
        self.search_engines = {
            'fast': SearchEngineFactory.create_fast_engine(),
            'accurate': SearchEngineFactory.create_accurate_engine(),
            'balanced': SearchEngineFactory.create_balanced_engine(),
            'custom': self._create_custom_engine()
        }

        # ê²€ìƒ‰ ì—”ì§„ ì›œì—…
        async with self.session_maker() as session:
            for name, engine in self.search_engines.items():
                logger.info(f"Warming up {name} engine...")
                await engine.warm_up(session)

        logger.info("Demo initialization completed")

    def _create_custom_engine(self) -> HybridSearchEngine:
        """ì»¤ìŠ¤í…€ ê²€ìƒ‰ ì—”ì§„ ìƒì„±"""
        config = SearchConfig(
            # BM25 ì„¤ì •
            bm25_k1=1.8,  # ë†’ì€ ê°’ìœ¼ë¡œ term frequency ê°•ì¡°
            bm25_b=0.6,   # ë¬¸ì„œ ê¸¸ì´ ì •ê·œí™” ì¡°ì •
            bm25_topk=25,

            # Vector ì„¤ì •
            vector_topk=25,
            vector_similarity_threshold=0.1,  # ë‚®ì€ ìœ ì‚¬ë„ ê²°ê³¼ í•„í„°ë§

            # Fusion ì„¤ì •
            fusion_method=FusionMethod.RRF,  # Reciprocal Rank Fusion
            normalization_method=NormalizationMethod.MIN_MAX,
            bm25_weight=0.6,  # BM25 ì•½ê°„ ìš°ì„ 
            vector_weight=0.4,

            # Reranking ì„¤ì •
            enable_reranking=True,
            rerank_candidates=40,
            final_topk=8,
            use_multi_stage=True,

            # ì„±ëŠ¥ ì„¤ì •
            use_adaptive_fusion=True,
            use_optimized_engines=True,
            max_query_time=1.5
        )
        return HybridSearchEngine(config)

    async def run_basic_search_demo(self):
        """ê¸°ë³¸ ê²€ìƒ‰ ë°ëª¨"""
        logger.info("=== Basic Search Demo ===")

        test_queries = [
            "machine learning algorithms",
            "neural network architecture",
            "ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™”",
            "API ë³´ì•ˆ ê°€ì´ë“œ",
            "í´ë¼ìš°ë“œ ì»´í“¨íŒ… ë¹„ìš©"
        ]

        async with self.session_maker() as session:
            for query in test_queries:
                logger.info(f"Searching for: '{query}'")

                # ê· í˜•ì¡íŒ ì—”ì§„ìœ¼ë¡œ ê²€ìƒ‰
                engine = self.search_engines['balanced']
                response = await engine.search(session, query)

                logger.info(f"Found {len(response.results)} results in {response.total_time:.3f}s")
                logger.info(f"BM25: {response.bm25_time:.3f}s, Vector: {response.vector_time:.3f}s, "
                           f"Fusion: {response.fusion_time:.3f}s, Rerank: {response.rerank_time:.3f}s")

                # ìƒìœ„ 3ê°œ ê²°ê³¼ ì¶œë ¥
                for i, result in enumerate(response.results[:3]):
                    logger.info(f"  {i+1}. Score: {result.score:.3f} | "
                               f"Sources: {result.sources} | "
                               f"Text: {result.text[:100]}...")

                print()

    async def run_comparison_demo(self):
        """ê²€ìƒ‰ ì—”ì§„ ë¹„êµ ë°ëª¨"""
        logger.info("=== Search Engine Comparison Demo ===")

        query = "deep learning neural networks"
        filters = {"canonical_in": [["AI", "ML"]]}

        async with self.session_maker() as session:
            results = {}

            for name, engine in self.search_engines.items():
                start_time = time.time()
                response = await engine.search(session, query, filters)
                total_time = time.time() - start_time

                results[name] = {
                    'response': response,
                    'total_time': total_time,
                    'result_count': len(response.results)
                }

                logger.info(f"{name.upper()} Engine:")
                logger.info(f"  Results: {len(response.results)}")
                logger.info(f"  Time: {response.total_time:.3f}s")
                logger.info(f"  Top score: {response.results[0].score:.3f}" if response.results else "  No results")

            # ì„±ëŠ¥ ë¹„êµ ìš”ì•½
            logger.info("\n=== Performance Summary ===")
            for name, result in results.items():
                logger.info(f"{name}: {result['result_count']} results in {result['total_time']:.3f}s")

    async def run_adaptive_fusion_demo(self):
        """ì ì‘í˜• ìœµí•© ë°ëª¨"""
        logger.info("=== Adaptive Fusion Demo ===")

        test_scenarios = [
            {
                'query': 'api',  # ì§§ì€ ì¿¼ë¦¬
                'description': 'Short query (BM25 should be prioritized)'
            },
            {
                'query': 'How to implement neural network backpropagation algorithm?',  # ê¸´ ì¿¼ë¦¬
                'description': 'Long query (Vector should be prioritized)'
            },
            {
                'query': '"exact phrase matching"',  # êµ¬ë¬¸ ê²€ìƒ‰
                'description': 'Phrase query (BM25 should be prioritized)'
            },
            {
                'query': 'machine learning deep learning AI',  # ê¸°ìˆ  ìš©ì–´
                'description': 'Technical terms (Vector should be prioritized)'
            }
        ]

        # ì ì‘í˜• ìœµí•© ì—”ì§„ ì‚¬ìš©
        engine = self.search_engines['accurate']  # adaptive fusion enabled

        async with self.session_maker() as session:
            for scenario in test_scenarios:
                logger.info(f"\nScenario: {scenario['description']}")
                logger.info(f"Query: '{scenario['query']}'")

                response = await engine.search(session, scenario['query'])

                if response.results:
                    # ê²°ê³¼ ë¶„ì„
                    bm25_sources = sum(1 for r in response.results if 'bm25' in r.sources)
                    vector_sources = sum(1 for r in response.results if 'vector' in r.sources)

                    logger.info(f"Results: {len(response.results)}")
                    logger.info(f"BM25 sources: {bm25_sources}, Vector sources: {vector_sources}")
                    logger.info(f"Top result score: {response.results[0].score:.3f}")

    async def run_performance_optimization_demo(self):
        """ì„±ëŠ¥ ìµœì í™” ë°ëª¨"""
        logger.info("=== Performance Optimization Demo ===")

        # ìºì‹œ ì‹œìŠ¤í…œ ë°ëª¨
        cache = await get_cache()
        performance_monitor = get_performance_monitor()

        test_query = "performance optimization techniques"

        async with self.session_maker() as session:
            # ì²« ë²ˆì§¸ ê²€ìƒ‰ (ìºì‹œ ë¯¸ìŠ¤)
            logger.info("First search (cache miss):")
            start_time = time.time()
            response1 = await self.search_engines['balanced'].search(session, test_query)
            first_time = time.time() - start_time
            logger.info(f"Time: {first_time:.3f}s, Results: {len(response1.results)}")

            # ë‘ ë²ˆì§¸ ê²€ìƒ‰ (ìºì‹œ íˆíŠ¸ ê°€ëŠ¥)
            logger.info("Second search (potential cache hit):")
            start_time = time.time()
            response2 = await self.search_engines['balanced'].search(session, test_query)
            second_time = time.time() - start_time
            logger.info(f"Time: {second_time:.3f}s, Results: {len(response2.results)}")

            # ìºì‹œ í†µê³„
            cache_stats = cache.get_cache_stats()
            logger.info(f"Cache stats: {cache_stats}")

            # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
            performance_report = performance_monitor.get_performance_report()
            logger.info(f"Performance report: {performance_report}")

    async def run_query_optimization_demo(self):
        """ì¿¼ë¦¬ ìµœì í™” ë°ëª¨"""
        logger.info("=== Query Optimization Demo ===")

        test_queries = [
            "machine    learning   algorithms!!!",  # ê³µë°±ê³¼ íŠ¹ìˆ˜ë¬¸ì ì •ë¦¬
            "AI AI machine learning AI",  # ì¤‘ë³µ ë‹¨ì–´ ì œê±°
            "How to optimize database performance?",  # ì¼ë°˜ì ì¸ ì¿¼ë¦¬
        ]

        for original_query in test_queries:
            optimized_query = QueryOptimizer.optimize_query(original_query)
            complexity = QueryOptimizer.analyze_query_complexity(original_query)

            logger.info(f"Original: '{original_query}'")
            logger.info(f"Optimized: '{optimized_query}'")
            logger.info(f"Complexity: {complexity['estimated_difficulty']} "
                       f"(score: {complexity['complexity_score']:.2f})")
            print()

    async def run_batch_processing_demo(self):
        """ë°°ì¹˜ ì²˜ë¦¬ ë°ëª¨"""
        logger.info("=== Batch Processing Demo ===")

        from apps.search.optimization import BatchProcessor

        batch_processor = BatchProcessor(max_workers=4)
        queries = [
            "database optimization",
            "web security",
            "cloud computing",
            "machine learning",
            "API design patterns"
        ]

        async with self.session_maker() as session:
            start_time = time.time()

            # ë°°ì¹˜ ê²€ìƒ‰ ì²˜ë¦¬
            results = await batch_processor.process_search_batch(
                queries,
                self.search_engines['fast'],
                session
            )

            batch_time = time.time() - start_time

            logger.info(f"Processed {len(queries)} queries in {batch_time:.3f}s")
            logger.info(f"Average time per query: {batch_time/len(queries):.3f}s")

            for i, (query, result) in enumerate(zip(queries, results)):
                if 'error' not in result:
                    logger.info(f"  {i+1}. '{query}': {len(result.results)} results")
                else:
                    logger.info(f"  {i+1}. '{query}': ERROR - {result['error']}")

    async def run_comprehensive_demo(self):
        """ì¢…í•© ë°ëª¨ ì‹¤í–‰"""
        logger.info("ğŸš€ Starting Hybrid Search System Comprehensive Demo")

        try:
            await self.initialize()

            # ê° ë°ëª¨ ì‹¤í–‰
            await self.run_basic_search_demo()
            await self.run_comparison_demo()
            await self.run_adaptive_fusion_demo()
            await self.run_performance_optimization_demo()
            await self.run_query_optimization_demo()
            await self.run_batch_processing_demo()

            logger.info("âœ… All demos completed successfully!")

        except Exception as e:
            logger.error(f"âŒ Demo failed: {e}")
            raise

        finally:
            if self.engine:
                await self.engine.dispose()


async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # ë°ì´í„°ë² ì´ìŠ¤ URL (í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •)
    DATABASE_URL = "sqlite+aiosqlite:///dt_rag_test.db"
    # DATABASE_URL = "postgresql+asyncpg://user:password@localhost/db_name"

    demo = HybridSearchDemo(DATABASE_URL)
    await demo.run_comprehensive_demo()


if __name__ == "__main__":
    asyncio.run(main())
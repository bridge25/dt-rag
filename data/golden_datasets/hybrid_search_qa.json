{
  "dataset_name": "hybrid_search_qa",
  "description": "Hybrid search and information retrieval questions for evaluation",
  "version": "1.0",
  "created_at": "2025-09-19T14:00:00Z",
  "data_points": [
    {
      "id": "hybrid_001",
      "query": "What is the difference between BM25 and vector search?",
      "expected_answer": "BM25 is a lexical search algorithm that matches exact keywords and phrases using statistical term weighting based on term frequency and inverse document frequency. Vector search uses semantic embeddings to find conceptually similar content even when exact keywords don't match. BM25 excels at precise keyword matching while vector search captures semantic relationships and synonyms. Hybrid systems combine both approaches for comprehensive retrieval.",
      "expected_contexts": [
        "BM25 is based on probabilistic information retrieval theory and term statistics",
        "Vector search uses neural embeddings to capture semantic meaning in high-dimensional space",
        "BM25 works well for exact term matches and technical queries with specific vocabulary",
        "Vector search handles synonyms, paraphrases, and conceptual similarity better than keyword search"
      ],
      "taxonomy_path": ["Information Retrieval", "Algorithms", "Comparison"],
      "difficulty_level": "medium",
      "domain": "Search",
      "metadata": {
        "topic": "search_algorithms",
        "expected_keywords": ["BM25", "vector search", "lexical", "semantic", "embeddings", "keywords"]
      }
    },
    {
      "id": "hybrid_002",
      "query": "How does Reciprocal Rank Fusion (RRF) work in hybrid search?",
      "expected_answer": "Reciprocal Rank Fusion (RRF) combines rankings from multiple search systems by calculating scores based on the reciprocal of each document's rank position across different systems. The formula is typically score = sum(1/(rank + k)) where k is a small constant (usually 60). Documents that appear highly ranked in multiple systems receive higher combined scores. RRF is simple, effective, and doesn't require parameter tuning or training data.",
      "expected_contexts": [
        "RRF aggregates multiple ranking lists without needing relevance scores",
        "The constant k prevents infinite scores for rank 0 and controls the fusion behavior",
        "RRF is rank-based and doesn't depend on the absolute scores from different systems",
        "It's particularly effective when combining systems with different scoring scales"
      ],
      "taxonomy_path": ["Information Retrieval", "Fusion", "RRF"],
      "difficulty_level": "hard",
      "domain": "Search",
      "metadata": {
        "topic": "result_fusion",
        "expected_keywords": ["RRF", "reciprocal rank", "fusion", "ranking", "aggregation"]
      }
    },
    {
      "id": "hybrid_003",
      "query": "What are the advantages of cross-encoder re-ranking?",
      "expected_answer": "Cross-encoder re-ranking provides several advantages: (1) More accurate relevance scoring by jointly encoding query and document, (2) Better handling of subtle semantic relationships and context, (3) Ability to capture interaction features between query and document that bi-encoders miss, (4) Improved ranking quality especially for top results, and (5) State-of-the-art performance on many retrieval benchmarks. The trade-off is higher computational cost compared to bi-encoders.",
      "expected_contexts": [
        "Cross-encoders process query and document together, enabling rich interaction modeling",
        "Bi-encoders encode query and document separately, limiting interaction modeling but enabling efficient search",
        "Re-ranking applies expensive models only to top-k candidates from initial retrieval",
        "Cross-encoders typically achieve higher accuracy but with significantly higher latency"
      ],
      "taxonomy_path": ["Information Retrieval", "Re-ranking", "Cross-Encoder"],
      "difficulty_level": "hard",
      "domain": "Search",
      "metadata": {
        "topic": "advanced_ranking",
        "expected_keywords": ["cross-encoder", "re-ranking", "interaction modeling", "bi-encoder", "accuracy"]
      }
    },
    {
      "id": "hybrid_004",
      "query": "How do you optimize the alpha parameter in hybrid search?",
      "expected_answer": "The alpha parameter in hybrid search controls the balance between lexical (BM25) and semantic (vector) search components. Optimization approaches include: (1) Grid search over alpha values using evaluation metrics like NDCG or MAP, (2) Query-dependent alpha selection based on query characteristics, (3) Learning-based approaches that predict optimal alpha for each query, and (4) A/B testing in production to find the best global alpha. Typically, alpha values between 0.3-0.8 work well for most domains.",
      "expected_contexts": [
        "Alpha = 0 means pure vector search, alpha = 1 means pure BM25 search",
        "Different query types may benefit from different alpha values",
        "Technical queries often benefit from higher alpha (more BM25), conceptual queries from lower alpha",
        "The optimal alpha depends on the domain, query distribution, and quality of embeddings"
      ],
      "taxonomy_path": ["Information Retrieval", "Hybrid Search", "Parameter Optimization"],
      "difficulty_level": "medium",
      "domain": "Search",
      "metadata": {
        "topic": "parameter_tuning",
        "expected_keywords": ["alpha parameter", "optimization", "balance", "BM25", "vector search", "grid search"]
      }
    },
    {
      "id": "hybrid_005",
      "query": "What is the role of query expansion in hybrid search systems?",
      "expected_answer": "Query expansion in hybrid search enhances retrieval by adding related terms to the original query. Techniques include: (1) Synonym expansion using thesauri or word embeddings, (2) Pseudo-relevance feedback from initial search results, (3) Context-aware expansion using user history or domain knowledge, and (4) Neural query expansion using language models. This improves recall by capturing alternative expressions and related concepts that users might not have included in their original query.",
      "expected_contexts": [
        "Query expansion addresses the vocabulary mismatch problem between queries and documents",
        "Automatic expansion can improve recall but may hurt precision if irrelevant terms are added",
        "Pseudo-relevance feedback assumes top initial results are relevant and extracts expansion terms",
        "Modern neural approaches can generate contextually appropriate expansion terms"
      ],
      "taxonomy_path": ["Information Retrieval", "Query Processing", "Query Expansion"],
      "difficulty_level": "medium",
      "domain": "Search",
      "metadata": {
        "topic": "query_enhancement",
        "expected_keywords": ["query expansion", "synonyms", "pseudo-relevance", "recall", "vocabulary mismatch"]
      }
    },
    {
      "id": "hybrid_006",
      "query": "How do you handle cold start problems in personalized search?",
      "expected_answer": "Cold start problems in personalized search occur when there's insufficient user data for personalization. Solutions include: (1) Content-based recommendations using document features, (2) Collaborative filtering with similar users, (3) Hybrid approaches combining multiple signals, (4) Gradual personalization that starts with general results and adapts over time, (5) Demographic-based defaults, and (6) Active learning to quickly gather user preferences. The key is graceful degradation to general search when personalization data is unavailable.",
      "expected_contexts": [
        "Cold start affects new users, new items, and returning users with sparse interaction data",
        "Content-based methods use item features to make recommendations without user history",
        "Collaborative filtering leverages similarity between users to make predictions",
        "Active learning strategies can quickly elicit user preferences through targeted questions"
      ],
      "taxonomy_path": ["Information Retrieval", "Personalization", "Cold Start"],
      "difficulty_level": "hard",
      "domain": "Search",
      "metadata": {
        "topic": "personalization_challenges",
        "expected_keywords": ["cold start", "personalization", "collaborative filtering", "content-based", "active learning"]
      }
    }
  ]
}
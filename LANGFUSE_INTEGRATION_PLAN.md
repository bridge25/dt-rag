# Langfuse í†µí•© ì„¤ê³„ ë¬¸ì„œ (Phase 2)

## 1. ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ (IG ì„ê³„ì  ê²€ì¦)

### âœ… í™•ì¸ëœ ì •ë³´
- **íŒ¨í‚¤ì§€ ë²„ì „**: `langfuse==3.6.1` (ìµœì‹ , 2025ë…„ v3 GA ë²„ì „)
- **ì„¤ì¹˜ ë°©ë²•**: `pip install langfuse`
- **SDK ì•„í‚¤í…ì²˜**: OpenTelemetry ê¸°ë°˜ (v3)
- **í™˜ê²½ë³€ìˆ˜**: `LANGFUSE_PUBLIC_KEY`, `LANGFUSE_SECRET_KEY`, `LANGFUSE_HOST`
- **í†µí•© ë°©ë²•**: Decorator íŒ¨í„´ (`@observe()`) ë˜ëŠ” Low-level SDK

### âœ… í†µí•© ë²”ìœ„ ê²°ì •
```python
# í†µí•© ëŒ€ìƒ (ìš°ì„ ìˆœìœ„ìˆœ)
1. apps/evaluation/ragas_engine.py - Gemini 2.5 Flash API í˜¸ì¶œ (í‰ê°€ ì—”ì§„)
2. apps/api/embedding_service.py - OpenAI text-embedding-3-large (ì„ë² ë”© ìƒì„±)
3. apps/search/hybrid_search_engine.py - search() (ê²€ìƒ‰ ì—”ì§„)
4. apps/api/routers/search_router.py - search_documents() (API ì—”ë“œí¬ì¸íŠ¸)
```

### âœ… í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ LLM í™•ì¸
- **í‰ê°€(RAGAS)**: Gemini 2.5 Flash (`apps/evaluation/ragas_engine.py:51`)
  - API Key: `GEMINI_API_KEY` (í™˜ê²½ë³€ìˆ˜ ì œê³µë¨)
  - ëª¨ë¸: `gemini-pro` (ì‹¤ì œ ì‚¬ìš©: gemini-2.5-flash ê¶Œì¥)
- **ì„ë² ë”©**: OpenAI text-embedding-3-large (`apps/api/embedding_service.py:61`)
  - API Key: `OPENAI_API_KEY`
  - ì°¨ì›: 1536
- **ìƒì„±(ë¯¸ì‚¬ìš©)**: í˜„ì¬ LLM ê¸°ë°˜ í…ìŠ¤íŠ¸ ìƒì„± ì—†ìŒ (í‰ê°€ë§Œ ì‚¬ìš©)

---

## 2. êµ¬í˜„ ê³„íš

### Step 1: ì˜ì¡´ì„± ì¶”ê°€ (1ì‹œê°„)
```bash
# requirements.txtì— ì¶”ê°€
langfuse>=3.6.0
```

### Step 2: Langfuse í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (2ì‹œê°„)
**íŒŒì¼**: `apps/api/monitoring/langfuse_client.py` (ì‹ ê·œ)

```python
"""
Langfuse LLM ë¹„ìš© ì¶”ì  í´ë¼ì´ì–¸íŠ¸
OpenTelemetry ê¸°ë°˜ v3 SDK ì‚¬ìš©
"""
import os
from typing import Optional
from langfuse import Langfuse
from langfuse.decorators import observe

# í™˜ê²½ë³€ìˆ˜ ê¸°ë°˜ ì´ˆê¸°í™”
langfuse_client = Langfuse(
    public_key=os.getenv("LANGFUSE_PUBLIC_KEY"),
    secret_key=os.getenv("LANGFUSE_SECRET_KEY"),
    host=os.getenv("LANGFUSE_HOST", "https://cloud.langfuse.com"),
    enabled=os.getenv("LANGFUSE_ENABLED", "true").lower() == "true"
)

# IG ì„ê³„ì : Sentryì™€ ì¶©ëŒ í™•ì¸ í•„ìš”
# - SentryëŠ” ì—ëŸ¬ ì¶”ì , LangfuseëŠ” ë¹„ìš© ì¶”ì  (ëª©ì  ë¶„ë¦¬)
# - ë‘ ëª¨ë‹ˆí„°ë§ ë„êµ¬ ë³‘í–‰ ê°€ëŠ¥ (ê²€ì¦ í•„ìš”)

def get_langfuse_client() -> Langfuse:
    """ì‹±ê¸€í†¤ Langfuse í´ë¼ì´ì–¸íŠ¸ ë°˜í™˜"""
    return langfuse_client
```

### Step 3: Embedding ì„œë¹„ìŠ¤ í†µí•© (3ì‹œê°„)
**íŒŒì¼**: `apps/api/embedding_service.py:117-145`

```python
from .monitoring.langfuse_client import observe

class EmbeddingService:
    @observe(name="generate_embedding")
    async def generate_embedding(self, text: str, use_cache: bool = True) -> List[float]:
        """
        Langfuse ìë™ ì¶”ì :
        - ì…ë ¥ í† í° ìˆ˜ (tiktoken)
        - API í˜¸ì¶œ ì‹œê°„
        - ëª¨ë¸ëª… (text-embedding-3-large)
        - ë¹„ìš© ê³„ì‚° (ìë™)
        """
        # ê¸°ì¡´ ë¡œì§ ìœ ì§€
        ...
```

**ì¶”ì  ë©”íŠ¸ë¦­**:
- ì…ë ¥ í…ìŠ¤íŠ¸ ê¸¸ì´ â†’ í† í° ìˆ˜ ë³€í™˜ (tiktoken)
- OpenAI API í˜¸ì¶œ ë¹„ìš© ($0.00013/1k tokens for text-embedding-3-large)
- ìºì‹œ íˆíŠ¸ìœ¨
- ë ˆì´í„´ì‹œ

### Step 4: ê²€ìƒ‰ ì—”ì§„ í†µí•© (2ì‹œê°„)
**íŒŒì¼**: `apps/search/hybrid_search_engine.py:508-643`

```python
from ..api.monitoring.langfuse_client import observe

class HybridSearchEngine:
    @observe(name="hybrid_search")
    async def search(self, query: str, top_k: int = 5, ...) -> Tuple[...]:
        """
        Langfuse ìë™ ì¶”ì :
        - ê²€ìƒ‰ ì¿¼ë¦¬
        - BM25/Vector í›„ë³´ ìˆ˜
        - ìµœì¢… ê²°ê³¼ ìˆ˜
        - ë ˆì´í„´ì‹œ
        """
        # ê¸°ì¡´ ë¡œì§ ìœ ì§€
        ...
```

### Step 5: ë¹„ìš© ëŒ€ì‹œë³´ë“œ API (4ì‹œê°„)
**íŒŒì¼**: `apps/api/routers/monitoring_router.py` (ìˆ˜ì •)

```python
@router.get("/api/v1/monitoring/llm-costs")
async def get_llm_costs(
    api_key: APIKeyInfo = Depends(verify_api_key)
):
    """
    Langfuse ë¹„ìš© ëŒ€ì‹œë³´ë“œ (Gemini 2.5 Flash + OpenAI Embedding)

    Returns:
        - ì¼ë³„ ë¹„ìš© (â‚©)
        - ì¿¼ë¦¬ë‹¹ í‰ê·  ë¹„ìš© (â‚©)
        - ëª¨ë¸ë³„ ë¹„ìš© ë¶„í¬
        - ëª©í‘œ ë¹„ìš©(â‚©10/ì¿¼ë¦¬) ì¤€ìˆ˜ ì—¬ë¶€
    """
    from .monitoring.langfuse_client import get_langfuse_client

    client = get_langfuse_client()

    # Langfuse APIë¡œ ë¹„ìš© ì¡°íšŒ
    traces = client.get_traces(limit=1000)  # ìµœê·¼ 1000ê°œ

    # ëª¨ë¸ë³„ ë¹„ìš© ë¶„ë¦¬
    gemini_cost = 0.0
    embedding_cost = 0.0

    for trace in traces:
        if "gemini" in trace.model.lower():
            gemini_cost += trace.calculated_total_cost
        elif "embedding" in trace.model.lower():
            embedding_cost += trace.calculated_total_cost

    total_cost_usd = gemini_cost + embedding_cost

    # í™˜ìœ¨: $1 = â‚©1,300 (í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬)
    exchange_rate = float(os.getenv("USD_TO_KRW", "1300"))

    # Gemini 2.5 Flash ìš”ê¸ˆ
    # - Input: $0.075 / 1M tokens ($0.000075 / 1K tokens)
    # - Output: $0.30 / 1M tokens ($0.0003 / 1K tokens)
    # - 128K context window

    # OpenAI text-embedding-3-large ìš”ê¸ˆ
    # - $0.13 / 1M tokens ($0.00013 / 1K tokens)

    return {
        "total_cost_usd": total_cost_usd,
        "total_cost_krw": total_cost_usd * exchange_rate,
        "cost_breakdown_krw": {
            "gemini_2.5_flash": gemini_cost * exchange_rate,
            "openai_embedding": embedding_cost * exchange_rate
        },
        "avg_cost_per_query_krw": (total_cost_usd / len(traces) * exchange_rate) if traces else 0,
        "target_cost_krw": 10,
        "is_within_budget": (total_cost_usd / len(traces) * exchange_rate) <= 10 if traces else True,
        "pricing_info": {
            "gemini_2.5_flash": {
                "input_per_1k_tokens_usd": 0.000075,
                "output_per_1k_tokens_usd": 0.0003,
                "context_window": "128K"
            },
            "openai_embedding_3_large": {
                "per_1k_tokens_usd": 0.00013,
                "dimensions": 1536
            }
        }
    }
```

---

## 3. ë¦¬ìŠ¤í¬ ë¶„ì„

### âš ï¸ ë¯¸í™•ì¸ ë¦¬ìŠ¤í¬ (Abstain ì‚¬ìœ )

**1. Sentry ì¶©ëŒ ê°€ëŠ¥ì„±**
- **í˜„ìƒ**: ë‘ ëª¨ë‹ˆí„°ë§ SDKê°€ OpenTelemetry ì»¨í…ìŠ¤íŠ¸ ê³µìœ ?
- **ê²€ì¦ ë°©ë²•**: ë¡œì»¬ í…ŒìŠ¤íŠ¸ë¡œ í™•ì¸
- **ì™„í™” ì „ëµ**: Langfuse ë¹„í™œì„±í™” í”Œë˜ê·¸ (`LANGFUSE_ENABLED=false`)

**2. ì„±ëŠ¥ ì˜¤ë²„í—¤ë“œ**
- **í˜„ìƒ**: `@observe()` ë°ì½”ë ˆì´í„°ê°€ ë ˆì´í„´ì‹œ ì¶”ê°€?
- **ê²€ì¦ ë°©ë²•**: ë²¤ì¹˜ë§ˆí¬ (ëª©í‘œ: < 10ms)
- **ì™„í™” ì „ëµ**: ìƒ˜í”Œë§ (ì „ì²´ ìš”ì²­ì˜ 10%ë§Œ ì¶”ì )

**3. ë¹„ìš© ê³„ì‚° ê³µì‹ ì •í™•ì„±**
- **í˜„ìƒ**: Langfuseê°€ ìë™ ê³„ì‚°í•˜ëŠ” ë¹„ìš©ì´ ì‹¤ì œ ì²­êµ¬ì„œì™€ ì¼ì¹˜?
- **ê²€ì¦ ëŒ€ìƒ**:
  - Gemini 2.5 Flash: Google Cloud Console ì²­êµ¬ì„œ
  - OpenAI Embedding: OpenAI ì‚¬ìš©ëŸ‰ í˜ì´ì§€
- **ê²€ì¦ ë°©ë²•**: 1ì£¼ì¼ ì‹¤ì œ ìš´ì˜ í›„ ë¹„êµ (Â±5% ì´ë‚´ ì˜¤ì°¨ í—ˆìš©)
- **ì™„í™” ì „ëµ**: ìˆ˜ë™ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±

**4. Gemini ëª¨ë¸ ëª…ì‹œ ì—…ë°ì´íŠ¸ í•„ìš”**
- **í˜„ìƒ**: `ragas_engine.py:51`ì—ì„œ `gemini-pro` ì‚¬ìš© ì¤‘
- **ê¶Œì¥**: `gemini-2.5-flash-latest` ë˜ëŠ” `gemini-2.0-flash-exp`ë¡œ ì—…ë°ì´íŠ¸
- **ë¹„ìš© ì˜í–¥**: Gemini 2.5 Flashê°€ ë” ì €ë ´ (Input: $0.075/1M vs Pro: $0.50/1M)

---

## 4. ì‹¤í–‰ ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸

### âœ… IG ì„ê³„ì  í†µê³¼ ì¡°ê±´
- [x] langfuse íŒ¨í‚¤ì§€ ì¡´ì¬ í™•ì¸ (v3.6.1)
- [x] í†µí•© ì§€ì  ëª…í™•í™” (embedding_service, hybrid_search_engine)
- [x] í™˜ê²½ë³€ìˆ˜ ê´€ë¦¬ ë°©ë²• ì •ì˜ (.env.local)
- [ ] Sentry ì¶©ëŒ ì—¬ë¶€ ë¡œì»¬ í…ŒìŠ¤íŠ¸
- [ ] ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ (ëª©í‘œ: < 10ms ì˜¤ë²„í—¤ë“œ)
- [ ] ë¹„ìš© ê³„ì‚° ê³µì‹ ê²€ì¦

### ğŸ”´ Abstain í•´ì œ ì¡°ê±´
1. **ë¡œì»¬ í…ŒìŠ¤íŠ¸ ì™„ë£Œ**: Sentry + Langfuse ë™ì‹œ ë™ì‘ í™•ì¸
2. **ë²¤ì¹˜ë§ˆí¬ í†µê³¼**: `@observe()` ì˜¤ë²„í—¤ë“œ < 10ms
3. **ë¹„ìš© ê³µì‹ ê²€ì¦**: OpenAI ì²­êµ¬ì„œì™€ Â±5% ì´ë‚´ ì˜¤ì°¨

---

## 5. ë°”ì´ë¸Œì½”ë”© ì›ì¹™ ì ìš©

### í˜¼ì„  ì œê±°
```yaml
# âŒ ëª¨í˜¸í•œ ëª©í‘œ
ëª©í‘œ: "LLM ë¹„ìš© ì¶”ì  í†µí•©"

# âœ… ìˆ˜ì¹˜í™”ëœ ëª©í‘œ
ëª©í‘œ: "ë¹„ìš©/ì¿¼ë¦¬ â‰¤ â‚©10 ê²€ì¦ ê°€ëŠ¥í•˜ë„ë¡ Langfuse í†µí•©"
ì¸¡ì •: "langfuse.get_traces().calculated_total_cost Ã— 1300 (í™˜ìœ¨)"
ì„ê³„ê°’: "avg_cost_krw > 10 ì‹œ ì•Œë¦¼"
```

### ì‘ì€ ì»¤ë°‹ (â‰¤5 íŒŒì¼)
```bash
# Commit 1: Langfuse í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
git add apps/api/monitoring/langfuse_client.py requirements.txt
git commit -m "feat: Langfuse í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (v3.6.1)"

# Commit 2: Embedding ì„œë¹„ìŠ¤ í†µí•©
git add apps/api/embedding_service.py
git commit -m "feat: Embedding ì„œë¹„ìŠ¤ Langfuse í†µí•© (@observe)"

# Commit 3: ê²€ìƒ‰ ì—”ì§„ í†µí•©
git add apps/search/hybrid_search_engine.py
git commit -m "feat: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ Langfuse í†µí•©"

# Commit 4: ë¹„ìš© ëŒ€ì‹œë³´ë“œ API
git add apps/api/routers/monitoring_router.py
git commit -m "feat: LLM ë¹„ìš© ëŒ€ì‹œë³´ë“œ API (/monitoring/llm-costs)"
```

---

## 6. ë‹¤ìŒ ë‹¨ê³„ (ìŠ¹ì¸ í›„ ì‹¤í–‰)

1. **ë¡œì»¬ í…ŒìŠ¤íŠ¸** (1ì¼):
   - Sentry + Langfuse ì¶©ëŒ í™•ì¸
   - ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

2. **êµ¬í˜„** (2-3ì¼):
   - Step 1-5 ìˆœì°¨ ì‹¤í–‰
   - ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±

3. **ê²€ì¦** (1ì£¼):
   - ì‹¤ì œ ìš´ì˜ ë°ì´í„°ë¡œ ë¹„ìš© ê³„ì‚° ê²€ì¦
   - OpenAI ì²­êµ¬ì„œ ë¹„êµ

---

**ìµœì¢… ê¶Œì¥**: ë¡œì»¬ í…ŒìŠ¤íŠ¸ ì™„ë£Œ í›„ Phase 2 ì°©ìˆ˜ ìŠ¹ì¸ ìš”ì²­

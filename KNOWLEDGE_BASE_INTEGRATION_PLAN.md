# Knowledge Base Integration Enhancement Plan
> **ÏûëÏÑ±Ïùº**: 2025-09-19
> **ÌîÑÎ°úÏ†ùÌä∏**: Dynamic Taxonomy RAG v1.8.1
> **Î™©Ï†Å**: Subagent Knowledge Base ÌôúÏö©ÎèÑ 0% ‚Üí 100% Í∞úÏÑ†

---

## üéØ Executive Summary

### Î¨∏Ï†ú ÏÉÅÌô©
- **ÌòÑÏû¨ ÏÉÅÌÉú**: SubagentÎì§Ïù¥ knowledge-base/*.json ÌååÏùºÏùÑ Ï†ÑÌòÄ ÏùΩÏßÄ Î™ªÌï®
- **ÏõêÏù∏**: Task ÎèÑÍµ¨Í∞Ä .claude/agents/*.mdÎäî ÏùΩÏßÄÎßå, JSON ÌååÏùºÏùÄ ÏûêÎèô Î°úÎìúÌïòÏßÄ ÏïäÏùå
- **ÏòÅÌñ•**: RAGAS v2.0 Îì± ÏµúÏã† Ï†ïÎ≥¥ ÎØ∏ÌôúÏö©, ÏùºÎ∞òÏ†ÅÏù∏ ÎãµÎ≥ÄÎßå ÏÉùÏÑ±

### Ìï¥Í≤∞ Î∞©Ïïà
3Îã®Í≥Ñ ÌïòÏù¥Î∏åÎ¶¨Îìú Ï†ëÍ∑ºÎ≤ïÏúºÎ°ú Îã®Í≥ÑÏ†Å Í∞úÏÑ†:
1. **Phase 1**: MD ÌååÏùºÏóê Essential Knowledge ÏûÑÎ≤†Îìú (Ï¶âÏãú Ìö®Í≥º)
2. **Phase 2**: Bash Í∏∞Î∞ò Hook ÏûêÎèôÌôî (Í∞ÑÎã®Ìïú ÏûêÎèôÌôî)
3. **Phase 3**: Python Í∏∞Î∞ò ÏßÄÎä•Ìòï Hook (Ï†ïÍµêÌïú Ï†úÏñ¥)

---

## üìã Phase 1: Essential Knowledge MD ÌååÏùº Í∞úÏÑ†

### 1.1 Î™©Ìëú
- Í∞Å ÏóêÏù¥Ï†ÑÌä∏ MD ÌååÏùºÏóê ÌïµÏã¨ Knowledge 10-15Í∞ú Ìï≠Î™© ÏßÅÏ†ë Ìè¨Ìï®
- Ï¶âÏãú Ìö®Í≥º, Ï∂îÍ∞Ä ÏÑ§Ï†ï Î∂àÌïÑÏöî

### 1.2 ÏûëÏóÖ ÎÇ¥Ïó≠

#### Step 1: Knowledge JSON Î∂ÑÏÑù (20Î∂Ñ)
```python
# Î∂ÑÏÑù Ïä§ÌÅ¨Î¶ΩÌä∏ ÏòàÏãú
import json
from pathlib import Path

kb_dir = Path("knowledge-base")
for kb_file in kb_dir.glob("*_knowledge.json"):
    with open(kb_file) as f:
        data = json.load(f)
        items = data.get("search_results", [])

        # ÏÉÅÏúÑ 10Í∞ú ÏÑ†Î≥Ñ Í∏∞Ï§Ä
        # 1. relevance_score > 0.9
        # 2. 2025ÎÖÑ ÏµúÏã† Ï†ïÎ≥¥
        # 3. Íµ¨Ï≤¥Ï†Å Íµ¨ÌòÑ Í∞ÄÏù¥Îìú Ìè¨Ìï®

        essential = [
            item for item in items[:20]
            if item.get("relevance_score", 0) > 0.9
        ][:10]
```

#### Step 2: MD ÌååÏùº ÏóÖÎç∞Ïù¥Ìä∏ ÌÖúÌîåÎ¶ø
```markdown
## Essential Knowledge (Auto-loaded)

### üéØ Key Tools & Versions
- **RAGAS v2.0** (2025-04-28): Faithfulness ‚â• 0.85, Answer Relevancy, Context Precision
- **Arize Phoenix**: RAG triad metrics - context relevance, groundedness, answer relevance
- **DeepEval**: 14+ LLM evaluation metrics, self-explaining for debugging
- **LangSmith 2025**: Align Evals, Trace Mode, cross-framework support
- **TruLens**: Reference-free evaluation, groundedness scoring

### üìä Critical Configurations
- **Minimum Test Set**: 20 questions (personal), 100 questions (enterprise)
- **Golden Dataset Quality**: > 95% annotation accuracy required
- **Inter-annotator Agreement**: > 90% for reliability
- **Evaluation Frequency**: Every PR, nightly full evaluation
- **Performance Target**: Faithfulness ‚â• 0.85, Answer Relevancy ‚â• 0.8

### ‚ö†Ô∏è Best Practices
- Always use component-level evaluation (retrieval + generation separately)
- Implement A/B testing with statistical significance (p < 0.05)
- Use canary releases with automated rollback triggers
- Monitor evaluation metrics in production continuously
- Create domain-specific custom metrics beyond standard RAGAS

### üìå Full Knowledge Access
Complete knowledge base with detailed examples available at:
`knowledge-base/rag-evaluation-specialist_knowledge.json`
```

### 1.3 Í≤ÄÏ¶ù Ï≤¥ÌÅ¨Î¶¨Ïä§Ìä∏
- [ ] MD ÌååÏùº ÌÅ¨Í∏∞ < 200KB (Git Í¥ÄÎ¶¨ Ïö©Ïù¥)
- [ ] Essential Knowledge Í∞ÄÎèÖÏÑ± ÌôïÏù∏
- [ ] Ï§ëÎ≥µ Ï†ïÎ≥¥ Ï†úÍ±∞
- [ ] Î≤ÑÏ†Ñ Ï†ïÎ≥¥ Î™ÖÏãú
- [ ] Ïã§Ìñâ Í∞ÄÎä•Ìïú Íµ¨Ï≤¥Ï†Å Í∞ÄÏù¥Îìú Ìè¨Ìï®

---

## üìã Phase 2: Bash Hook Íµ¨ÌòÑ

### 2.1 Î™©Ìëú
- Task ÎèÑÍµ¨ Ìò∏Ï∂ú Ïãú ÏûêÎèô Knowledge Î°úÎìú
- Í∞ÑÎã®Ìïú Bash Ïä§ÌÅ¨Î¶ΩÌä∏Î°ú Íµ¨ÌòÑ

### 2.2 Íµ¨ÌòÑ ÏÉÅÏÑ∏

#### Hook Ïä§ÌÅ¨Î¶ΩÌä∏: `.claude/hooks/inject_knowledge.sh`
```bash
#!/bin/bash
# Knowledge Base Auto-injection Hook for Task tool
# Compatible with Windows Git Bash and WSL

set -e  # Exit on error

# Parse tool input
tool_name=$(echo "$CLAUDE_TOOL_INPUT" | jq -r '.tool_name // empty')
subagent_type=$(echo "$CLAUDE_TOOL_INPUT" | jq -r '.tool_input.subagent_type // empty')

# Debug logging
echo "[KB Hook] Tool: $tool_name, Subagent: $subagent_type" >&2

# Only process Task tool calls
if [ "$tool_name" != "Task" ] || [ -z "$subagent_type" ]; then
    echo '{"continue": true}'
    exit 0
fi

# Windows path handling
if [[ "$OSTYPE" == "msys" ]] || [[ "$OSTYPE" == "win32" ]]; then
    KB_BASE="C:/MYCLAUDE_PROJECT/sonheungmin/Unmanned/dt-rag/knowledge-base"
else
    KB_BASE="/mnt/c/MYCLAUDE_PROJECT/sonheungmin/Unmanned/dt-rag/knowledge-base"
fi

KB_FILE="${KB_BASE}/${subagent_type}_knowledge.json"

# Check file existence
if [ ! -f "$KB_FILE" ]; then
    echo "[KB Hook] Warning: Knowledge base not found for $subagent_type" >&2
    echo '{"continue": true}'
    exit 0
fi

# Extract and inject top 5 items
echo "[KB Hook] Loading knowledge for $subagent_type..." >&2

# Create minimal context injection
jq -c '{
    continue: true,
    suppressOutput: false,
    additionalContext: (
        "üîç Knowledge Base Loaded: " + (.subagent // "unknown") + "\n" +
        "üìö Top References:\n" +
        (.search_results[:5] | map("- " + .title + " (" + (.relevance_score | tostring) + ")") | join("\n"))
    )
}' "$KB_FILE"
```

### 2.3 ÏÑ§Ï†ï ÏóÖÎç∞Ïù¥Ìä∏
```json
{
  "permissions": {
    // existing permissions...
  },
  "hooks": {
    "PreToolUse": [
      {
        "matcher": "Task",
        "hooks": [
          {
            "type": "command",
            "command": "bash .claude/hooks/inject_knowledge.sh",
            "timeout": 5,
            "continueOnError": true
          }
        ]
      }
    ]
  }
}
```

### 2.4 Ìä∏Îü¨Î∏îÏäàÌåÖ
- **Î¨∏Ï†ú**: Windows Í≤ΩÎ°ú Ï≤òÎ¶¨
  - **Ìï¥Í≤∞**: OSTYPE Ï≤¥ÌÅ¨Î°ú ÏûêÎèô Í≤ΩÎ°ú Î≥ÄÌôò
- **Î¨∏Ï†ú**: jq Î™ÖÎ†πÏñ¥ ÏóÜÏùå
  - **Ìï¥Í≤∞**: Git Bash Í∏∞Î≥∏ Ìè¨Ìï®, WSLÏùÄ `apt install jq`
- **Î¨∏Ï†ú**: Í∂åÌïú Ïò§Î•ò
  - **Ìï¥Í≤∞**: `chmod +x inject_knowledge.sh`

---

## üìã Phase 3: Python Í∏∞Î∞ò ÏßÄÎä•Ìòï Hook (Deep Design)

### 3.1 ÏÑ§Í≥Ñ Î™©Ìëú
- **ÏßÄÎä•Ìòï ÌïÑÌÑ∞ÎßÅ**: Task ÎÇ¥Ïö© Î∂ÑÏÑùÌïòÏó¨ Í¥ÄÎ†® KnowledgeÎßå ÏÑ†Î≥Ñ
- **ÏÑ±Îä• ÏµúÏ†ÅÌôî**: Ï∫êÏã±ÏúºÎ°ú Î∞òÎ≥µ Î°úÎìú Î∞©ÏßÄ
- **ÏóêÎü¨ Î≥µÍµ¨**: Ïã§Ìå® ÏãúÏóêÎèÑ Task Ïã§Ìñâ Î≥¥Ïû•
- **Ïã§ÏãúÍ∞Ñ Í≤ÄÏ¶ù**: Mock Îç∞Ïù¥ÌÑ∞ Î∞©ÏßÄ, Ïã§Ï†ú Îç∞Ïù¥ÌÑ∞ Î≥¥Ïû•

### 3.2 ÏïÑÌÇ§ÌÖçÏ≤ò ÏÑ§Í≥Ñ

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         PreToolUse Hook Trigger         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ
             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     knowledge_injector.py Main          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 1. Parse CLAUDE_TOOL_INPUT              ‚îÇ
‚îÇ 2. Validate Task tool & subagent_type   ‚îÇ
‚îÇ 3. Load Knowledge with caching          ‚îÇ
‚îÇ 4. Intelligent filtering                ‚îÇ
‚îÇ 5. Format injection response            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ
             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ        Response to Claude Code          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ {                                       ‚îÇ
‚îÇ   "continue": true,                     ‚îÇ
‚îÇ   "additionalContext": "...",           ‚îÇ
‚îÇ   "injectedKnowledge": {...}            ‚îÇ
‚îÇ }                                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 3.3 ÏôÑÏ†ÑÌïú Python Hook Íµ¨ÌòÑ

#### `.claude/hooks/knowledge_injector.py`
```python
#!/usr/bin/env python3
"""
Advanced Knowledge Base Injection Hook for Claude Code
Ensures real data injection, not mock data
Version: 1.0.0
Author: DT-RAG Team
"""

import os
import sys
import json
import hashlib
import time
from pathlib import Path
from typing import Dict, List, Any, Optional
from datetime import datetime

# Constants
KB_BASE_PATH = Path("C:/MYCLAUDE_PROJECT/sonheungmin/Unmanned/dt-rag/knowledge-base")
LOG_PATH = Path(".claude/hooks/logs/kb_injection.log")
CACHE_PATH = Path(".claude/hooks/cache/kb_cache.json")
MAX_ITEMS_TO_INJECT = 10
CACHE_TTL_SECONDS = 300  # 5 minutes

class KnowledgeInjector:
    """Advanced knowledge base injection with caching and intelligent filtering"""

    def __init__(self):
        self.cache = self._load_cache()
        self.ensure_directories()

    def ensure_directories(self):
        """Create necessary directories"""
        LOG_PATH.parent.mkdir(parents=True, exist_ok=True)
        CACHE_PATH.parent.mkdir(parents=True, exist_ok=True)

    def _load_cache(self) -> Dict:
        """Load cache with TTL check"""
        if CACHE_PATH.exists():
            try:
                with open(CACHE_PATH, 'r', encoding='utf-8') as f:
                    cache = json.load(f)
                    # Clean expired entries
                    current_time = time.time()
                    cache = {
                        k: v for k, v in cache.items()
                        if current_time - v.get('timestamp', 0) < CACHE_TTL_SECONDS
                    }
                    return cache
            except Exception:
                return {}
        return {}

    def _save_cache(self):
        """Save cache to disk"""
        try:
            with open(CACHE_PATH, 'w', encoding='utf-8') as f:
                json.dump(self.cache, f)
        except Exception as e:
            self.log(f"Cache save error: {e}", level="ERROR")

    def log(self, message: str, level: str = "INFO"):
        """Structured logging"""
        timestamp = datetime.now().isoformat()
        log_entry = f"[{timestamp}] [{level}] {message}\n"

        try:
            with open(LOG_PATH, 'a', encoding='utf-8') as f:
                f.write(log_entry)
        except Exception:
            # Silent fail for logging
            pass

        # Also output to stderr for debugging
        if level in ["ERROR", "WARNING"]:
            print(f"[KB Hook] {level}: {message}", file=sys.stderr)

    def get_tool_input(self) -> Optional[Dict]:
        """Parse and validate tool input"""
        tool_input_str = os.environ.get('CLAUDE_TOOL_INPUT', '{}')

        try:
            tool_input = json.loads(tool_input_str)
            self.log(f"Tool input parsed: {tool_input.get('tool_name', 'unknown')}")
            return tool_input
        except json.JSONDecodeError as e:
            self.log(f"Failed to parse CLAUDE_TOOL_INPUT: {e}", "ERROR")
            return None

    def load_knowledge_base(self, subagent_type: str) -> Optional[Dict]:
        """Load knowledge base with caching"""
        cache_key = f"kb_{subagent_type}"

        # Check cache first
        if cache_key in self.cache:
            self.log(f"Cache hit for {subagent_type}")
            return self.cache[cache_key]['data']

        # Load from file
        kb_path = KB_BASE_PATH / f"{subagent_type}_knowledge.json"

        if not kb_path.exists():
            self.log(f"Knowledge base not found: {kb_path}", "WARNING")
            return None

        try:
            with open(kb_path, 'r', encoding='utf-8') as f:
                knowledge = json.load(f)

                # Validate structure
                if not isinstance(knowledge, dict):
                    self.log(f"Invalid KB structure for {subagent_type}", "ERROR")
                    return None

                # Cache it
                self.cache[cache_key] = {
                    'data': knowledge,
                    'timestamp': time.time()
                }
                self._save_cache()

                self.log(f"Loaded KB for {subagent_type}: {len(knowledge.get('search_results', []))} items")
                return knowledge

        except Exception as e:
            self.log(f"Failed to load KB for {subagent_type}: {e}", "ERROR")
            return None

    def calculate_relevance(self, item: Dict, task_keywords: List[str]) -> float:
        """Calculate item relevance to task"""
        score = item.get('relevance_score', 0.5)

        # Boost score for keyword matches
        title = item.get('title', '').lower()
        content = item.get('content', '').lower()

        for keyword in task_keywords:
            keyword_lower = keyword.lower()
            if keyword_lower in title:
                score += 0.2
            if keyword_lower in content:
                score += 0.1

        return min(score, 1.0)  # Cap at 1.0

    def filter_relevant_items(self, knowledge: Dict, task_prompt: str) -> List[Dict]:
        """Intelligent filtering based on task content"""
        items = knowledge.get('search_results', [])

        if not items:
            return []

        # Extract keywords from task prompt
        task_lower = task_prompt.lower()

        # Domain-specific keyword mappings
        keyword_maps = {
            'evaluation': ['ragas', 'metric', 'evaluation', 'assess', 'measure', 'quality'],
            'database': ['postgres', 'pgvector', 'hnsw', 'index', 'migration', 'alembic'],
            'search': ['bm25', 'vector', 'hybrid', 'rerank', 'cross-encoder', 'retrieval'],
            'orchestration': ['langgraph', 'workflow', 'state', 'pipeline', 'chain'],
            'ingestion': ['chunk', 'parse', 'extract', 'document', 'pdf', 'ocr'],
            'api': ['fastapi', 'openapi', 'rest', 'endpoint', 'cors', 'swagger'],
            'security': ['auth', 'security', 'vulnerability', 'audit', 'compliance'],
            'taxonomy': ['dag', 'hierarchy', 'classification', 'ontology', 'tree'],
        }

        # Determine relevant keywords
        active_keywords = []
        for domain, keywords in keyword_maps.items():
            if any(kw in task_lower for kw in keywords[:3]):  # Check first 3 keywords
                active_keywords.extend(keywords)

        # If no specific domain detected, use general keywords
        if not active_keywords:
            # Extract potential keywords from task (simple tokenization)
            words = task_lower.split()
            active_keywords = [w for w in words if len(w) > 4][:10]

        self.log(f"Active keywords: {active_keywords[:5]}")

        # Score and filter items
        scored_items = []
        for item in items:
            relevance = self.calculate_relevance(item, active_keywords)
            if relevance > 0.6:  # Threshold
                item_copy = item.copy()
                item_copy['computed_relevance'] = relevance
                scored_items.append(item_copy)

        # Sort by relevance and return top N
        scored_items.sort(key=lambda x: x['computed_relevance'], reverse=True)
        return scored_items[:MAX_ITEMS_TO_INJECT]

    def format_injection_response(self,
                                 subagent_type: str,
                                 relevant_items: List[Dict],
                                 task_prompt: str) -> Dict:
        """Format the final injection response"""

        # Create a concise summary for injection
        if relevant_items:
            # Build context string
            context_lines = [
                f"üìö Knowledge Base: {subagent_type}",
                f"üîç Filtered {len(relevant_items)} relevant items from knowledge base",
                "",
                "üéØ Top References:",
            ]

            for i, item in enumerate(relevant_items[:5], 1):
                title = item.get('title', 'Unknown')
                score = item.get('computed_relevance', item.get('relevance_score', 0))
                # Truncate long titles
                if len(title) > 80:
                    title = title[:77] + "..."
                context_lines.append(f"{i}. {title} (relevance: {score:.2f})")

            # Add key insights
            context_lines.append("")
            context_lines.append("üí° Key Insights:")

            # Extract unique key points
            seen_points = set()
            for item in relevant_items[:3]:
                content = item.get('content', '')
                # Extract first meaningful sentence
                sentences = content.split('.')
                for sentence in sentences:
                    sentence = sentence.strip()
                    if len(sentence) > 20 and len(sentence) < 150:
                        sentence_hash = hashlib.md5(sentence.encode()).hexdigest()[:8]
                        if sentence_hash not in seen_points:
                            context_lines.append(f"‚Ä¢ {sentence}.")
                            seen_points.add(sentence_hash)
                            break

            additional_context = "\n".join(context_lines)

            # Structured data for potential future use
            injected_knowledge = {
                "source": "knowledge_base",
                "agent": subagent_type,
                "timestamp": datetime.now().isoformat(),
                "items_count": len(relevant_items),
                "task_summary": task_prompt[:100] if len(task_prompt) > 100 else task_prompt,
                "top_items": [
                    {
                        "title": item.get('title', ''),
                        "relevance": round(item.get('computed_relevance', 0), 3),
                        "url": item.get('url', ''),
                        "category": item.get('category', 'general')
                    }
                    for item in relevant_items[:5]
                ]
            }

        else:
            additional_context = f"üìö Knowledge Base: {subagent_type}\n‚ö†Ô∏è No highly relevant items found for this specific task."
            injected_knowledge = {
                "source": "knowledge_base",
                "agent": subagent_type,
                "timestamp": datetime.now().isoformat(),
                "items_count": 0,
                "task_summary": task_prompt[:100] if len(task_prompt) > 100 else task_prompt
            }

        return {
            "continue": True,
            "suppressOutput": False,
            "additionalContext": additional_context,
            "metadata": injected_knowledge  # This won't be shown but logged
        }

    def create_error_response(self, error_msg: str) -> Dict:
        """Create a safe error response that allows Task to continue"""
        self.log(f"Creating error response: {error_msg}", "ERROR")
        return {
            "continue": True,
            "suppressOutput": True,
            "warning": f"Knowledge injection failed: {error_msg}"
        }

    def run(self) -> Dict:
        """Main execution flow"""
        try:
            # Parse tool input
            tool_input = self.get_tool_input()
            if not tool_input:
                return self.create_error_response("Invalid tool input")

            # Check if it's a Task tool
            tool_name = tool_input.get('tool_name')
            if tool_name != 'Task':
                self.log(f"Skipping non-Task tool: {tool_name}")
                return {"continue": True}

            # Extract subagent type
            task_input = tool_input.get('tool_input', {})
            subagent_type = task_input.get('subagent_type')

            if not subagent_type:
                self.log("No subagent_type in Task input")
                return {"continue": True}

            # Get task prompt for context
            task_prompt = task_input.get('prompt', '')

            self.log(f"Processing Task for {subagent_type}")

            # Load knowledge base
            knowledge = self.load_knowledge_base(subagent_type)
            if not knowledge:
                return self.create_error_response(f"Knowledge base not found for {subagent_type}")

            # Filter relevant items
            relevant_items = self.filter_relevant_items(knowledge, task_prompt)

            self.log(f"Filtered {len(relevant_items)} relevant items from {len(knowledge.get('search_results', []))} total")

            # Format and return response
            response = self.format_injection_response(subagent_type, relevant_items, task_prompt)

            # Log successful injection
            self.log(f"Successfully injected knowledge for {subagent_type}")

            return response

        except Exception as e:
            # Log full traceback for debugging
            import traceback
            tb = traceback.format_exc()
            self.log(f"Unexpected error: {e}\n{tb}", "ERROR")

            # Return safe response to not block Task execution
            return self.create_error_response(str(e))


def validate_mock_data_prevention():
    """Self-test to ensure no mock data is being used"""
    # This runs during import to validate the system
    test_kb_path = KB_BASE_PATH / "rag-evaluation-specialist_knowledge.json"

    if test_kb_path.exists():
        try:
            with open(test_kb_path, 'r') as f:
                data = json.load(f)
                # Check for real data indicators
                if 'search_results' in data and len(data['search_results']) > 0:
                    first_item = data['search_results'][0]
                    # Verify real data structure
                    required_fields = ['query', 'url', 'title', 'content', 'relevance_score']
                    if all(field in first_item for field in required_fields):
                        print("[KB Hook] Validation passed: Real data structure confirmed", file=sys.stderr)
                    else:
                        print("[KB Hook] Warning: Knowledge base structure incomplete", file=sys.stderr)
        except Exception as e:
            print(f"[KB Hook] Validation warning: {e}", file=sys.stderr)


# Run validation on import
validate_mock_data_prevention()

# Main execution
if __name__ == "__main__":
    injector = KnowledgeInjector()
    response = injector.run()

    # Output JSON response for Claude Code
    print(json.dumps(response, ensure_ascii=False, indent=2))
```

### 3.4 Í≥†Í∏â Ìä∏Îü¨Î∏îÏäàÌåÖ Í∞ÄÏù¥Îìú

#### Î¨∏Ï†ú 1: Mock Îç∞Ïù¥ÌÑ∞ Î∞òÌôò Î∞©ÏßÄ
**Ï¶ùÏÉÅ**: KnowledgeÍ∞Ä Ï£ºÏûÖÎêòÏßÄÎßå Ïã§Ï†ú ÎÇ¥Ïö©Ïù¥ ÏïÑÎãå placeholder
**ÏõêÏù∏**: JSON ÌååÏùº Íµ¨Ï°∞ Î∂àÏùºÏπò, ÌååÏã± Ïò§Î•ò
**Ìï¥Í≤∞**:
```python
# Validation Ìï®Ïàò Ï∂îÍ∞Ä
def validate_knowledge_structure(knowledge: Dict) -> bool:
    """Ensure knowledge has real data, not mock"""
    if not knowledge.get('search_results'):
        return False

    # Check first item has real content
    first_item = knowledge['search_results'][0]
    if len(first_item.get('content', '')) < 50:
        return False  # Too short, likely mock

    # Check for mock indicators
    mock_indicators = ['example', 'test', 'placeholder', 'lorem ipsum']
    content_lower = first_item.get('content', '').lower()
    if any(indicator in content_lower for indicator in mock_indicators):
        return False

    return True
```

#### Î¨∏Ï†ú 2: Ïù∏ÏΩîÎî© Ïò§Î•ò (ÌïúÍ∏Ä Ìè¨Ìï® Ïãú)
**Ï¶ùÏÉÅ**: UTF-8 decode error
**Ìï¥Í≤∞**:
```python
# Î™®Îì† ÌååÏùº Ïó¥Í∏∞Ïóê encoding Î™ÖÏãú
with open(kb_path, 'r', encoding='utf-8', errors='replace') as f:
    knowledge = json.load(f)
```

#### Î¨∏Ï†ú 3: ÎåÄÏö©Îüâ Knowledge Ï≤òÎ¶¨
**Ï¶ùÏÉÅ**: Hook timeout (5Ï¥à Ï¥àÍ≥º)
**Ìï¥Í≤∞**:
```python
# Ïä§Ìä∏Î¶¨Î∞ç Î∞©ÏãùÏúºÎ°ú Î≥ÄÍ≤Ω
import ijson  # pip install ijson

def load_knowledge_streaming(path: Path, limit: int = 100):
    """Load only first N items for performance"""
    items = []
    with open(path, 'rb') as f:
        parser = ijson.items(f, 'search_results.item')
        for item in parser:
            items.append(item)
            if len(items) >= limit:
                break
    return {'search_results': items}
```

#### Î¨∏Ï†ú 4: Hook Ïã§Ìñâ ÌôïÏù∏
**ÏßÑÎã® Ïä§ÌÅ¨Î¶ΩÌä∏**: `.claude/hooks/test_hook.py`
```python
#!/usr/bin/env python3
"""Test script to verify hook is working"""

import os
import json

# Simulate Task tool call
test_input = {
    "tool_name": "Task",
    "tool_input": {
        "subagent_type": "rag-evaluation-specialist",
        "prompt": "Evaluate the RAG system using RAGAS metrics"
    }
}

os.environ['CLAUDE_TOOL_INPUT'] = json.dumps(test_input)

# Run the hook
from knowledge_injector import KnowledgeInjector
injector = KnowledgeInjector()
result = injector.run()

print("Hook Response:")
print(json.dumps(result, indent=2))

# Verify real data
if 'additionalContext' in result:
    context = result['additionalContext']
    if 'RAGAS' in context or 'evaluation' in context:
        print("‚úÖ Real knowledge detected!")
    else:
        print("‚ö†Ô∏è Generic response - check knowledge base")
else:
    print("‚ùå No context injected")
```

### 3.5 ÏÑ±Îä• ÏµúÏ†ÅÌôî

#### Ï∫êÏã± Ï†ÑÎûµ
- **In-memory cache**: 5Î∂Ñ TTL
- **File-based cache**: ÏòÅÍµ¨ Ï†ÄÏû•
- **Cache warming**: ÏÑúÎ≤Ñ ÏãúÏûë Ïãú ÏûêÏ£º ÏÇ¨Ïö©ÌïòÎäî KB ÎØ∏Î¶¨ Î°úÎìú

#### Î≥ëÎ†¨ Ï≤òÎ¶¨ (ÎåÄÏö©Îüâ KB)
```python
import asyncio
import aiofiles

async def load_knowledge_async(subagent_type: str):
    """Async loading for better performance"""
    kb_path = KB_BASE_PATH / f"{subagent_type}_knowledge.json"

    async with aiofiles.open(kb_path, mode='r', encoding='utf-8') as f:
        content = await f.read()
        return json.loads(content)
```

### 3.6 Î™®ÎãàÌÑ∞ÎßÅ Î∞è Î©îÌä∏Î¶≠

#### Î°úÍ∑∏ Î∂ÑÏÑù Ïä§ÌÅ¨Î¶ΩÌä∏
```bash
#!/bin/bash
# analyze_kb_usage.sh

LOG_FILE=".claude/hooks/logs/kb_injection.log"

echo "=== Knowledge Base Hook Usage Analysis ==="
echo

echo "1. Total invocations:"
grep -c "Processing Task" "$LOG_FILE" 2>/dev/null || echo "0"

echo
echo "2. Success rate:"
SUCCESS=$(grep -c "Successfully injected" "$LOG_FILE" 2>/dev/null || echo "0")
TOTAL=$(grep -c "Processing Task" "$LOG_FILE" 2>/dev/null || echo "1")
echo "scale=2; $SUCCESS * 100 / $TOTAL" | bc

echo
echo "3. Most used agents:"
grep "Processing Task for" "$LOG_FILE" | awk '{print $NF}' | sort | uniq -c | sort -rn | head -5

echo
echo "4. Cache hit rate:"
CACHE_HITS=$(grep -c "Cache hit" "$LOG_FILE" 2>/dev/null || echo "0")
echo "scale=2; $CACHE_HITS * 100 / $TOTAL" | bc

echo
echo "5. Average items injected:"
grep "Filtered [0-9]* relevant items" "$LOG_FILE" | \
    sed 's/.*Filtered \([0-9]*\).*/\1/' | \
    awk '{sum+=$1; count++} END {if(count>0) print sum/count; else print 0}'
```

---

## üìä ÏÑ±Í≥µ ÏßÄÌëú Î∞è Í≤ÄÏ¶ù

### PhaseÎ≥Ñ ÏÑ±Í≥µ Í∏∞Ï§Ä

#### Phase 1 (MD Í∞úÏÑ†)
- [ ] Í∞Å MD ÌååÏùºÏóê Essential Knowledge ÏÑπÏÖò Ï∂îÍ∞Ä
- [ ] Git diff Í≤ÄÌÜ† ÏôÑÎ£å
- [ ] Task Ïã§Ìñâ Ïãú Essential Knowledge Ïñ∏Í∏â ÌôïÏù∏

#### Phase 2 (Bash Hook)
- [ ] Hook Ïä§ÌÅ¨Î¶ΩÌä∏ Ïã§Ìñâ Í∂åÌïú ÏÑ§Ï†ï
- [ ] settings.local.json ÏóÖÎç∞Ïù¥Ìä∏
- [ ] Task Ìò∏Ï∂ú Ïãú "Loading knowledge" Î°úÍ∑∏ ÌôïÏù∏

#### Phase 3 (Python Hook)
- [ ] Ïã§Ï†ú Îç∞Ïù¥ÌÑ∞ Ï£ºÏûÖ Í≤ÄÏ¶ù (no mock)
- [ ] 5Ï¥à ÎÇ¥ Ïã§Ìñâ ÏôÑÎ£å
- [ ] Ï∫êÏã± ÎèôÏûë ÌôïÏù∏
- [ ] ÏóêÎü¨ ÏãúÏóêÎèÑ Task Í≥ÑÏÜç Ïã§Ìñâ

### ÏµúÏ¢Ö Í≤ÄÏ¶ù Ï≤¥ÌÅ¨Î¶¨Ïä§Ìä∏
```bash
# 1. Knowledge ÌôúÏö©Î•† Ï∏°Ï†ï
grep -r "RAGAS v2.0\|Arize Phoenix\|DeepEval" generated_reports/*.md

# 2. Hook Î°úÍ∑∏ Î∂ÑÏÑù
tail -n 100 .claude/hooks/logs/kb_injection.log

# 3. Ïã§Ï†ú Task ÌÖåÏä§Ìä∏
echo "Test: rag-evaluation-specialistÎ°ú RAGAS v2.0 Í∏∞Ï§Ä ÌèâÍ∞Ä ÏàòÌñâ"
# ÏùëÎãµÏóê RAGAS v2.0 specific metrics Ìè¨Ìï® Ïó¨Î∂Ä ÌôïÏù∏

# 4. ÏÑ±Îä• Ï∏°Ï†ï
time python3 .claude/hooks/test_hook.py
```

---

## ‚è±Ô∏è ÏùºÏ†ï Î∞è Î¶¨ÏÜåÏä§

### ÌÉÄÏûÑÎùºÏù∏
- **Phase 1**: 1ÏãúÍ∞Ñ (Ï¶âÏãú ÏãúÏûë Í∞ÄÎä•)
- **Phase 2**: 30Î∂Ñ (Phase 1 ÏôÑÎ£å ÌõÑ)
- **Phase 3**: 2ÏãúÍ∞Ñ (Ï†ïÍµêÌïú ÏÑ§Í≥Ñ Ìè¨Ìï®)
- **Í≤ÄÏ¶ù Î∞è Ï°∞Ï†ï**: 30Î∂Ñ

### ÌïÑÏöî Î¶¨ÏÜåÏä§
- Python 3.8+
- jq (command-line JSON processor)
- Git Bash ÎòêÎäî WSL
- Ïì∞Í∏∞ Í∂åÌïú (hooks ÎîîÎ†âÌÜ†Î¶¨)

---

## üéØ Í∏∞ÎåÄ Ìö®Í≥º

### Ï†ïÎüâÏ†Å Í∞úÏÑ†
- **Knowledge ÌôúÏö©Î•†**: 0% ‚Üí 100%
- **Íµ¨Ï≤¥Ï†Å Ï†ïÎ≥¥ Ïñ∏Í∏â**: 10% ‚Üí 80%
- **ÏµúÏã† ÎèÑÍµ¨ Î≤ÑÏ†Ñ Ïù∏Ïãù**: 0% ‚Üí 100%
- **ÏûëÏóÖ Ï†ïÌôïÎèÑ**: 65% ‚Üí 90%

### Ï†ïÏÑ±Ï†Å Í∞úÏÑ†
- RAGAS v2.0 Í∞ôÏùÄ ÏµúÏã† ÎèÑÍµ¨ Ï†ïÌôïÌûà Ïñ∏Í∏â
- Íµ¨Ï≤¥Ï†Å ÏÑ§Ï†ïÍ∞í Ï†úÏãú (ef_construction=64 Îì±)
- ÏóÖÍ≥Ñ ÌëúÏ§Ä Ï§ÄÏàò (20 questions minimum Îì±)
- Ïã§Ìñâ Í∞ÄÎä•Ìïú Íµ¨Ï≤¥Ï†Å Í∞ÄÏù¥Îìú Ï†úÍ≥µ

---

## üìù Í≤∞Î°†

Ïù¥ 3Îã®Í≥Ñ Ï†ëÍ∑ºÎ≤ïÏùÑ ÌÜµÌï¥:
1. **Ï¶âÏãú Í∞úÏÑ†** (Phase 1)ÏúºÎ°ú Îπ†Î•∏ Ìö®Í≥º
2. **ÏûêÎèôÌôî** (Phase 2)Î°ú ÏùºÍ¥ÄÏÑ± ÌôïÎ≥¥
3. **ÏßÄÎä•Ìôî** (Phase 3)Î°ú ÏµúÏ†Å ÏÑ±Îä• Îã¨ÏÑ±

ÌäπÌûà Phase 3Ïùò Python HookÏùÄ mock Îç∞Ïù¥ÌÑ∞ Î∞©ÏßÄ, Ïã§ÏãúÍ∞Ñ Í≤ÄÏ¶ù, ÏßÄÎä•Ìòï ÌïÑÌÑ∞ÎßÅÏùÑ ÌÜµÌï¥
Ïã§Ï†ú KnowledgeÍ∞Ä ÌôïÏã§ÌïòÍ≤å Ï£ºÏûÖÎêòÎèÑÎ°ù ÏÑ§Í≥ÑÎêòÏóàÏäµÎãàÎã§.
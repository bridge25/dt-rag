# Knowledge Base Integration Enhancement Plan
> **ì‘ì„±ì¼**: 2025-09-19
> **í”„ë¡œì íŠ¸**: Dynamic Taxonomy RAG v1.8.1
> **ëª©ì **: Subagent Knowledge Base í™œìš©ë„ 0% â†’ 100% ê°œì„ 

---

## ğŸ¯ Executive Summary

### ë¬¸ì œ ìƒí™©
- **í˜„ì¬ ìƒíƒœ**: Subagentë“¤ì´ knowledge-base/*.json íŒŒì¼ì„ ì „í˜€ ì½ì§€ ëª»í•¨
- **ì›ì¸**: Task ë„êµ¬ê°€ .claude/agents/*.mdëŠ” ì½ì§€ë§Œ, JSON íŒŒì¼ì€ ìë™ ë¡œë“œí•˜ì§€ ì•ŠìŒ
- **ì˜í–¥**: RAGAS v2.0 ë“± ìµœì‹  ì •ë³´ ë¯¸í™œìš©, ì¼ë°˜ì ì¸ ë‹µë³€ë§Œ ìƒì„±

### í•´ê²° ë°©ì•ˆ
3ë‹¨ê³„ í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼ë²•ìœ¼ë¡œ ë‹¨ê³„ì  ê°œì„ :
1. **Phase 1**: MD íŒŒì¼ì— Essential Knowledge ì„ë² ë“œ (ì¦‰ì‹œ íš¨ê³¼)
2. **Phase 2**: Bash ê¸°ë°˜ Hook ìë™í™” (ê°„ë‹¨í•œ ìë™í™”)
3. **Phase 3**: Python ê¸°ë°˜ ì§€ëŠ¥í˜• Hook (ì •êµí•œ ì œì–´)

---

## ğŸ“‹ Phase 1: Essential Knowledge MD íŒŒì¼ ê°œì„ 

### 1.1 ëª©í‘œ
- ê° ì—ì´ì „íŠ¸ MD íŒŒì¼ì— í•µì‹¬ Knowledge 10-15ê°œ í•­ëª© ì§ì ‘ í¬í•¨
- ì¦‰ì‹œ íš¨ê³¼, ì¶”ê°€ ì„¤ì • ë¶ˆí•„ìš”

### 1.2 ì‘ì—… ë‚´ì—­

#### Step 1: Knowledge JSON ë¶„ì„ (20ë¶„)
```python
# ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸ ì˜ˆì‹œ
import json
from pathlib import Path

kb_dir = Path("knowledge-base")
for kb_file in kb_dir.glob("*_knowledge.json"):
    with open(kb_file) as f:
        data = json.load(f)
        items = data.get("search_results", [])

        # ìƒìœ„ 10ê°œ ì„ ë³„ ê¸°ì¤€
        # 1. relevance_score > 0.9
        # 2. 2025ë…„ ìµœì‹  ì •ë³´
        # 3. êµ¬ì²´ì  êµ¬í˜„ ê°€ì´ë“œ í¬í•¨

        essential = [
            item for item in items[:20]
            if item.get("relevance_score", 0) > 0.9
        ][:10]
```

#### Step 2: MD íŒŒì¼ ì—…ë°ì´íŠ¸ í…œí”Œë¦¿
```markdown
## Essential Knowledge (Auto-loaded)

### ğŸ¯ Key Tools & Versions
- **RAGAS v2.0** (2025-04-28): Faithfulness â‰¥ 0.85, Answer Relevancy, Context Precision
- **Arize Phoenix**: RAG triad metrics - context relevance, groundedness, answer relevance
- **DeepEval**: 14+ LLM evaluation metrics, self-explaining for debugging
- **LangSmith 2025**: Align Evals, Trace Mode, cross-framework support
- **TruLens**: Reference-free evaluation, groundedness scoring

### ğŸ“Š Critical Configurations
- **Minimum Test Set**: 20 questions (personal), 100 questions (enterprise)
- **Golden Dataset Quality**: > 95% annotation accuracy required
- **Inter-annotator Agreement**: > 90% for reliability
- **Evaluation Frequency**: Every PR, nightly full evaluation
- **Performance Target**: Faithfulness â‰¥ 0.85, Answer Relevancy â‰¥ 0.8

### âš ï¸ Best Practices
- Always use component-level evaluation (retrieval + generation separately)
- Implement A/B testing with statistical significance (p < 0.05)
- Use canary releases with automated rollback triggers
- Monitor evaluation metrics in production continuously
- Create domain-specific custom metrics beyond standard RAGAS

### ğŸ“Œ Full Knowledge Access
Complete knowledge base with detailed examples available at:
`knowledge-base/rag-evaluation-specialist_knowledge.json`
```

### 1.3 ê²€ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸
- [ ] MD íŒŒì¼ í¬ê¸° < 200KB (Git ê´€ë¦¬ ìš©ì´)
- [ ] Essential Knowledge ê°€ë…ì„± í™•ì¸
- [ ] ì¤‘ë³µ ì •ë³´ ì œê±°
- [ ] ë²„ì „ ì •ë³´ ëª…ì‹œ
- [ ] ì‹¤í–‰ ê°€ëŠ¥í•œ êµ¬ì²´ì  ê°€ì´ë“œ í¬í•¨

---

## ğŸ“‹ Phase 2: Bash Hook êµ¬í˜„

### 2.1 ëª©í‘œ
- Task ë„êµ¬ í˜¸ì¶œ ì‹œ ìë™ Knowledge ë¡œë“œ
- ê°„ë‹¨í•œ Bash ìŠ¤í¬ë¦½íŠ¸ë¡œ êµ¬í˜„

### 2.2 êµ¬í˜„ ìƒì„¸

#### Hook ìŠ¤í¬ë¦½íŠ¸: `.claude/hooks/inject_knowledge.sh`
```bash
#!/bin/bash
# Knowledge Base Auto-injection Hook for Task tool
# Compatible with Windows Git Bash and WSL

set -e  # Exit on error

# Parse tool input
tool_name=$(echo "$CLAUDE_TOOL_INPUT" | jq -r '.tool_name // empty')
subagent_type=$(echo "$CLAUDE_TOOL_INPUT" | jq -r '.tool_input.subagent_type // empty')

# Debug logging
echo "[KB Hook] Tool: $tool_name, Subagent: $subagent_type" >&2

# Only process Task tool calls
if [ "$tool_name" != "Task" ] || [ -z "$subagent_type" ]; then
    echo '{"continue": true}'
    exit 0
fi

# Windows path handling
if [[ "$OSTYPE" == "msys" ]] || [[ "$OSTYPE" == "win32" ]]; then
    KB_BASE="C:/MYCLAUDE_PROJECT/sonheungmin/Unmanned/dt-rag/knowledge-base"
else
    KB_BASE="/mnt/c/MYCLAUDE_PROJECT/sonheungmin/Unmanned/dt-rag/knowledge-base"
fi

KB_FILE="${KB_BASE}/${subagent_type}_knowledge.json"

# Check file existence
if [ ! -f "$KB_FILE" ]; then
    echo "[KB Hook] Warning: Knowledge base not found for $subagent_type" >&2
    echo '{"continue": true}'
    exit 0
fi

# Extract and inject top 5 items
echo "[KB Hook] Loading knowledge for $subagent_type..." >&2

# Create minimal context injection
jq -c '{
    continue: true,
    suppressOutput: false,
    additionalContext: (
        "ğŸ” Knowledge Base Loaded: " + (.subagent // "unknown") + "\n" +
        "ğŸ“š Top References:\n" +
        (.search_results[:5] | map("- " + .title + " (" + (.relevance_score | tostring) + ")") | join("\n"))
    )
}' "$KB_FILE"
```

### 2.3 ì„¤ì • ì—…ë°ì´íŠ¸
```json
{
  "permissions": {
    // existing permissions...
  },
  "hooks": {
    "PreToolUse": [
      {
        "matcher": "Task",
        "hooks": [
          {
            "type": "command",
            "command": "bash .claude/hooks/inject_knowledge.sh",
            "timeout": 5,
            "continueOnError": true
          }
        ]
      }
    ]
  }
}
```

### 2.4 íŠ¸ëŸ¬ë¸”ìŠˆíŒ…
- **ë¬¸ì œ**: Windows ê²½ë¡œ ì²˜ë¦¬
  - **í•´ê²°**: OSTYPE ì²´í¬ë¡œ ìë™ ê²½ë¡œ ë³€í™˜
- **ë¬¸ì œ**: jq ëª…ë ¹ì–´ ì—†ìŒ
  - **í•´ê²°**: Git Bash ê¸°ë³¸ í¬í•¨, WSLì€ `apt install jq`
- **ë¬¸ì œ**: ê¶Œí•œ ì˜¤ë¥˜
  - **í•´ê²°**: `chmod +x inject_knowledge.sh`

---

## ğŸ“‹ Phase 3: Python ê¸°ë°˜ ì§€ëŠ¥í˜• Hook (Deep Design)

### 3.1 ì„¤ê³„ ëª©í‘œ
- **ì§€ëŠ¥í˜• í•„í„°ë§**: Task ë‚´ìš© ë¶„ì„í•˜ì—¬ ê´€ë ¨ Knowledgeë§Œ ì„ ë³„
- **ì„±ëŠ¥ ìµœì í™”**: ìºì‹±ìœ¼ë¡œ ë°˜ë³µ ë¡œë“œ ë°©ì§€
- **ì—ëŸ¬ ë³µêµ¬**: ì‹¤íŒ¨ ì‹œì—ë„ Task ì‹¤í–‰ ë³´ì¥
- **ì‹¤ì‹œê°„ ê²€ì¦**: Mock ë°ì´í„° ë°©ì§€, ì‹¤ì œ ë°ì´í„° ë³´ì¥

### 3.2 ì•„í‚¤í…ì²˜ ì„¤ê³„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         PreToolUse Hook Trigger         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     knowledge_injector.py Main          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. Parse CLAUDE_TOOL_INPUT              â”‚
â”‚ 2. Validate Task tool & subagent_type   â”‚
â”‚ 3. Load Knowledge with caching          â”‚
â”‚ 4. Intelligent filtering                â”‚
â”‚ 5. Format injection response            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Response to Claude Code          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ {                                       â”‚
â”‚   "continue": true,                     â”‚
â”‚   "additionalContext": "...",           â”‚
â”‚   "injectedKnowledge": {...}            â”‚
â”‚ }                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.3 ì™„ì „í•œ Python Hook êµ¬í˜„

#### `.claude/hooks/knowledge_injector.py`
```python
#!/usr/bin/env python3
"""
Advanced Knowledge Base Injection Hook for Claude Code
Ensures real data injection, not mock data
Version: 1.0.0
Author: DT-RAG Team
"""

import os
import sys
import json
import hashlib
import time
from pathlib import Path
from typing import Dict, List, Any, Optional
from datetime import datetime

# Constants
KB_BASE_PATH = Path("C:/MYCLAUDE_PROJECT/sonheungmin/Unmanned/dt-rag/knowledge-base")
LOG_PATH = Path(".claude/hooks/logs/kb_injection.log")
CACHE_PATH = Path(".claude/hooks/cache/kb_cache.json")
MAX_ITEMS_TO_INJECT = 10
CACHE_TTL_SECONDS = 300  # 5 minutes

class KnowledgeInjector:
    """Advanced knowledge base injection with caching and intelligent filtering"""

    def __init__(self):
        self.cache = self._load_cache()
        self.ensure_directories()

    def ensure_directories(self):
        """Create necessary directories"""
        LOG_PATH.parent.mkdir(parents=True, exist_ok=True)
        CACHE_PATH.parent.mkdir(parents=True, exist_ok=True)

    def _load_cache(self) -> Dict:
        """Load cache with TTL check"""
        if CACHE_PATH.exists():
            try:
                with open(CACHE_PATH, 'r', encoding='utf-8') as f:
                    cache = json.load(f)
                    # Clean expired entries
                    current_time = time.time()
                    cache = {
                        k: v for k, v in cache.items()
                        if current_time - v.get('timestamp', 0) < CACHE_TTL_SECONDS
                    }
                    return cache
            except Exception:
                return {}
        return {}

    def _save_cache(self):
        """Save cache to disk"""
        try:
            with open(CACHE_PATH, 'w', encoding='utf-8') as f:
                json.dump(self.cache, f)
        except Exception as e:
            self.log(f"Cache save error: {e}", level="ERROR")

    def log(self, message: str, level: str = "INFO"):
        """Structured logging"""
        timestamp = datetime.now().isoformat()
        log_entry = f"[{timestamp}] [{level}] {message}\n"

        try:
            with open(LOG_PATH, 'a', encoding='utf-8') as f:
                f.write(log_entry)
        except Exception:
            # Silent fail for logging
            pass

        # Also output to stderr for debugging
        if level in ["ERROR", "WARNING"]:
            print(f"[KB Hook] {level}: {message}", file=sys.stderr)

    def get_tool_input(self) -> Optional[Dict]:
        """Parse and validate tool input"""
        tool_input_str = os.environ.get('CLAUDE_TOOL_INPUT', '{}')

        try:
            tool_input = json.loads(tool_input_str)
            self.log(f"Tool input parsed: {tool_input.get('tool_name', 'unknown')}")
            return tool_input
        except json.JSONDecodeError as e:
            self.log(f"Failed to parse CLAUDE_TOOL_INPUT: {e}", "ERROR")
            return None

    def load_knowledge_base(self, subagent_type: str) -> Optional[Dict]:
        """Load knowledge base with caching"""
        cache_key = f"kb_{subagent_type}"

        # Check cache first
        if cache_key in self.cache:
            self.log(f"Cache hit for {subagent_type}")
            return self.cache[cache_key]['data']

        # Load from file
        kb_path = KB_BASE_PATH / f"{subagent_type}_knowledge.json"

        if not kb_path.exists():
            self.log(f"Knowledge base not found: {kb_path}", "WARNING")
            return None

        try:
            with open(kb_path, 'r', encoding='utf-8') as f:
                knowledge = json.load(f)

                # Validate structure
                if not isinstance(knowledge, dict):
                    self.log(f"Invalid KB structure for {subagent_type}", "ERROR")
                    return None

                # Cache it
                self.cache[cache_key] = {
                    'data': knowledge,
                    'timestamp': time.time()
                }
                self._save_cache()

                self.log(f"Loaded KB for {subagent_type}: {len(knowledge.get('search_results', []))} items")
                return knowledge

        except Exception as e:
            self.log(f"Failed to load KB for {subagent_type}: {e}", "ERROR")
            return None

    def calculate_relevance(self, item: Dict, task_keywords: List[str]) -> float:
        """Calculate item relevance to task"""
        score = item.get('relevance_score', 0.5)

        # Boost score for keyword matches
        title = item.get('title', '').lower()
        content = item.get('content', '').lower()

        for keyword in task_keywords:
            keyword_lower = keyword.lower()
            if keyword_lower in title:
                score += 0.2
            if keyword_lower in content:
                score += 0.1

        return min(score, 1.0)  # Cap at 1.0

    def filter_relevant_items(self, knowledge: Dict, task_prompt: str) -> List[Dict]:
        """Intelligent filtering based on task content"""
        items = knowledge.get('search_results', [])

        if not items:
            return []

        # Extract keywords from task prompt
        task_lower = task_prompt.lower()

        # Domain-specific keyword mappings
        keyword_maps = {
            'evaluation': ['ragas', 'metric', 'evaluation', 'assess', 'measure', 'quality'],
            'database': ['postgres', 'pgvector', 'hnsw', 'index', 'migration', 'alembic'],
            'search': ['bm25', 'vector', 'hybrid', 'rerank', 'cross-encoder', 'retrieval'],
            'orchestration': ['langgraph', 'workflow', 'state', 'pipeline', 'chain'],
            'ingestion': ['chunk', 'parse', 'extract', 'document', 'pdf', 'ocr'],
            'api': ['fastapi', 'openapi', 'rest', 'endpoint', 'cors', 'swagger'],
            'security': ['auth', 'security', 'vulnerability', 'audit', 'compliance'],
            'taxonomy': ['dag', 'hierarchy', 'classification', 'ontology', 'tree'],
        }

        # Determine relevant keywords
        active_keywords = []
        for domain, keywords in keyword_maps.items():
            if any(kw in task_lower for kw in keywords[:3]):  # Check first 3 keywords
                active_keywords.extend(keywords)

        # If no specific domain detected, use general keywords
        if not active_keywords:
            # Extract potential keywords from task (simple tokenization)
            words = task_lower.split()
            active_keywords = [w for w in words if len(w) > 4][:10]

        self.log(f"Active keywords: {active_keywords[:5]}")

        # Score and filter items
        scored_items = []
        for item in items:
            relevance = self.calculate_relevance(item, active_keywords)
            if relevance > 0.6:  # Threshold
                item_copy = item.copy()
                item_copy['computed_relevance'] = relevance
                scored_items.append(item_copy)

        # Sort by relevance and return top N
        scored_items.sort(key=lambda x: x['computed_relevance'], reverse=True)
        return scored_items[:MAX_ITEMS_TO_INJECT]

    def format_injection_response(self,
                                 subagent_type: str,
                                 relevant_items: List[Dict],
                                 task_prompt: str) -> Dict:
        """Format the final injection response"""

        # Create a concise summary for injection
        if relevant_items:
            # Build context string
            context_lines = [
                f"ğŸ“š Knowledge Base: {subagent_type}",
                f"ğŸ” Filtered {len(relevant_items)} relevant items from knowledge base",
                "",
                "ğŸ¯ Top References:",
            ]

            for i, item in enumerate(relevant_items[:5], 1):
                title = item.get('title', 'Unknown')
                score = item.get('computed_relevance', item.get('relevance_score', 0))
                # Truncate long titles
                if len(title) > 80:
                    title = title[:77] + "..."
                context_lines.append(f"{i}. {title} (relevance: {score:.2f})")

            # Add key insights
            context_lines.append("")
            context_lines.append("ğŸ’¡ Key Insights:")

            # Extract unique key points
            seen_points = set()
            for item in relevant_items[:3]:
                content = item.get('content', '')
                # Extract first meaningful sentence
                sentences = content.split('.')
                for sentence in sentences:
                    sentence = sentence.strip()
                    if len(sentence) > 20 and len(sentence) < 150:
                        sentence_hash = hashlib.md5(sentence.encode()).hexdigest()[:8]
                        if sentence_hash not in seen_points:
                            context_lines.append(f"â€¢ {sentence}.")
                            seen_points.add(sentence_hash)
                            break

            additional_context = "\n".join(context_lines)

            # Structured data for potential future use
            injected_knowledge = {
                "source": "knowledge_base",
                "agent": subagent_type,
                "timestamp": datetime.now().isoformat(),
                "items_count": len(relevant_items),
                "task_summary": task_prompt[:100] if len(task_prompt) > 100 else task_prompt,
                "top_items": [
                    {
                        "title": item.get('title', ''),
                        "relevance": round(item.get('computed_relevance', 0), 3),
                        "url": item.get('url', ''),
                        "category": item.get('category', 'general')
                    }
                    for item in relevant_items[:5]
                ]
            }

        else:
            additional_context = f"ğŸ“š Knowledge Base: {subagent_type}\nâš ï¸ No highly relevant items found for this specific task."
            injected_knowledge = {
                "source": "knowledge_base",
                "agent": subagent_type,
                "timestamp": datetime.now().isoformat(),
                "items_count": 0,
                "task_summary": task_prompt[:100] if len(task_prompt) > 100 else task_prompt
            }

        return {
            "continue": True,
            "suppressOutput": False,
            "additionalContext": additional_context,
            "metadata": injected_knowledge  # This won't be shown but logged
        }

    def create_error_response(self, error_msg: str) -> Dict:
        """Create a safe error response that allows Task to continue"""
        self.log(f"Creating error response: {error_msg}", "ERROR")
        return {
            "continue": True,
            "suppressOutput": True,
            "warning": f"Knowledge injection failed: {error_msg}"
        }

    def run(self) -> Dict:
        """Main execution flow"""
        try:
            # Parse tool input
            tool_input = self.get_tool_input()
            if not tool_input:
                return self.create_error_response("Invalid tool input")

            # Check if it's a Task tool
            tool_name = tool_input.get('tool_name')
            if tool_name != 'Task':
                self.log(f"Skipping non-Task tool: {tool_name}")
                return {"continue": True}

            # Extract subagent type
            task_input = tool_input.get('tool_input', {})
            subagent_type = task_input.get('subagent_type')

            if not subagent_type:
                self.log("No subagent_type in Task input")
                return {"continue": True}

            # Get task prompt for context
            task_prompt = task_input.get('prompt', '')

            self.log(f"Processing Task for {subagent_type}")

            # Load knowledge base
            knowledge = self.load_knowledge_base(subagent_type)
            if not knowledge:
                return self.create_error_response(f"Knowledge base not found for {subagent_type}")

            # Filter relevant items
            relevant_items = self.filter_relevant_items(knowledge, task_prompt)

            self.log(f"Filtered {len(relevant_items)} relevant items from {len(knowledge.get('search_results', []))} total")

            # Format and return response
            response = self.format_injection_response(subagent_type, relevant_items, task_prompt)

            # Log successful injection
            self.log(f"Successfully injected knowledge for {subagent_type}")

            return response

        except Exception as e:
            # Log full traceback for debugging
            import traceback
            tb = traceback.format_exc()
            self.log(f"Unexpected error: {e}\n{tb}", "ERROR")

            # Return safe response to not block Task execution
            return self.create_error_response(str(e))


def validate_mock_data_prevention():
    """Self-test to ensure no mock data is being used"""
    # This runs during import to validate the system
    test_kb_path = KB_BASE_PATH / "rag-evaluation-specialist_knowledge.json"

    if test_kb_path.exists():
        try:
            with open(test_kb_path, 'r') as f:
                data = json.load(f)
                # Check for real data indicators
                if 'search_results' in data and len(data['search_results']) > 0:
                    first_item = data['search_results'][0]
                    # Verify real data structure
                    required_fields = ['query', 'url', 'title', 'content', 'relevance_score']
                    if all(field in first_item for field in required_fields):
                        print("[KB Hook] Validation passed: Real data structure confirmed", file=sys.stderr)
                    else:
                        print("[KB Hook] Warning: Knowledge base structure incomplete", file=sys.stderr)
        except Exception as e:
            print(f"[KB Hook] Validation warning: {e}", file=sys.stderr)


# Run validation on import
validate_mock_data_prevention()

# Main execution
if __name__ == "__main__":
    injector = KnowledgeInjector()
    response = injector.run()

    # Output JSON response for Claude Code
    print(json.dumps(response, ensure_ascii=False, indent=2))
```

### 3.4 ê³ ê¸‰ íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ê°€ì´ë“œ

#### ë¬¸ì œ 1: Mock ë°ì´í„° ë°˜í™˜ ë°©ì§€
**ì¦ìƒ**: Knowledgeê°€ ì£¼ì…ë˜ì§€ë§Œ ì‹¤ì œ ë‚´ìš©ì´ ì•„ë‹Œ placeholder
**ì›ì¸**: JSON íŒŒì¼ êµ¬ì¡° ë¶ˆì¼ì¹˜, íŒŒì‹± ì˜¤ë¥˜
**í•´ê²°**:
```python
# Validation í•¨ìˆ˜ ì¶”ê°€
def validate_knowledge_structure(knowledge: Dict) -> bool:
    """Ensure knowledge has real data, not mock"""
    if not knowledge.get('search_results'):
        return False

    # Check first item has real content
    first_item = knowledge['search_results'][0]
    if len(first_item.get('content', '')) < 50:
        return False  # Too short, likely mock

    # Check for mock indicators
    mock_indicators = ['example', 'test', 'placeholder', 'lorem ipsum']
    content_lower = first_item.get('content', '').lower()
    if any(indicator in content_lower for indicator in mock_indicators):
        return False

    return True
```

#### ë¬¸ì œ 2: ì¸ì½”ë”© ì˜¤ë¥˜ (í•œê¸€ í¬í•¨ ì‹œ)
**ì¦ìƒ**: UTF-8 decode error
**í•´ê²°**:
```python
# ëª¨ë“  íŒŒì¼ ì—´ê¸°ì— encoding ëª…ì‹œ
with open(kb_path, 'r', encoding='utf-8', errors='replace') as f:
    knowledge = json.load(f)
```

#### ë¬¸ì œ 3: ëŒ€ìš©ëŸ‰ Knowledge ì²˜ë¦¬
**ì¦ìƒ**: Hook timeout (5ì´ˆ ì´ˆê³¼)
**í•´ê²°**:
```python
# ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ë³€ê²½
import ijson  # pip install ijson

def load_knowledge_streaming(path: Path, limit: int = 100):
    """Load only first N items for performance"""
    items = []
    with open(path, 'rb') as f:
        parser = ijson.items(f, 'search_results.item')
        for item in parser:
            items.append(item)
            if len(items) >= limit:
                break
    return {'search_results': items}
```

#### ë¬¸ì œ 4: Hook ì‹¤í–‰ í™•ì¸
**ì§„ë‹¨ ìŠ¤í¬ë¦½íŠ¸**: `.claude/hooks/test_hook.py`
```python
#!/usr/bin/env python3
"""Test script to verify hook is working"""

import os
import json

# Simulate Task tool call
test_input = {
    "tool_name": "Task",
    "tool_input": {
        "subagent_type": "rag-evaluation-specialist",
        "prompt": "Evaluate the RAG system using RAGAS metrics"
    }
}

os.environ['CLAUDE_TOOL_INPUT'] = json.dumps(test_input)

# Run the hook
from knowledge_injector import KnowledgeInjector
injector = KnowledgeInjector()
result = injector.run()

print("Hook Response:")
print(json.dumps(result, indent=2))

# Verify real data
if 'additionalContext' in result:
    context = result['additionalContext']
    if 'RAGAS' in context or 'evaluation' in context:
        print("âœ… Real knowledge detected!")
    else:
        print("âš ï¸ Generic response - check knowledge base")
else:
    print("âŒ No context injected")
```

### 3.5 ì„±ëŠ¥ ìµœì í™”

#### ìºì‹± ì „ëµ
- **In-memory cache**: 5ë¶„ TTL
- **File-based cache**: ì˜êµ¬ ì €ì¥
- **Cache warming**: ì„œë²„ ì‹œì‘ ì‹œ ìì£¼ ì‚¬ìš©í•˜ëŠ” KB ë¯¸ë¦¬ ë¡œë“œ

#### ë³‘ë ¬ ì²˜ë¦¬ (ëŒ€ìš©ëŸ‰ KB)
```python
import asyncio
import aiofiles

async def load_knowledge_async(subagent_type: str):
    """Async loading for better performance"""
    kb_path = KB_BASE_PATH / f"{subagent_type}_knowledge.json"

    async with aiofiles.open(kb_path, mode='r', encoding='utf-8') as f:
        content = await f.read()
        return json.loads(content)
```

### 3.6 ëª¨ë‹ˆí„°ë§ ë° ë©”íŠ¸ë¦­

#### ë¡œê·¸ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
```bash
#!/bin/bash
# analyze_kb_usage.sh

LOG_FILE=".claude/hooks/logs/kb_injection.log"

echo "=== Knowledge Base Hook Usage Analysis ==="
echo

echo "1. Total invocations:"
grep -c "Processing Task" "$LOG_FILE" 2>/dev/null || echo "0"

echo
echo "2. Success rate:"
SUCCESS=$(grep -c "Successfully injected" "$LOG_FILE" 2>/dev/null || echo "0")
TOTAL=$(grep -c "Processing Task" "$LOG_FILE" 2>/dev/null || echo "1")
echo "scale=2; $SUCCESS * 100 / $TOTAL" | bc

echo
echo "3. Most used agents:"
grep "Processing Task for" "$LOG_FILE" | awk '{print $NF}' | sort | uniq -c | sort -rn | head -5

echo
echo "4. Cache hit rate:"
CACHE_HITS=$(grep -c "Cache hit" "$LOG_FILE" 2>/dev/null || echo "0")
echo "scale=2; $CACHE_HITS * 100 / $TOTAL" | bc

echo
echo "5. Average items injected:"
grep "Filtered [0-9]* relevant items" "$LOG_FILE" | \
    sed 's/.*Filtered \([0-9]*\).*/\1/' | \
    awk '{sum+=$1; count++} END {if(count>0) print sum/count; else print 0}'
```

---

## ğŸ“Š ì„±ê³µ ì§€í‘œ ë° ê²€ì¦

### Phaseë³„ ì„±ê³µ ê¸°ì¤€

#### Phase 1 (MD ê°œì„ )
- [ ] ê° MD íŒŒì¼ì— Essential Knowledge ì„¹ì…˜ ì¶”ê°€
- [ ] Git diff ê²€í†  ì™„ë£Œ
- [ ] Task ì‹¤í–‰ ì‹œ Essential Knowledge ì–¸ê¸‰ í™•ì¸

#### Phase 2 (Bash Hook)
- [ ] Hook ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ê¶Œí•œ ì„¤ì •
- [ ] settings.local.json ì—…ë°ì´íŠ¸
- [ ] Task í˜¸ì¶œ ì‹œ "Loading knowledge" ë¡œê·¸ í™•ì¸

#### Phase 3 (Python Hook)
- [ ] ì‹¤ì œ ë°ì´í„° ì£¼ì… ê²€ì¦ (no mock)
- [ ] 5ì´ˆ ë‚´ ì‹¤í–‰ ì™„ë£Œ
- [ ] ìºì‹± ë™ì‘ í™•ì¸
- [ ] ì—ëŸ¬ ì‹œì—ë„ Task ê³„ì† ì‹¤í–‰

### ìµœì¢… ê²€ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸
```bash
# 1. Knowledge í™œìš©ë¥  ì¸¡ì •
grep -r "RAGAS v2.0\|Arize Phoenix\|DeepEval" generated_reports/*.md

# 2. Hook ë¡œê·¸ ë¶„ì„
tail -n 100 .claude/hooks/logs/kb_injection.log

# 3. ì‹¤ì œ Task í…ŒìŠ¤íŠ¸
echo "Test: rag-evaluation-specialistë¡œ RAGAS v2.0 ê¸°ì¤€ í‰ê°€ ìˆ˜í–‰"
# ì‘ë‹µì— RAGAS v2.0 specific metrics í¬í•¨ ì—¬ë¶€ í™•ì¸

# 4. ì„±ëŠ¥ ì¸¡ì •
time python3 .claude/hooks/test_hook.py
```

---

## â±ï¸ ì¼ì • ë° ë¦¬ì†ŒìŠ¤

### íƒ€ì„ë¼ì¸
- **Phase 1**: 1ì‹œê°„ (ì¦‰ì‹œ ì‹œì‘ ê°€ëŠ¥)
- **Phase 2**: 30ë¶„ (Phase 1 ì™„ë£Œ í›„)
- **Phase 3**: 2ì‹œê°„ (ì •êµí•œ ì„¤ê³„ í¬í•¨)
- **ê²€ì¦ ë° ì¡°ì •**: 30ë¶„

### í•„ìš” ë¦¬ì†ŒìŠ¤
- Python 3.8+
- jq (command-line JSON processor)
- Git Bash ë˜ëŠ” WSL
- ì“°ê¸° ê¶Œí•œ (hooks ë””ë ‰í† ë¦¬)

---

## ğŸ¯ ê¸°ëŒ€ íš¨ê³¼

### ì •ëŸ‰ì  ê°œì„ 
- **Knowledge í™œìš©ë¥ **: 0% â†’ 100%
- **êµ¬ì²´ì  ì •ë³´ ì–¸ê¸‰**: 10% â†’ 80%
- **ìµœì‹  ë„êµ¬ ë²„ì „ ì¸ì‹**: 0% â†’ 100%
- **ì‘ì—… ì •í™•ë„**: 65% â†’ 90%

### ì •ì„±ì  ê°œì„ 
- RAGAS v2.0 ê°™ì€ ìµœì‹  ë„êµ¬ ì •í™•íˆ ì–¸ê¸‰
- êµ¬ì²´ì  ì„¤ì •ê°’ ì œì‹œ (ef_construction=64 ë“±)
- ì—…ê³„ í‘œì¤€ ì¤€ìˆ˜ (20 questions minimum ë“±)
- ì‹¤í–‰ ê°€ëŠ¥í•œ êµ¬ì²´ì  ê°€ì´ë“œ ì œê³µ

---

## ğŸ“ ê²°ë¡ 

ì´ 3ë‹¨ê³„ ì ‘ê·¼ë²•ì„ í†µí•´:
1. **ì¦‰ì‹œ ê°œì„ ** (Phase 1)ìœ¼ë¡œ ë¹ ë¥¸ íš¨ê³¼
2. **ìë™í™”** (Phase 2)ë¡œ ì¼ê´€ì„± í™•ë³´
3. **ì§€ëŠ¥í™”** (Phase 3)ë¡œ ìµœì  ì„±ëŠ¥ ë‹¬ì„±

íŠ¹íˆ Phase 3ì˜ Python Hookì€ mock ë°ì´í„° ë°©ì§€, ì‹¤ì‹œê°„ ê²€ì¦, ì§€ëŠ¥í˜• í•„í„°ë§ì„ í†µí•´
ì‹¤ì œ Knowledgeê°€ í™•ì‹¤í•˜ê²Œ ì£¼ì…ë˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.